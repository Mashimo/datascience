{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Audio transcription\n",
    "Whisper is an open-source speech recognition model [developed by OpenAI](https://openai.com/research/whisper)\n",
    "\n",
    "Here we can see how to use it convert an audio into text, a good example of the potentiality of the Large Language Models, neural networks trained on huge amount of text and audio.\n",
    "\n",
    "The model can be installed directly from GitHub:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install git+https://github.com/openai/whisper.git -q\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: install also ffmpeg (just need to copy the exe file) and add it in the PATH\n",
    "This is needed by the model to convert audio/video formats (i.e. you could give as input a file video and it will extract the audio component). \n",
    "\n",
    "On Mac: copy it to /usr/local/bin, verify it's working with the command \"which ffmpeg\"\n",
    "It might also be necessary to open it once so mac os will add an exception and notes that you trust it even if it's an appliccation from unidentified developer\n",
    "\n",
    "## Import module and language model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import whisper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model supports multiple languages and can also do language identification.\n",
    "\n",
    "There are five model sizes, from tiny to large, offering speed and accuracy tradeoffs. Each size can support   English-only or multiple model.\n",
    "I use the medium version for multiple languages which has around 770M parameters and requires 5GB VRAM.\n",
    "The large versione is double that.\n",
    "\n",
    "The models are trained on 680,000 hours of audio and the corresponding transcripts collected from the internet. 65% of this data represents English-language audio and matched English transcripts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sizeMmodel = whisper.load_model(\"medium\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transcribe with a single line\n",
    "\n",
    "I try first with a short audio of news in Italian language:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Massimo/anaconda3/envs/ML/lib/python3.11/site-packages/whisper/transcribe.py:114: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
     ]
    }
   ],
   "source": [
    "transcriptionIT = sizeMmodel.transcribe(\"NotizieIT.mp3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, the only required function parameter is the audio file path and name, not the language.\n",
    "The conversione did not overload the cpu nor the memory, I could easily do something else in the meanwhile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" Notizie flash Una delegazione della Commissione Affari Esteri conclude oggi la sua visita in Cile. I deputati hanno discusso con le autorità del Paese, con i rappresentanti della società civile, del rafforzamento del partenariato tra Unione Europea e America Latina. Domani gli eurodeputati si ericheranno in Brasile per il rilancio delle relazioni col Paese, per discutere della posizione del Brasile sulla guerra russa e della lotta contro l'incambiamento climatico e la deforestazione. La presidente del Parlamento Europeo, Roberta Mezzola, è a Zagabria. Ieri ha incontrato il Primo Ministro croato Andrei Plenkovic e ha partecipato a una conferenza sui 10 anni di adesione della Croazia all'Unione Europea, oltre che a un evento con i giovani. Oggi Mezzola parlerà al Parlamento Croato e domani la presidente sarà invece a Londra per partecipare alla conferenza sulla ripresa dell'Ucraina e per pronunciare a Westminster un discorso programmatico all'evento parlamentare della conferenza. Una delegazione della Commissione Cultura e Istruzione è in Scozia. Gli eurodeputati stanno discutendo della potenziale cooperazione nei settori dell'istruzione, della cultura, dei giovani e dello sport dopo la Brexit. A Edimburgo esaminaranno in particolare le possibilità di continuare la mobilità tra Scozia e Unione Europea nell'ambito del programma Erasmus Plus, la visita si concluderà domani.\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#printing the transcribe\n",
    "transcriptionIT['text']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And here is a Chinese audio:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Massimo/anaconda3/envs/ML/lib/python3.11/site-packages/whisper/transcribe.py:114: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
     ]
    }
   ],
   "source": [
    "transcriptionCH = sizeMmodel.transcribe(\"CH6-5-1.mp3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'对话一你想吃什么就吃什么。我饿了。我们找个饭馆吃饭吧。好。前面有个饭馆,我们去吃自助餐,怎么样?好啊。你喜欢吃中餐还是西餐?什么都行,不过我还是喜欢吃中餐。那里有包子,饺子,炒饭和各种炒菜。你想吃什么就吃什么,走吧!太好了!一,根据对话内容,选择正确答案。一,男的和女的现在在哪儿?二,谁饿了?三,他们准备去吃什么?'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#printing the transcribe\n",
    "transcriptionCH['text']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It worked perfectly for both languages. Even better that commercial products. Speed was more or less 2x the audio total time\n",
    "\n",
    "I tried also a 20 minutes video in German language and extracted perfectly its audio too.\n",
    "And all this with the medium size, not even the large one.\n",
    "Although hallucinations are possible.\n",
    "\n",
    "## Detect language\n",
    "\n",
    "The function _detect_language()_ will examine the audio and outputs the probability for all supported languages (around one hundred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio = whisper.load_audio(\"CH6-5-1.mp3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio = whisper.pad_or_trim(audio)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make log-Mel spectrogram and move to the same device as the model\n",
    "mel = whisper.log_mel_spectrogram(audio).to(sizeMmodel.device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# detect the spoken language\n",
    "_, probs = sizeMmodel.detect_language(mel)  # probs is a dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'zh'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(probs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "keys are a two-letters symbol for language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9969410300254822"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs['zh']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ZH is Chinese. The model predicted it with 99.7% probability\n",
    "\n",
    "## Translate\n",
    "\n",
    "The model can also translate into English during the transcription.\n",
    "Just call the _transcribe()_ function passing a task to translate:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Massimo/anaconda3/envs/ML/lib/python3.11/site-packages/whisper/transcribe.py:114: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
     ]
    }
   ],
   "source": [
    "transcriptionEN = sizeMmodel.transcribe(\"CH6-5-1.mp3\", task=\"translate\") # Default is transcribe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" Conversation 1 You can eat whatever you want. I'm hungry. Let's find a restaurant to eat. OK! There is a restaurant in front. How about we go to eat a self-serve meal? OK! Do you like Chinese or Western food? Anything is fine. But I still like Chinese food. There are buns, dumplings, fried rice and all kinds of stir-fried dishes. You can eat whatever you want. Let's go! Great! 1 According to the conversation, choose the right answer. 1 Where are the men and women now? 2 Who is hungry? 3 What are they going to eat?\""
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transcriptionEN['text']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The translation is also quite good: maybe only _self-serve meal_ would be better as _buffet_ :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
