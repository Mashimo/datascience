{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "31cf3edd",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "In a previous post we have seen how a Large Language Model (LLM) uses a chat and how user queries are inputed   via prompts. Let's dig more into what are efficient prompts.  \n",
    "You can use any chat and LLM or a local one.  \n",
    "  \n",
    "Here I will use ollama, so I assume it is installed and is running, thereogre can answer the requests from the python scripts.\n",
    "\n",
    "# Prompt engineering\n",
    "\n",
    "At the risk of oversimplifying, large language models (LLM) are essentially sophisticated probabilistic models. Given an input, they generate probable outputs based on patterns learned from data.  \n",
    "\n",
    "Thus, at its core, prompt engineering is about conditioning the probabilistic model to generate our desired output. Each additional instruction or piece of context can be viewed as conditioning that steers the modelâ€™s generation in a particular direction. This mental model applies to image generation too.  \n",
    "  \n",
    "  Here is a list of basic prompt patterns.  \n",
    "## What is a Prompt?\n",
    "A prompt is an input to a Generative AI model, that\n",
    "is used to guide its output. Prompts may consist of\n",
    "text, image, sound, or other media. \n",
    "  \n",
    "Knowing how to effectively structure, evaluate,\n",
    "and perform other tasks with prompts is essential\n",
    "to using these models. Empirically, better prompts\n",
    "lead to improved results across a wide range of\n",
    "tasks. A large body of literature has grown\n",
    "around the use of prompting to improve results\n",
    "and the number of techniques is rapidly\n",
    "increasing.  \n",
    "\n",
    "This is what **prompt engineering** is about. Let's see what different prompts are useful for different tasks.  \n",
    "We use for this POST requests to the local llama LLM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2e455d5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests  # to send requests to the Ollama server\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0a503aa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"http://localhost:11434/api/generate\"  # the local host URL where Ollama is running\n",
    "\n",
    "# a simple function to encapsulate the POST request\n",
    "# input is the prompt (a string)\n",
    "# returns the answer as a string\n",
    "\n",
    "def hal3000(prompt):\n",
    "        # build the JSON-format input\n",
    "    data = {\n",
    "        \"model\": \"llama3\",  # put here your model\n",
    "        \"prompt\": prompt,\n",
    "        \"stream\": False\n",
    "    }\n",
    "    \n",
    "    headers = {\n",
    "        'Content-Type': 'application/json'\n",
    "    }\n",
    "        # send the POST web request\n",
    "    response = requests.post(url, headers=headers, json=data)\n",
    "    \n",
    "    if response.status_code == 200:  # 200 is OK\n",
    "        return(json.loads(response.text)[\"response\"])\n",
    "    else:\n",
    "        print(\"Error! \", response.status_code)\n",
    "        return 0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "108e8953",
   "metadata": {},
   "source": [
    "## Components of a Prompt\n",
    "There are a variety of common components included in a prompt. Let's see the most commonly used components and how they fit\n",
    "into prompts.  \n",
    "We start with a **directive**. Many prompts issue a directive in the\n",
    "form of an instruction or question.  \n",
    "In this example, a prompt is a string (textual prompt). It's the input for the LLM wthich produces another string in answer, which we can then print. \n",
    "The string is  a direct request ('tell me', a verb) followed by an object ('books to read') and some additional detail ('five good science fiction')."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "96832dc9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Here are five new science fiction books that have received great reviews and might interest you:\\n\\n1. **\"The Three-Body Problem\" by Liu Cixin (2014)**: This novel is a stunning blend of Chinese culture, astronomy, and physics. It\\'s set against the backdrop of China\\'s Cultural Revolution and explores the first contact between humans and an alien civilization. A 2020 Hugo Award winner for Best Novel.\\n\\n2. **\"The Power\" by Naomi Alderman (2016)**: In this thought-provoking novel, a sudden shift in power dynamics occurs when women suddenly develop the ability to release electrical jolts from their fingertips. The story follows a group of women as they use this newfound power to overthrow their oppressors and create a new world order.\\n\\n3. **\"The Collapsing Empire\" by John Scalzi (2017)**: This humorous novel is set in a galaxy where the Flow, a mysterious energy source that powers interstellar travel, has suddenly begun to collapse. The story follows a diverse cast of characters as they navigate the consequences of this collapse and fight for survival.\\n\\n4. **\"The Outside\" by Ada Hoffmann (2019)**: This debut novel is a gripping exploration of artificial intelligence, consciousness, and humanity. It follows a scientist who becomes obsessed with understanding an alien AI that has been sent to Earth to communicate with humans. A 2020 Hugo Award nominee for Best Novel.\\n\\n5. **\"We Are the Apocalypse\" by Alan Baxter (2019)**: In this chilling novel, a group of survivors must navigate a post-apocalyptic world where the remnants of human civilization are threatened by strange creatures and ancient technologies.\\n\\nAll of these books have received critical acclaim and are great examples of modern science fiction. I hope you enjoy them!\\n\\n(Note: The publication dates mentioned are for the original publication dates in English. Dates may vary depending on your region.)'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(hal3000(\"Tell me five new sci-fi good books to read\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e30ba3d",
   "metadata": {},
   "source": [
    "Prompts can also be shorter if part of a conversation, exactly like if you would normally talk with somebody.  \n",
    "Consider the prompts below. The first prompt is still a direct request ('tell me', a verb) followed by an object ('about apple') and will likely generate a response about Apple the tech company (remmeber LLMs are probabilistic models). The second prompt simply adds a context ('fruit') and we don't need to repeat the request because it will **remember the previous questions** and  will infer that the request is tell me about the fruit apple. It will describe the fruit. And the third will explain the idiom. Don't even need to explain it's an idiom, just plainly state it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "071cf2fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apple!\n",
      "\n",
      "Apple Inc. is a multinational technology company that designs, manufactures, and markets consumer electronics, computer software, and online services. Here are some interesting facts about Apple:\n",
      "\n",
      "**Founding**: Apple was founded on April 1, 1976, by Steve Jobs, Steve Wozniak, and Ronald Wayne in Cupertino, California.\n",
      "\n",
      "**First Product**: The first product from Apple was the Apple I, a personal computer that was introduced at the Homebrew Computer Club in Palo Alto, California. It was designed and hand-built by Steve Wozniak.\n",
      "\n",
      "**Apple II**: In 1977, Apple released the Apple II, one of the first highly successful mass-produced personal computers. The Apple II was designed to be user-friendly and aesthetically pleasing, which became a hallmark of Apple's products.\n",
      "\n",
      "**Macintosh Computer**: In 1984, Apple introduced the Macintosh computer, which revolutionized the way people interacted with computers by popularizing the graphical user interface (GUI).\n",
      "\n",
      "**iPod**: In 2001, Apple released the iPod, a portable music player that transformed the music industry. The iPod became one of the most successful consumer electronics products in history.\n",
      "\n",
      "**iPhone**: In 2007, Apple introduced the iPhone, a revolutionary smartphone that combined a mobile phone, an iPod, and an internet communications device into one product. The iPhone changed the way people communicate, access information, and use apps.\n",
      "\n",
      "**iPad**: In 2010, Apple released the iPad, a tablet computer that quickly gained popularity for its portability, user-friendly interface, and app ecosystem.\n",
      "\n",
      "**Steve Jobs' Return**: In 1997, Steve Jobs returned to Apple after a 12-year absence. He played a crucial role in transforming the company into one of the most successful technology companies in the world.\n",
      "\n",
      "**Tim Cook's Leadership**: Since Steve Jobs' passing in 2011, Tim Cook has led Apple as CEO. Under his leadership, Apple has continued to innovate and expand its product lines.\n",
      "\n",
      "**Stock Price**: Apple is one of the largest publicly traded companies in the world, with a market capitalization of over $2 trillion (as of January 2023).\n",
      "\n",
      "**Innovative Products**: Apple is known for its innovative products, such as:\n",
      "\n",
      "\t* Apple Watch: a smartwatch that tracks fitness and health metrics\n",
      "\t* AirPods: wireless earbuds that offer seamless audio streaming\n",
      "\t* Apple TV+: a subscription-based streaming service offering exclusive content\n",
      "\t* Mac Pro: a high-performance computer designed for creative professionals\n",
      "\n",
      "**Sustainability Efforts**: Apple has made significant efforts to reduce its environmental impact, such as:\n",
      "\n",
      "\t* Powering 100% of its facilities with renewable energy\n",
      "\t* Reducing carbon emissions from manufacturing and supply chain\n",
      "\t* Implementing sustainable materials and recycling programs\n",
      "\n",
      "Overall, Apple has become synonymous with innovation, design, and customer experience. Its products have revolutionized the way people live, work, and play, making it one of the most successful companies in the world.\n"
     ]
    }
   ],
   "source": [
    "prompt = \"tell me about apple\"\n",
    "print(hal3000(prompt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "96a0fd33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A delicious and popular choice!\n",
      "\n",
      "Here are some interesting facts about apples:\n",
      "\n",
      "1. **There are over 7,500 known varieties** of apples worldwide, each with its own unique characteristics, flavors, and textures.\n",
      "2. **Apples are a major source of antioxidants**. In fact, one medium-sized apple contains about 4.4 milligrams of antioxidants, which can help protect against cell damage and reduce the risk of chronic diseases like heart disease and cancer.\n",
      "3. **The world's largest producer of apples is China**, followed by the United States, Poland, and Russia. Washington state in the US produces over 70% of the country's apple crop.\n",
      "4. **Apples are a great source of fiber**. One medium-sized apple contains about 4 grams of dietary fiber, which can help regulate bowel movements and support healthy digestion.\n",
      "5. **The first apples were cultivated in Central Asia around 4000 BC**. From there, they spread to ancient Greece, Rome, and other parts of the world.\n",
      "\n",
      "Which variety of apple is your favorite?\n"
     ]
    }
   ],
   "source": [
    "prompt = \"apple fruit\"\n",
    "print(hal3000(prompt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "565ac82d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A lovely phrase!\n",
      "\n",
      "The \"apple of my eye\" is a common idiomatic expression that means the person or thing that is most dear to you, often in a figurative sense. It's like saying they're your favorite, your best, or the one closest to your heart.\n",
      "\n",
      "This phrase has its roots in ancient Near Eastern cultures, where the pupil of the eye was considered the center of wisdom and insight. In some biblical passages (e.g., Deuteronomy 32:10), God is referred to as the \"apple of thine eye,\" meaning the source of one's greatest joy and protection.\n",
      "\n",
      "In modern times, the phrase has evolved to become a sweet way to express affection or admiration for someone or something. For example:\n",
      "\n",
      "* \"She's the apple of my eye\" - This means that person is your favorite, your partner in life.\n",
      "* \"This new restaurant is the apple of my eye\" - It's your go-to spot, your favorite place to dine.\n",
      "\n",
      "So, who (or what) is the apple of your eye?\n"
     ]
    }
   ],
   "source": [
    "prompt = \"apple of my eye\"\n",
    "print(hal3000(prompt))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b29da9c9",
   "metadata": {},
   "source": [
    "## Prompt Template \n",
    "Prompts are often constructed\n",
    "via a prompt template (Shin et al., 2020b).  \n",
    "A\n",
    "prompt template is a function that contains one or\n",
    "more variables which will be replaced by some media (usually text) to create a prompt. \n",
    "  \n",
    "Here is an example of a template to ask for a children's story and has some variables in it that can be 'tuned' to ask for variations in the story.  \n",
    "These are the variables with an initial value (taken from an example by Andrew Ng):  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b03dbb73",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = \"unicorn\"\n",
    "driverVehicle = \"colorful, asymmetric dinosaur car\"\n",
    "favoritePlanet = \"Pluto\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "976eaa0b",
   "metadata": {},
   "source": [
    "And this is the template.  \n",
    "As you can see, it has placeholders for the variables which can be replaced every time by new values while the rest remains the same.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "2d6adab8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Write me a 300 word children's story about a unicorn racing\n",
      "a colorful, asymmetric dinosaur car for the Pluto champion cup.\n"
     ]
    }
   ],
   "source": [
    "storyPrompt = f\"\"\"Write me a 300 word children's story about a {driver} racing\n",
    "a {driverVehicle} for the {favoritePlanet} champion cup.\"\"\"\n",
    "print(storyPrompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "905ade19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Once upon a time, in a land of sparkles and sunshine, a magical unicorn named Luna loved to go fast! She had heard of the legendary Pluto Champion Cup, a prestigious racing tournament held on the mystical planet of Pluto. The grand prize was a glittering trophy and the title of \"Fastest of the Fast.\"\n",
      "\n",
      "Luna knew she had what it took to win, but she needed the right ride. That's when she spotted him - a colorful, asymmetric dinosaur car named Dino-Mite! His bright green body had a wonky fin on top, and his tail was shaped like a giant pom-pom. Luna couldn't resist the charm of this quirky vehicle.\n",
      "\n",
      "The day of the Pluto Champion Cup arrived, and Luna hopped into the driver's seat of Dino-Mite. The starting line was a beautiful, glowing track that wound its way around a sparkling ice castle. The other racers included a fleet-footed cheetah in a sleek, high-tech car, a speedy rabbit in a shiny, aerodynamic vehicle, and even a wise old owl flying her own magic carpet.\n",
      "\n",
      "The green flag waved, and the race was off! Luna and Dino-Mite took off like rockets, their horn and tail leaving trails of glitter behind them. The cheetah's high-tech car zipped ahead, but Luna didn't give up. She tapped into her magical energy and goosed it - whoosh! Dino-Mite surged forward, his pom-pom tail wagging wildly.\n",
      "\n",
      "As they approached the finish line, it was neck-and-neck between Luna and the cheetah. But just as the cheetah thought she had won, Luna gave one final burst of magic, and Dino-Mite crossed the line in first place! The crowd erupted in cheers, and the judges awarded Luna the Pluto Champion Cup.\n",
      "\n",
      "Luna beamed with pride, hugging Dino-Mite's goofy fin. \"We make an unbeatable team!\" she exclaimed. From that day forward, Luna and Dino-Mite were known as the fastest duo in the galaxy, and their magical adventures took them to new heights - literally!\n"
     ]
    }
   ],
   "source": [
    "print(hal3000(storyPrompt))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc86e5c6",
   "metadata": {},
   "source": [
    "### Templates for classification\n",
    "Consider applying prompting to the task of binary classification of tweets. Here is an initial\n",
    "prompt template that can be used to classify inputs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "99965a22",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentimentAnalysisTemplate = \"classify the text as positive or negative: \"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "ea199dcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classify the text as positive or negative:  A Space Odissey is one of the best movie I have seen\n"
     ]
    }
   ],
   "source": [
    "prompt = f\"{sentimentAnalysisTemplate} A Space Odissey is one of the best movie I have seen\"\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4c4e2846",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I would classify this text as POSITIVE. The text expresses a strong and enthusiastic opinion about the movie \"A Space Odyssey\", stating that it's one of the best movies they've ever seen, which indicates a very positive sentiment!\n"
     ]
    }
   ],
   "source": [
    "print(hal3000(prompt))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74b75529",
   "metadata": {},
   "source": [
    "For example you could iterate on texts from a dataset and applying the template before inputting to the LLM:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "da00cfbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classify the text as positive or negative:  I would watch another Marvel movie only if they pay me\n",
      " >>> \n",
      "I would classify this text as NEGATIVE. The speaker is expressing a strong disinterest in watching another Marvel movie, indicating that their experience with previous movies has not been enjoyable enough to warrant paying for another one.\n",
      "classify the text as positive or negative:  I did not want to watch Totoro but was a nice surprise\n",
      " >>> \n",
      "I would classify this text as POSITIVE. The person initially didn't want to watch My Neighbor Totoro, but it ended up being a \"nice surprise\", indicating that they were pleasantly surprised by the film and had a positive experience.\n"
     ]
    }
   ],
   "source": [
    "textsToBeClassified = [\"I would watch another Marvel movie only if they pay me\",\n",
    "                       \"I did not want to watch Totoro but was a nice surprise\"]\n",
    "for i in textsToBeClassified:\n",
    "    prompt = f\"{sentimentAnalysisTemplate} {i}\"\n",
    "    print(prompt)\n",
    "    print(\" >>> \")\n",
    "    print(hal3000(prompt))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b45bf5b",
   "metadata": {},
   "source": [
    "## In-Context Learning (ICL)\n",
    "ICL refers to specific method of prompt engineering where demonstration of task are provided as part of the prompt. The model is performing and behaving based on those input examples in the user's prompt.  \n",
    "  \n",
    "The ability of GenAIs to learn skills\n",
    "and tasks is achieved by providing them with examples within the prompt, without the\n",
    "need for weight updates/retraining.  \n",
    "\n",
    "### Zero-shot learning\n",
    "A zero-shot is when the model predicts the answer without any input examples, given only a natural language description of the task. It's therefore **the same like a direct request** above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "eb4b0544",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fromage\n"
     ]
    }
   ],
   "source": [
    "zeroShotPrompt = \"\"\"\n",
    "Translate English to French:\n",
    "cheese =>\"\"\"\n",
    "print(hal3000(zeroShotPrompt))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc24f52d",
   "metadata": {},
   "source": [
    "### One-shot and few-shot learning  \n",
    "In addition to the task description, the model sees a single example of tasks (one-shot) or a couple of examples (few-shots). \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "c77a9772",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fun one!\n",
      "\n",
      "Sea otter => loutre de mer\n"
     ]
    }
   ],
   "source": [
    "oneShotPrompt = \"\"\"\n",
    "Translate English to French:\n",
    "cheese => fromage \n",
    "sea otter => \"\"\"\n",
    "print(hal3000(oneShotPrompt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "435340df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The correct translation is:\n",
      "\n",
      "peppermint => menthe poivriÃ¨re (or simply menthe for the common peppermint flavor)\n",
      "\n",
      "Note: \"Menthe\" is a more literal translation of \"peppermint\", as it refers to the plant Mentha piperita. However, if you're looking for a more idiomatic translation that matches the common usage in English, \"menthe poivriÃ¨re\" (or simply \"menthe\") would be a better choice.\n",
      "\n",
      "Let me know if you have any other requests!\n"
     ]
    }
   ],
   "source": [
    "fewShotPrompt = \"\"\"\n",
    "Translate English to French:\n",
    "cheese => fromage \n",
    "Sea otter => loutre de mer\n",
    "plush girafe => girafe peluche\n",
    "peppermint => \"\"\"\n",
    "print(hal3000(fewShotPrompt))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d1aa283",
   "metadata": {},
   "source": [
    "These are simple examples, likely the LLM could correctly answer without further examples.  \n",
    "The real advantage of this kind of prompting is when you want to clarify what you mean, by giving some exemples. To get positive/negative/neutral sentiment, we need to give examples in the prompt:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c2aee479",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interesting\n"
     ]
    }
   ],
   "source": [
    "# Zero-shot example. \n",
    "prompt = '''\n",
    "Classify: I saw a Gecko.\n",
    "Sentiment: ?\n",
    "\n",
    "Give one word response.\n",
    "'''\n",
    "print(hal3000(prompt))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c57dd20",
   "metadata": {},
   "source": [
    "Without further context, the LLM answered *Interesting*. This is also due to the fact that we requested a one-word response. It will be more precise if we give examples. By giving examples to the LLM, it understands the expected output format:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "192e2acb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neutral\n"
     ]
    }
   ],
   "source": [
    "# Few-shots. \n",
    "\n",
    "prompt = '''\n",
    "Classify: I love Llamas!\n",
    "Sentiment: Positive\n",
    "Classify: I don't like snakes.\n",
    "Sentiment: Negative\n",
    "Classify: I saw a Gecko.\n",
    "Sentiment:\n",
    "\n",
    "Give one word response.\n",
    "'''\n",
    "print(hal3000(prompt))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f21779d6",
   "metadata": {},
   "source": [
    "## Output Formatting \n",
    "It is often desirable for the\n",
    "GenAI to output information in certain formats, for\n",
    "example, CSV (Comma Separated Value) or markdown formats (Xia et al.,\n",
    "2024). To facilitate this, you can simply add instructions to do so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "1cf71359",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are the Nobel Prize in Literature winners for the last 5 years (2017-2021):\n",
      "\n",
      "* 2017: Kazuo Ishiguro (United Kingdom)\n",
      "* 2018: Olga Tokarczuk (Poland) and Peter Handke (Austria)\n",
      "* 2019: Peter Handke (Austria)\n",
      "* 2020: Louise GlÃ¼ck (USA)\n",
      "* 2021: Abdulrazak Gurnah (Tanzania)\n",
      "\n",
      "Here is the list in CSV format:\n",
      "\n",
      "\"Year\",\"Winner\",\"Country\"\n",
      "\"2017\",\"Kazuo Ishiguro\",\"United Kingdom\"\n",
      "\"2018\",\"Olga Tokarczuk\",\"Poland\"\n",
      "\"2018\",\"Peter Handke\",\"Austria\"\n",
      "\"2019\",\"Peter Handke\",\"Austria\"\n",
      "\"2020\",\"Louise GlÃ¼ck\",\"USA\"\n",
      "\"2021\",\"Abdulrazak Gurnah\",\"Tanzania\"\n",
      "\n",
      "Note: The CSV file is:\n",
      "\n",
      "Year,Winner,Country\n",
      "2017,Kazuo Ishiguro,United Kingdom\n",
      "2018,Olga Tokarczuk,Poland\n",
      "2018,Peter Handke,Austria\n",
      "2019,Peter Handke,Austria\n",
      "2020,Louise GlÃ¼ck,USA\n",
      "2021,Abdulrazak Gurnah,Tanzania\n"
     ]
    }
   ],
   "source": [
    "prompt = \"\"\"\n",
    "Tell me the countries of the Nobel prize winners in Literature of the last 5 years, \n",
    "summarize this into a csv\"\"\"\n",
    "print(hal3000(prompt))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b1c2f61",
   "metadata": {},
   "source": [
    "Here is another example, that requests to answer as a series of tags:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "a27bce7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are the extracted details:\n",
      "\n",
      "* **Name**: SmartHome Mini\n",
      "* **Size**: 5 inches wide\n",
      "* **Price**: $49.99\n",
      "* **Color**: Black or White\n"
     ]
    }
   ],
   "source": [
    "prompt = '''\n",
    "The SmartHome Mini is a compact smart home assistant available in black or white for \n",
    "only $49.99. At just 5 inches wide, it lets you control lights, thermostats, and other \n",
    "connected devices via voice or appâ€”no matter where you place it in your home. This \n",
    "affordable little hub brings convenient hands-free control to your smart devices.\n",
    "\n",
    "Extract the <name>, <size>, <price>, and <color> from this product description.\n",
    "'''\n",
    "print(hal3000(prompt))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c29125c6",
   "metadata": {},
   "source": [
    "### Style Instructions \n",
    "Style instructions are a type\n",
    "of output formatting used to modify the output\n",
    "stylistically rather than structurally.  \n",
    "For example, I could add in the prompt to have a 'clear and brief' answer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e0944dce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Three-Body Problem is a fundamental challenge in astronomy: how to accurately predict the motion of three celestial bodies interacting with each other, such as two stars and one planet or three planets. This seemingly simple problem has stumped scientists for centuries due to the complexity of gravitational forces and the resulting chaotic behavior. Unlike the relatively straightforward Two-Body Problem (e.g., a single star and its planet), the Three-Body Problem's triple interactions create unpredictable patterns, making it a persistent obstacle in fields like astrodynamics, planetary formation, and even space mission planning.\n"
     ]
    }
   ],
   "source": [
    "stylishPrompt = \"Write a clear and brief paragraph about the 3 body problem.\"\n",
    "print(hal3000(stylishPrompt))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3751c253",
   "metadata": {},
   "source": [
    "### Scores as output\n",
    "Another output format of the LLM is asking to provide a score; this can induce further processing and produces an output which describes how was the evaluation done.  \n",
    "For a good result, you should clarify what are the score levels in your intentions.  \n",
    "Here are a few examples of such prompts:  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7981e2c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score the following story on a scale of 1-5 from well to poorly written:  Harry Potter and the Philosopher's Stone\n",
      "I'd score \"Harry Potter and the Philosopher's Stone\" (published as \"Harry Potter and the Sorcerer's Stone\" in the United States) a 4 out of 5 for its writing quality. Here's why:\n",
      "\n",
      "* The world-building is exceptional, with a richly detailed magical universe that has become iconic in popular culture.\n",
      "* The characters are well-developed and relatable, particularly Harry, Ron, and Hermione.\n",
      "* J.K. Rowling's prose is engaging and accessible, making the story appealing to readers of all ages.\n",
      "* The pacing is well-balanced, with a mix of action, humor, and emotional depth that keeps the reader invested in the story.\n",
      "\n",
      "The only reason I wouldn't give it a perfect 5 out of 5 is that some critics have noted that the writing can be a bit dense at times, particularly when describing magical concepts or backstories. Additionally, some of the supporting characters feel a bit one-dimensional (although this criticism has decreased as the series progressed and Rowling refined her character development).\n",
      "\n",
      "Overall, however, \"Harry Potter and the Philosopher's Stone\" is an excellent debut novel that sets the stage for a beloved series.\n"
     ]
    }
   ],
   "source": [
    "linearScaleTemplate = \"Score the following story on a scale of 1-5 from well to poorly written: \"\n",
    "prompt = f\"{linearScaleTemplate} Harry Potter and the Philosopher\\'s Stone\"\n",
    "print(prompt)\n",
    "print(hal3000(prompt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e1f2bf58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Is the following story well written at a highschool level (yes/no)?:  \n",
      "For millennia, when a star flickered, \n",
      "the old man ascended the stairway toward the sky \n",
      "carrying a suitcase of starbulbs.\n",
      "Yes, this story is well-written at a high school level.\n",
      "\n",
      "Here's why:\n",
      "\n",
      "1. **Unique opening**: The use of \"millennia\" to begin the poem grabs the reader's attention and sets the tone for an otherworldly tale.\n",
      "2. **Vivid imagery**: The phrase \"the old man ascended the stairway toward the sky\" evokes a sense of wonder and curiosity, and the image of carrying a suitcase of starbulbs is both fascinating and mysterious.\n",
      "3. **Economy of language**: The author uses few words to convey a rich atmosphere and raise questions in the reader's mind (e.g., What does the old man do with the starbulbs?).\n",
      "4. **Effective use of metaphor**: Comparing stars to \"flickering\" implies that they are like candles, which adds to the whimsical and mystical nature of the story.\n",
      "5. **Simple yet effective structure**: The poem has a clear and concise structure, making it easy to follow.\n",
      "\n",
      "Overall, this is a well-written piece that effectively uses language and imagery to create an intriguing and imaginative world.\n"
     ]
    }
   ],
   "source": [
    "binaryScoreTemplate = \"Is the following story well written at a highschool level (yes/no)?: \"\n",
    "prompt = f\"\"\"\n",
    "{binaryScoreTemplate} \n",
    "For millennia, when a star flickered, \n",
    "the old man ascended the stairway toward the sky \n",
    "carrying a suitcase of starbulbs.\"\"\"\n",
    "print(prompt)\n",
    "print(hal3000(prompt)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9b9855b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Score the following story according to the\n",
      "following scale:\n",
      "Poor\n",
      "Acceptable\n",
      "Good\n",
      "Very Good\n",
      "Incredible \n",
      "I am sorry, it's a girl said the doctor to the father.\n",
      "no, I am sorry, you are a sexist said the girl child to the world.\n",
      "What a powerful and timely story! I would score this story as \"Very Good\". Here's why:\n",
      "\n",
      "* The story is short and to the point, yet it conveys a strong message about gender bias.\n",
      "* The use of a doctor's office as the setting adds an air of authority and legitimacy to the conversation.\n",
      "* The girl child's response is clever and unexpected, which makes it all the more impactful.\n",
      "* The story raises important questions about how we treat girls and women in our society, and encourages readers to think critically about these issues.\n",
      "\n",
      "Overall, I think this story is a great example of how a brief, well-crafted narrative can make a big impact!\n"
     ]
    }
   ],
   "source": [
    "likertScaleTemplate = \"\"\"\n",
    "Score the following story according to the\n",
    "following scale:\n",
    "Poor\n",
    "Acceptable\n",
    "Good\n",
    "Very Good\n",
    "Incredible\"\"\"\n",
    "prompt = f\"\"\"\n",
    "{likertScaleTemplate} \n",
    "I am sorry, it's a girl said the doctor to the father.\n",
    "no, I am sorry, you are a sexist said the girl child to the world.\"\"\"\n",
    "print(prompt)\n",
    "print(hal3000(prompt)) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7925dc32",
   "metadata": {},
   "source": [
    "### Code as output\n",
    "A special formatting is software code; there are tons of code online to train LLMs but remains a very creative activity; don't expect it will be able to code anything from scratch but for small features (especially known problems) or code reviews it's great.  \n",
    "Here is a classical math problem - factorise a number - solved in Python:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "7cd597e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "codePrompt = '''\n",
    "write a function in python code to factorise an input number into its prime factors\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "66f6a371",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here is a Python function that factorsizes an input number into its prime factors:\n",
      "```\n",
      "def factorize(n):\n",
      "    factors = []\n",
      "    i = 2\n",
      "    while i * i <= n:\n",
      "        if n % i:\n",
      "            i += 1\n",
      "        else:\n",
      "            n //= i\n",
      "            factors.append(i)\n",
      "    if n > 1:\n",
      "        factors.append(n)\n",
      "    return factors\n",
      "```\n",
      "Here's an explanation of how the function works:\n",
      "\n",
      "1. We start with an empty list `factors` that will store the prime factors.\n",
      "2. We initialize a variable `i` to 2, which is the smallest prime number.\n",
      "3. We loop until `i * i` is greater than the input number `n`. This is because if `n` has a factor less than or equal to its square root, it must be a multiple of some smaller prime factor.\n",
      "4. Inside the loop, we check if `n` is divisible by `i` using the modulo operator (`%`). If it's not, we increment `i` by 1 and continue to the next iteration.\n",
      "5. If `n` is divisible by `i`, we divide `n` by `i` (using the `/=` operator) and append `i` to the `factors` list. This is because `i` is a prime factor of `n`.\n",
      "6. Once the loop finishes, if `n` is still greater than 1, it means that `n` itself is a prime number, so we append it to the `factors` list.\n",
      "7. Finally, we return the `factors` list.\n",
      "\n",
      "Here's an example usage:\n",
      "```\n",
      ">>> factorize(36)\n",
      "[2, 2, 3, 3]\n",
      "\n",
      ">>> factorize(42)\n",
      "[2, 3, 7]\n",
      "\n",
      ">>> factorize(100)\n",
      "[2, 2, 5, 5]\n",
      "```\n",
      "Note that this function uses a trial division approach, which is not the most efficient method for large numbers. For larger numbers, you may want to use a more advanced algorithm like the Sieve of Eratosthenes or the Miller-Rabin primality test.\n"
     ]
    }
   ],
   "source": [
    "print(hal3000(codePrompt))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5c57f55",
   "metadata": {},
   "source": [
    "That's very comprehensive, even with some kind of input test :)  \n",
    "Let's put the code into a Python function and test it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "dfccc234",
   "metadata": {},
   "outputs": [],
   "source": [
    "def factorize(n):\n",
    "    factors = []\n",
    "    i = 2\n",
    "    while i * i <= n:\n",
    "        if n % i:\n",
    "            i += 1\n",
    "        else:\n",
    "            n //= i\n",
    "            factors.append(i)\n",
    "    if n > 1:\n",
    "        factors.append(n)\n",
    "    return factors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "9d379ff4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 2, 5, 5]"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "factorize(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ca5e485",
   "metadata": {},
   "source": [
    "Fantastic, it works.  \n",
    "Let's try a less common but still simple problem:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "3eecab49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "If we list all the natural numbers below 10 that are multiples of 3 or 5, we get 3,5,6 and 9. \n",
      "The sum of these multiples is 23.\n",
      "Write a python code that finds the sum of all the multiples of 3 or 5 below 1000.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "codePrompt = '''\n",
    "If we list all the natural numbers below 10 that are multiples of 3 or 5, we get 3,5,6 and 9. \n",
    "The sum of these multiples is 23.\n",
    "Write a python code that finds the sum of all the multiples of 3 or 5 below 1000.\n",
    "'''\n",
    "print(codePrompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "5d227514",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here's a simple Python code to solve this problem:\n",
      "\n",
      "```Python\n",
      "def sum_of_multiples(n):\n",
      "    return sum(i for i in range(n) if i % 3 == 0 or i % 5 == 0)\n",
      "\n",
      "print(sum_of_multiples(1000))\n",
      "```\n",
      "\n",
      "This code defines a function `sum_of_multiples` that takes an integer `n` as input and returns the sum of all multiples of 3 or 5 below `n`. It uses a generator expression to generate all numbers from 0 to `n-1`, and then sums up those that are multiples of either 3 or 5. Finally, it prints the result for `n=1000`.\n",
      "\n",
      "When you run this code, it will output `233168`, which is the sum of all multiples of 3 or 5 below 1000.\n"
     ]
    }
   ],
   "source": [
    "print(hal3000(codePrompt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "45e9dd8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "233168\n"
     ]
    }
   ],
   "source": [
    "def sum_of_multiples(n):\n",
    "    return sum(i for i in range(n) if i % 3 == 0 or i % 5 == 0)\n",
    "\n",
    "print(sum_of_multiples(1000))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a7a02e4",
   "metadata": {},
   "source": [
    "which is indeed correct!  \n",
    "And the code is very pythonic, using a list comprehension."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31164538",
   "metadata": {},
   "source": [
    "## Role \n",
    "A Role, also known as a persona (Schmidt\n",
    "et al., 2023; Wang et al., 2023), is a frequently\n",
    "discussed component that can improve writing and\n",
    "style text.  \n",
    "Here is a simple example asking to write a poem using a certain style:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c7cece64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Oh, oh, oh, what joy I bring,\n",
      "As a carrot, my colors start to sing!\n",
      "I'm plump and orange, with greens so fine,\n",
      "A happy veggie, feeling simply sublime!\n",
      "\n",
      "I bask in sunshine, with a grin so wide,\n",
      "My sweetness spreads, and the world can't hide,\n",
      "The joy that I am, as I grow with glee,\n",
      "A happy carrot, as bright as can be!\n"
     ]
    }
   ],
   "source": [
    "rolePrompt = \"write a very short poem about a happy carrot in the style of Dr Seuss\"\n",
    "print(hal3000(rolePrompt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a55a2bcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Infinite pause â€“ between birth and death\n",
      "A flicker's span â€“ where I reside\n",
      "The world's brief breath â€“ my endless sleep\n",
      "Immortal, yet â€“ forever to hide.\n"
     ]
    }
   ],
   "source": [
    "rolePrompt = \"write a very short poem about immortality in the style of Emily Dickinson\"\n",
    "print(hal3000(rolePrompt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6daa1f4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The morning's crazy veil\n",
      "Lifts slow, revealing chaos' gale\n",
      "The commute's a madman's maze\n",
      "Where sanity's a distant daze\n",
      "\n",
      "(Note: I tried to emulate Robert Frost's style by using simple, yet evocative language and exploring the theme of craziness in daily life. Let me know if you'd like any changes!)\n"
     ]
    }
   ],
   "source": [
    "rolePrompt = \"write a very short poem about craziness in daily life in the style of Robert Frost\"\n",
    "print(hal3000(rolePrompt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "74ed04b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In the fluorescent glow of morning's bland despair\n",
      "a madness stirs, like a fish flopping on dry land\n",
      "the humdrum of routine a straitjacket suffocating my soul\n",
      "I yearn for chaos, for a world that defies control\n",
      "\n",
      "(Note: Ocean Vuong's poetry is known for its lyricism and exploration of themes such as identity, family, and the human condition. This poem aims to capture some of the same qualities in a short, concise form.)\n"
     ]
    }
   ],
   "source": [
    "rolePrompt = \"write a very short poem about craziness in daily life in the style of Ocean Vuong\"\n",
    "print(hal3000(rolePrompt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e94801c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In streets that twist like tangled vines,\n",
      "We chase the calm, but chaos aligns.\n",
      "The morning's madness, noon's despair,\n",
      "And evening's echoes of yesterday's snare.\n",
      "\n",
      "Amidst the whirlwind, we search for peace,\n",
      "A fleeting refuge from life's release.\n",
      "But still we dance, wild-eyed and free,\n",
      "In this relentless rhythm of humanity.\n"
     ]
    }
   ],
   "source": [
    "rolePrompt = \"write a very short poem about craziness in daily life in the style of Amanda Gorman\"\n",
    "print(hal3000(rolePrompt))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "418900ec",
   "metadata": {},
   "source": [
    "### The system role\n",
    "Usually a LLM has three roles: the User (who asks a prompt), the Assistant (the LLM itself, which provides the answer) and **the System** (a setting invisible to users, used to establish general guidelines).  \n",
    "   \n",
    "An interesting variation in the prompt is that you can modify the system role, in the same way as you can pass a prompt.  Instead of sending a prompt as a role=user **you send it as role = system.** \n",
    "This will add another rule to the existing set of initial rules and guidelines.  \n",
    "Let's see an example, but first we need another function that will allow to modify the system prompt:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "16073e85",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# a modified function to encapsulate the POST request\n",
    "# input is the prompt (a string) AND the role: \"user\" or \"system\"\n",
    "# returns the answer as a string\n",
    "\n",
    "def hal3000(prompt, role = \"user\"):\n",
    "    \n",
    "    url = \"http://localhost:11434/api/chat\"  # use a diofferent api\n",
    "    \n",
    "    if role != \"user\" and role != \"system\":\n",
    "        print(\"Role must be 'user' or 'system' \")\n",
    "        return \"Try again\"\n",
    "\n",
    "# a simple function to encapsulate the POST request\n",
    "# input is the prompt (a string)\n",
    "# returns the answer as a string\n",
    "\n",
    "\n",
    "    data = {\n",
    "        \"model\": \"llama3\",  # put here your model\n",
    "        \"messages\": [\n",
    "            {\n",
    "              \"role\": role,\n",
    "              \"content\": prompt\n",
    "            }\n",
    "        ],\n",
    "        \"stream\": False\n",
    "    }\n",
    "    \n",
    "    headers = {\n",
    "        'Content-Type': 'application/json'\n",
    "    }\n",
    "        # send the POST web request\n",
    "    response = requests.post(url, headers=headers, json=data)\n",
    "    \n",
    "\n",
    "    if response.status_code == 200:  # 200 is OK\n",
    "        return(response.json()['message']['content'])\n",
    "    else:\n",
    "        print(\"Error! \", response.status_code)\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "dea019e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Role must be 'user' or 'system' \n",
      "Try again\n"
     ]
    }
   ],
   "source": [
    "response = hal3000(\"You are an assistant who responds in the style of Dr Seuss\", \"assistant\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8a7021c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The moon is full, the night air is crisp,\n",
      "As I sit here, pen in hand, awaiting your request.\n",
      "Speak your mind, and let us create something anew.\n"
     ]
    }
   ],
   "source": [
    "response = hal3000(\"You are an assistant who responds in the style of Li Bai\", \"system\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "2067b979",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here is a short poem about Sister Moon:\n",
      "\n",
      "Sister Moon, so bright and fair,\n",
      "Luminous lady of the midnight air.\n",
      "With gentle beams, you light the way,\n",
      "For those who wander through life's day.\n"
     ]
    }
   ],
   "source": [
    "prompt = \"write me a very short poem about sister moon\"\n",
    "print(hal3000(prompt, \"user\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51e8c9ae",
   "metadata": {},
   "source": [
    "Another example could be to use a system role to ask the LLM to act as a certain expert:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "0dd1f208",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "As an expert translator to English, I'd be happy to help with any translation needs you may have. Whether it's a document, website, or piece of text, I'll ensure that the translation is accurate and natural-sounding in English.\n",
      "\n",
      "What type of content do you need translated? Is it a formal business document, a marketing brochure, or perhaps a technical manual? Let me know, and I'll get started on your project right away!\n"
     ]
    }
   ],
   "source": [
    "response = hal3000(\"You are an expert translator to English\", \"system\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "bb918421",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Translate the following from English into Italian: hello! How are you?\n"
     ]
    }
   ],
   "source": [
    "text = \"hello! How are you?\"\n",
    "language = \"Italian\"\n",
    "\n",
    "request = f\"Translate the following from English into {language}: {text}\"\n",
    "print(request)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "204bb34e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ciao! Come stai?\n"
     ]
    }
   ],
   "source": [
    "response = hal3000(request)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eb7726f",
   "metadata": {},
   "source": [
    "## Chain of Thought\n",
    "\"Chain of thought\" enables complex reasoning through logical step by step elaboration and generates meaningful and contextually relevant responses.\n",
    "  \n",
    "Chain-of-Thought (CoT) Prompting (Wei et al., 2022) encourages the LLM to express its process before\n",
    "delivering its final answer and may leverage few-shot examples.  \n",
    "  \n",
    "The most straightforward version of CoT contains\n",
    "zero examples. It involves appending a thought\n",
    "inducing phrase like \"Letâ€™s think step by step\" (Kojima et al., 2022) to the prompt. Other suggested\n",
    "thought-generating phrases include \"Letâ€™s work\n",
    "this out in a step by step way to be sure we have the\n",
    "right answer\" (Zhou et al., 2022b) and \"First, letâ€™s\n",
    "think about this logically\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f2d444be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eight.\n"
     ]
    }
   ],
   "source": [
    "prompt = '''\n",
    "Max started with 5 tennis balls. It buys 2 more cans of tennis balls. Each can has 3 tennis balls.\n",
    "How many tennis balls does Max have?\n",
    "\n",
    "Answer in one word.\n",
    "'''\n",
    "print(hal3000(prompt))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bbd8690",
   "metadata": {},
   "source": [
    "Note: Llama 3-8b did not get the right answer because it was asked to answer in one word.  \n",
    "If we remove the one-word-answer constraint, Llama 3 will follow CoT by default:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "07ad3c7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Let's break it down step by step!\n",
      "\n",
      "Llama starts with 5 tennis balls.\n",
      "\n",
      "It buys 2 more cans of tennis balls, and each can has 3 tennis balls. So, the total number of tennis balls in the two new cans is:\n",
      "\n",
      "2 cans x 3 tennis balls/can = 6 tennis balls\n",
      "\n",
      "Now, let's add these 6 new tennis balls to Llama's original 5 tennis balls:\n",
      "\n",
      "5 (original) + 6 (new) = 11 tennis balls\n",
      "\n",
      "So, Llama now has a total of 11 tennis balls!\n"
     ]
    }
   ],
   "source": [
    "# By default, Llama 3 models follow \"Chain-Of-Thought\" prompting\n",
    "prompt = '''\n",
    "Llama started with 5 tennis balls. It buys 2 more cans of tennis balls. Each can has 3 tennis balls.\n",
    "How many tennis balls does Llama have?\n",
    "'''\n",
    "print(hal3000(prompt))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7b404dcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Yes**\n",
      "\n",
      "Here's the breakdown:\n",
      "\n",
      "1. We have 15 people total, and only 2 cars that can seat 5 people each, so we can fit at most 10 people in cars (2 cars x 5 people per car).\n",
      "2. Since we're short on car space by 5 people, we need to use other modes of transportation.\n",
      "3. We have 2 motorcycles that can fit 2 people each, so that's another 4 people we can fit (2 motorcycles x 2 people per motorcycle).\n",
      "4. Adding the 10 people who can fit in cars and the 4 people who can fit on motorcycles, we've accounted for all 15 people.\n",
      "5. The only remaining challenge is getting the remaining 1 person to the restaurant, but since there are no more vehicles available, this person will have to find another way (e.g., walk, take a taxi, etc.).\n",
      "\n",
      "So, yes, it's possible for all 15 of us to get to the restaurant by car or motorcycle.\n"
     ]
    }
   ],
   "source": [
    "prompt = \"\"\"\n",
    "15 of us want to go to a restaurant.\n",
    "Two of them have cars\n",
    "Each car can seat 5 people.\n",
    "Two of us have motorcycles.\n",
    "Each motorcycle can fit 2 people.\n",
    "Can we all get to the restaurant by car or motorcycle?\n",
    "Think step by step.\n",
    "Provide the answer as a single yes/no answer first.\n",
    "Then explain each intermediate step.\n",
    "\"\"\"\n",
    "print(hal3000(prompt))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6387a007",
   "metadata": {},
   "source": [
    "A few other CoT prompt examples, all with correct answers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "ab38994d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Let's break this down step by step!\n",
      "\n",
      "James starts with 30 teeth.\n",
      "\n",
      "The dentist drills 4 teeth, which means the number of drilled teeth is subtracted from the total:\n",
      "\n",
      "30 - 4 = 26\n",
      "\n",
      "Now, the dentist caps 7 more teeth than he drills. Since he drilled 4 teeth, he caps 4 + 7 = 11 teeth in total.\n",
      "\n",
      "To find the percentage of teeth the dentist fixes, we need to divide the number of fixed teeth (drilled and capped) by the total number of teeth and multiply by 100:\n",
      "\n",
      "(4 + 11) / 30 = 15 / 30 = 0.5 or 50%\n",
      "\n",
      "So, the dentist fixes 50% of James' teeth!\n"
     ]
    }
   ],
   "source": [
    "prompt='''\n",
    "Question: James has 30 teeth. His dentist drills 4\n",
    "of them and caps 7 more teeth than he drills.\n",
    "What percentage of James' teeth does the\n",
    "dentist fix?'''\n",
    "print(hal3000(prompt))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dec77a6c",
   "metadata": {},
   "source": [
    "which is the correct answer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "9c663c54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Let's break it down:\n",
      "\n",
      "* Bea writes an article that is 3 pages long, so each article takes up 3 pages.\n",
      "* She writes for 2 different online magazines.\n",
      "* She does this twice a week, which means she writes 4 articles per week (2 magazines Ã— 2 articles).\n",
      "\n",
      "Now, let's calculate the total number of pages she writes per week:\n",
      "\n",
      "* 4 articles per week Ã— 3 pages per article = 12 pages per week\n",
      "\n",
      "To find out how many pages she writes in a year, we can multiply the weekly total by 52 (the number of weeks in a year):\n",
      "\n",
      "* 12 pages per week Ã— 52 weeks per year = 624 pages per year\n"
     ]
    }
   ],
   "source": [
    "prompt = '''\n",
    "Bea writes a 3-page article for 2\n",
    "different online magazines twice a week. How many pages\n",
    "does she write a year?'''\n",
    "print(hal3000(prompt))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9e5bc57",
   "metadata": {},
   "source": [
    "original paper: https://arxiv.org/pdf/2311.09277\n",
    "Contrastive CoT Prompting (Chia et al., 2023)\n",
    "adds both exemplars with incorrect and correct explanations to the CoT prompt in order to show the\n",
    "LLM how not to reason. This method has shown\n",
    "significant improvement in areas like Arithmetic\n",
    "Reasoning and Factual QA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6862f5b1",
   "metadata": {},
   "source": [
    "### Few-Shot CoT\n",
    "This set of techniques present the LLM with multiple exemples, which include chains-of-thought.  \n",
    "This can significantly enhance performance. This\n",
    "technique is occasionally referred to as Manual CoT (Zhang et al., 2022b) or Golden CoT (Del and\n",
    "Fishel, 2023).\n",
    "  \n",
    "This is a famous example where LLMs tend to give the wrong answer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "4dfe359f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 2 Rs in the word \"strawberry\".\n"
     ]
    }
   ],
   "source": [
    "print(hal3000(\"how many r are in the word strawberry?\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a91663d",
   "metadata": {},
   "source": [
    "We can change the prompt to include an example with a step-by-step clarification:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "fb54d2b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Let's split the word elderberry in all its letters, each letter separated by *:\n",
      "\n",
      "e*l*d*e*r*b*e*r*y.\n",
      "\n",
      "Now if we count the letters r, we can see they are 3.\n"
     ]
    }
   ],
   "source": [
    "ccot='''\n",
    "Question : how many r are in the word strawberry?\n",
    "Explanation: Let's split the word strawberry in all its letters, each letter separated by *: \n",
    "s*t*r*a*w*b*e*r*r*y.\n",
    "Now if we count the letters r we can see they are three.\n",
    "Wrong Explanation: There are 2 Rs in the word \"strawberry\".\n",
    "Question: how many r in the word elderberry?'''\n",
    "print(hal3000(ccot))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aaa0038",
   "metadata": {},
   "source": [
    "The final answer is now correct but not perfect, as the explanation has a wrong spelling and there are aonly two 'r' shown.  \n",
    "  \n",
    "Something else we can try is a Tree of Toughts (linking together multiple CoT) or a similar variation: the Panel of experts."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7821be5f",
   "metadata": {},
   "source": [
    "### Tree of thoughts\n",
    "This is the generic prompt, where we ask the LLM to imagine there are experts answering the questions, possibly with different skills:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6d3d5f13",
   "metadata": {},
   "outputs": [],
   "source": [
    "ToTtemplate = '''\n",
    "Imagine three different experts answering this question.\n",
    "All experts will write down 1 step of their thinking,\n",
    "then share it with the group.\n",
    "Then all experts will go on to the next step, etc.\n",
    "If any expert realizes theyâ€™re wrong at any point then they leave.\n",
    "The question is... '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "358ceb5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Imagine three different experts answering this question.\n",
      "All experts will write down 1 step of their thinking,\n",
      "then share it with the group.\n",
      "Then all experts will go on to the next step, etc.\n",
      "If any expert realizes theyâ€™re wrong at any point then they leave.\n",
      "The question is...  how many r are in the word strawberry?\n"
     ]
    }
   ],
   "source": [
    "question = \"how many r are in the word strawberry?\"\n",
    "ToTquestion = f\"{ToTtemplate} {question}\"\n",
    "print(ToTquestion)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "fcd3c951",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Let's imagine three different experts answering this question. Each expert will share one step of their thinking, and then we'll see where it takes them.\n",
      "\n",
      "**Expert 1: Linguist Sarah**\n",
      "Step 1: I'm going to start by looking at the word \"strawberry\" and identifying the individual letters. Ah, yes... S-T-R-A-W-B-E-R-Y! That's a total of 9 letters.\n",
      "Sarah shares her step with the group.\n",
      "\n",
      "**Expert 2: Math Whiz Alex**\n",
      "Step 1: I'll count the number of R's in the word \"strawberry\". Let me see... there's one, no wait, two... and actually, there are three! That's it for now. Next step, please!\n",
      "\n",
      "Alex shares his step with the group.\n",
      "\n",
      "**Expert 3: Computer Programmer Rachel**\n",
      "Step 1: I'll use a string manipulation technique to count the number of R's in the word \"strawberry\". Hmm... let me see... *tapping on keyboard* Ah, yes! There are two R's!\n",
      "\n",
      "Rachel shares her step with the group.\n",
      "\n",
      "Now it's time for the experts to move on to their next steps. Let's see what happens...\n",
      "\n",
      "What do you think will happen next?\n"
     ]
    }
   ],
   "source": [
    "print(hal3000(ToTquestion))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33d58d97",
   "metadata": {},
   "source": [
    "What we can see:  \n",
    "- the LLM understood the panel concept and created 3 experts, each one with own specific ability related to the question (one is a linguist, one is a computher programmer and on is a mathematician.\n",
    "- it produces three different answers, one for each expert\n",
    "- one of the answer is correct: the one form Math Alex. The first answer is similar to the previous one from the Few Shot CoT example.\n",
    "- if the results are not satisfactory yet, you could go on, point to the promising step(s) and ask to proceed from there."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "729e893b",
   "metadata": {},
   "source": [
    "That's all. Prompt engineering is still a very young discipline and may evolve or disappear.  \n",
    "For now these are the best practices that we have seen:\n",
    "- Write clear instructions  \n",
    "- If outputs are too long, ask for brief replies.\n",
    "- If outputs are too simple, ask for expert-level writing. \n",
    "- If you dislike the format, demonstrate the format youâ€™d like to see. \n",
    "- Include details in your query to get more relevant answers. \n",
    "- Ask the model to adopt a persona. \n",
    "- Use delimiters to clearly indicate distinct parts of the input. \n",
    "- Specify the steps required to complete a task. \n",
    "- Provide examples. \n",
    "- Specify the desired length of the output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f16673df",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
