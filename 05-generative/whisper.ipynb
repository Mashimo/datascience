{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Audio transcription\n",
    "Whisper is an open-source speech recognition model [developed by OpenAI](https://openai.com/research/whisper)\n",
    "\n",
    "Here we can see how to use it convert an audio into text, a good example of the potentiality of the Large Language Models, neural networks trained on huge amount of text and audio.\n",
    "\n",
    "The model can be installed directly from GitHub:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install git+https://github.com/openai/whisper.git -q\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting numpy==1.24\n",
      "  Using cached numpy-1.24.0-cp311-cp311-macosx_11_0_arm64.whl (13.8 MB)\n",
      "Installing collected packages: numpy\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.24.0\n",
      "    Uninstalling numpy-1.24.0:\n",
      "      Successfully uninstalled numpy-1.24.0\n",
      "Successfully installed numpy-1.24.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install --force-reinstall \"numpy==1.24\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.24.0\n"
     ]
    }
   ],
   "source": [
    "import numpy\n",
    "print (numpy.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: install also ffmpeg (just need to copy the exe file) and add it in the PATH\n",
    "This is needed by the model to convert audio/video formats (i.e. you could give as input a file video and it will extract the audio component). \n",
    "\n",
    "On Mac: copy it to /usr/local/bin, verify it's working with the command \"which ffmpeg\"\n",
    "It might also be necessary to open it once so mac os will add an exception and notes that you trust it even if it's an appliccation from unidentified developer\n",
    "\n",
    "## Import module and language model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import whisper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model supports multiple languages and can also do language identification.\n",
    "\n",
    "There are five model sizes, from tiny to large, offering speed and accuracy tradeoffs. Each size can support   English-only or multiple model.\n",
    "I use the medium version for multiple languages which has around 770M parameters and requires 5GB VRAM.\n",
    "The large versione is double that.\n",
    "\n",
    "The models are trained on 680,000 hours of audio and the corresponding transcripts collected from the internet. 65% of this data represents English-language audio and matched English transcripts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sizeMmodel = whisper.load_model(\"medium\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transcribe with a single line\n",
    "\n",
    "I try first with a short audio of news in Italian language:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Massimo/anaconda3/envs/ML/lib/python3.11/site-packages/whisper/transcribe.py:114: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
     ]
    }
   ],
   "source": [
    "transcriptionIT = sizeMmodel.transcribe(\"NotizieIT.mp3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, the only required function parameter is the audio file path and name, not the language.\n",
    "The conversione did not overload the cpu nor the memory, I could easily do something else in the meanwhile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" Notizie flash Una delegazione della Commissione Affari Esteri conclude oggi la sua visita in Cile. I deputati hanno discusso con le autorità del Paese, con i rappresentanti della società civile, del rafforzamento del partenariato tra Unione Europea e America Latina. Domani gli eurodeputati si ericheranno in Brasile per il rilancio delle relazioni col Paese, per discutere della posizione del Brasile sulla guerra russa e della lotta contro l'incambiamento climatico e la deforestazione. La presidente del Parlamento Europeo, Roberta Mezzola, è a Zagabria. Ieri ha incontrato il Primo Ministro croato Andrei Plenkovic e ha partecipato a una conferenza sui 10 anni di adesione della Croazia all'Unione Europea, oltre che a un evento con i giovani. Oggi Mezzola parlerà al Parlamento Croato e domani la presidente sarà invece a Londra per partecipare alla conferenza sulla ripresa dell'Ucraina e per pronunciare a Westminster un discorso programmatico all'evento parlamentare della conferenza. Una delegazione della Commissione Cultura e Istruzione è in Scozia. Gli eurodeputati stanno discutendo della potenziale cooperazione nei settori dell'istruzione, della cultura, dei giovani e dello sport dopo la Brexit. A Edimburgo esaminaranno in particolare le possibilità di continuare la mobilità tra Scozia e Unione Europea nell'ambito del programma Erasmus Plus, la visita si concluderà domani.\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#printing the transcribe\n",
    "transcriptionIT['text']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And here is a Chinese audio:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Massimo/anaconda3/lib/python3.11/site-packages/whisper/transcribe.py:114: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
     ]
    }
   ],
   "source": [
    "transcriptionCH = sizeMmodel.transcribe(\"../../../../Downloads/5-6-1.mp3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'5. 根据课文2,做下面的练习。课文2 李美丽和山田佑对话。山田佑,你怎么买了这么多衣服?我听说这儿冬天特别冷。你看,我买了一件羽绒服,两件毛衣,两条厚裤子。是不是因为便宜啊?不是,这儿一到十一月就冷了,只穿一条裤子,一定不行。是吗?对,病了要吃药,看病要花钱,还不舒服,所以还是多穿衣服好。今天出租车司机告诉我的,我觉得对。1. 选择正确答案。1. 山田佑没买什么东西。2. 山田佑为什么买这么多衣服?3. 山田佑为什么觉得多穿衣服好?2. 边听录音,边填空,然后朗读。1. 你怎么买了这么多衣服?2. 我买了一件羽绒服,两件毛衣,两条厚裤子。3. 是不是因为便宜啊?4. 这儿一到十一月就冷了,只穿一条裤子,一定不行。'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#printing the transcribe\n",
    "transcriptionCH['text']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It worked perfectly for both languages. Even better that commercial products. Speed was more or less 2x the audio total time\n",
    "\n",
    "I tried also a 20 minutes video in German language and extracted perfectly its audio too.\n",
    "And all this with the medium size, not even the large one.\n",
    "Although hallucinations are possible.\n",
    "\n",
    "## Detect language\n",
    "\n",
    "The function _detect_language()_ will examine the audio and outputs the probability for all supported languages (around one hundred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Failed to load audio: ffmpeg version 6.0-tessus  https://evermeet.cx/ffmpeg/  Copyright (c) 2000-2023 the FFmpeg developers\n  built with Apple clang version 11.0.0 (clang-1100.0.33.17)\n  configuration: --cc=/usr/bin/clang --prefix=/opt/ffmpeg --extra-version=tessus --enable-avisynth --enable-fontconfig --enable-gpl --enable-libaom --enable-libass --enable-libbluray --enable-libdav1d --enable-libfreetype --enable-libgsm --enable-libmodplug --enable-libmp3lame --enable-libmysofa --enable-libopencore-amrnb --enable-libopencore-amrwb --enable-libopenh264 --enable-libopenjpeg --enable-libopus --enable-librubberband --enable-libshine --enable-libsnappy --enable-libsoxr --enable-libspeex --enable-libtheora --enable-libtwolame --enable-libvidstab --enable-libvmaf --enable-libvo-amrwbenc --enable-libvorbis --enable-libvpx --enable-libwebp --enable-libx264 --enable-libx265 --enable-libxavs --enable-libxvid --enable-libzimg --enable-libzmq --enable-libzvbi --enable-version3 --pkg-config-flags=--static --disable-ffplay\n  libavutil      58.  2.100 / 58.  2.100\n  libavcodec     60.  3.100 / 60.  3.100\n  libavformat    60.  3.100 / 60.  3.100\n  libavdevice    60.  1.100 / 60.  1.100\n  libavfilter     9.  3.100 /  9.  3.100\n  libswscale      7.  1.100 /  7.  1.100\n  libswresample   4. 10.100 /  4. 10.100\n  libpostproc    57.  1.100 / 57.  1.100\n21-6-2.mp3: No such file or directory\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mCalledProcessError\u001b[0m                        Traceback (most recent call last)",
      "File \u001b[0;32m~/anaconda3/envs/ML/lib/python3.11/site-packages/whisper/audio.py:59\u001b[0m, in \u001b[0;36mload_audio\u001b[0;34m(file, sr)\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 59\u001b[0m     out \u001b[38;5;241m=\u001b[39m run(cmd, capture_output\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, check\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\u001b[38;5;241m.\u001b[39mstdout\n\u001b[1;32m     60\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m CalledProcessError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/anaconda3/envs/ML/lib/python3.11/subprocess.py:571\u001b[0m, in \u001b[0;36mrun\u001b[0;34m(input, capture_output, timeout, check, *popenargs, **kwargs)\u001b[0m\n\u001b[1;32m    570\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m check \u001b[38;5;129;01mand\u001b[39;00m retcode:\n\u001b[0;32m--> 571\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m CalledProcessError(retcode, process\u001b[38;5;241m.\u001b[39margs,\n\u001b[1;32m    572\u001b[0m                                  output\u001b[38;5;241m=\u001b[39mstdout, stderr\u001b[38;5;241m=\u001b[39mstderr)\n\u001b[1;32m    573\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m CompletedProcess(process\u001b[38;5;241m.\u001b[39margs, retcode, stdout, stderr)\n",
      "\u001b[0;31mCalledProcessError\u001b[0m: Command '['ffmpeg', '-nostdin', '-threads', '0', '-i', '21-6-2.mp3', '-f', 's16le', '-ac', '1', '-acodec', 'pcm_s16le', '-ar', '16000', '-']' returned non-zero exit status 1.",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[34], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m audio \u001b[38;5;241m=\u001b[39m whisper\u001b[38;5;241m.\u001b[39mload_audio(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m21-6-2.mp3\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/ML/lib/python3.11/site-packages/whisper/audio.py:61\u001b[0m, in \u001b[0;36mload_audio\u001b[0;34m(file, sr)\u001b[0m\n\u001b[1;32m     59\u001b[0m     out \u001b[38;5;241m=\u001b[39m run(cmd, capture_output\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, check\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\u001b[38;5;241m.\u001b[39mstdout\n\u001b[1;32m     60\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m CalledProcessError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m---> 61\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to load audio: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;241m.\u001b[39mstderr\u001b[38;5;241m.\u001b[39mdecode()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39mfrombuffer(out, np\u001b[38;5;241m.\u001b[39mint16)\u001b[38;5;241m.\u001b[39mflatten()\u001b[38;5;241m.\u001b[39mastype(np\u001b[38;5;241m.\u001b[39mfloat32) \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m32768.0\u001b[39m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Failed to load audio: ffmpeg version 6.0-tessus  https://evermeet.cx/ffmpeg/  Copyright (c) 2000-2023 the FFmpeg developers\n  built with Apple clang version 11.0.0 (clang-1100.0.33.17)\n  configuration: --cc=/usr/bin/clang --prefix=/opt/ffmpeg --extra-version=tessus --enable-avisynth --enable-fontconfig --enable-gpl --enable-libaom --enable-libass --enable-libbluray --enable-libdav1d --enable-libfreetype --enable-libgsm --enable-libmodplug --enable-libmp3lame --enable-libmysofa --enable-libopencore-amrnb --enable-libopencore-amrwb --enable-libopenh264 --enable-libopenjpeg --enable-libopus --enable-librubberband --enable-libshine --enable-libsnappy --enable-libsoxr --enable-libspeex --enable-libtheora --enable-libtwolame --enable-libvidstab --enable-libvmaf --enable-libvo-amrwbenc --enable-libvorbis --enable-libvpx --enable-libwebp --enable-libx264 --enable-libx265 --enable-libxavs --enable-libxvid --enable-libzimg --enable-libzmq --enable-libzvbi --enable-version3 --pkg-config-flags=--static --disable-ffplay\n  libavutil      58.  2.100 / 58.  2.100\n  libavcodec     60.  3.100 / 60.  3.100\n  libavformat    60.  3.100 / 60.  3.100\n  libavdevice    60.  1.100 / 60.  1.100\n  libavfilter     9.  3.100 /  9.  3.100\n  libswscale      7.  1.100 /  7.  1.100\n  libswresample   4. 10.100 /  4. 10.100\n  libpostproc    57.  1.100 / 57.  1.100\n21-6-2.mp3: No such file or directory\n"
     ]
    }
   ],
   "source": [
    "audio = whisper.load_audio(\"21-6-2.mp3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio = whisper.pad_or_trim(audio)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make log-Mel spectrogram and move to the same device as the model\n",
    "mel = whisper.log_mel_spectrogram(audio).to(sizeMmodel.device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# detect the spoken language\n",
    "_, probs = sizeMmodel.detect_language(mel)  # probs is a dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'zh'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(probs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "keys are a two-letters symbol for language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9969410300254822"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs['zh']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ZH is Chinese. The model predicted it with 99.7% probability\n",
    "\n",
    "## Translate\n",
    "\n",
    "The model can also translate into English during the transcription.\n",
    "Just call the _transcribe()_ function passing a task to translate:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Massimo/anaconda3/lib/python3.11/site-packages/whisper/transcribe.py:114: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
     ]
    }
   ],
   "source": [
    "transcriptionEN = sizeMmodel.transcribe(\"../../../../Downloads/5-6-1.mp3\", task=\"translate\") # Default is transcribe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" Short text one I am listening to the recording. Today, when we were listening to the Chinese class, the teacher played a recording. I listened to it twice and didn't understand it. I plan to listen to it again after I go home. In the afternoon, when I was listening to the CD, my brother suddenly came in from outside. I took off my earphone and asked him what was wrong. He said that his father bought him a CD from the bookstore. There is a very nice song in it. Ask me if I want to listen. I said I was listening to the recording. My brother looked at me and didn't talk. He closed the door and left. After he left, I listened again. But some sentences still didn't understand. At this time, my brother came in again and said, Brother, can you listen to this song? It's very nice. I said, don't talk to me. I don't understand some sentences. My brother said, it's really nice. Listen to it. You can understand it when you listen to it. 1. According to the short text, choose the right answer. 1. What language do I study? 2. Who bought my brother a plate of mp3? 3. What did my brother come in for?\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transcriptionEN['text']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The translation is also quite good: maybe only _self-serve meal_ would be better as _buffet_ :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
