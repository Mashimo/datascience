{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensors introduction\n",
    "One of the data types introduced by most deep learning frameworks such as Tensorflow or PyTorch is the **tensor**.  \n",
    "  \n",
    "From a Computer Science perspective tensors are multi-dimensional arrays plus a number of basic operations on them that have turned out to be very useful in a lot of applications.\n",
    "\n",
    "A tensor is nearly the same thing as a NumPy array, but with an additional restriction that unlocks some additional capabilities. It's the same in that it, too, is a multidimensional table of data, with all items of the same type. However, the restriction is that a tensor cannot use just any type — it has to use a single basic numeric type for all components. For example, a PyTorch tensor cannot be jagged. It is always a regularly shaped multidimensional rectangular structure.  \n",
    "  \n",
    "One major capability is that these structures can live on the GPU, in which case their computation will be optimized for the GPU and can run much faster.  \n",
    "In this sense, PyTorch or Tensorflow can be seen as a replacement for NumPy to use the power of GPUs.  \n",
    "  \n",
    "PyTorch interface has been created to be as much as possible similar to the Numpy's one. Let's see more in details what are the tensors (specifically the PyTorch tensors) and the similarities with the NumPy arrays.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.1\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "you can check whether your installation recognizes your built-in NVIDIA GPU by running the following code in Python:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensor creation\n",
    "A NumPy array is a multidimensional table of data, with all items of the same type.  \n",
    " By \"multidimensional table\" we mean, for instance, a list (dimension of one), a table or matrix (dimension of two), a \"table of tables\" or \"cube\" (dimension of three), and so forth. If the items are all of some simple type such as integer or float, then NumPy will store them as a compact C data structure in memory. This is where NumPy shines. NumPy has a wide variety of operators and methods that can run computations on these compact structures at the same speed as optimized C, because they are written in optimized C.  \n",
    "  \n",
    "Tensors are simply regularly shaped arrays—for example, a matrix. Matrices have rows and columns; we call these the axes or dimensions. The number of dimensions of a tensor is its rank:\n",
    "  \n",
    "Rank zero: scalar  \n",
    "Rank one: vector  \n",
    "Rank two: matrix  \n",
    "  \n",
    "To create a tensor - same way as for an array - pass a list (or list of lists, or list of lists of lists, etc.) to tensor():  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a 0D tensor (scalar) from a Python integer\n",
    "tensor0d = torch.tensor(1)\n",
    "tensor0d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A one dimension tensor is basically like a numpy array:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a 1D tensor (vector) from a Python list\n",
    "tensor1d = torch.tensor([1, 2, 3])\n",
    "\n",
    "tensor1d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 3])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simple_array = np.array ([1,2,3]) # NumPy array\n",
    "simple_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor1d == simple_array  # still they are different data structures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The types are different: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Array Type: <class 'numpy.ndarray'>\n",
      "Array data type: int64\n",
      "Array Shape: (3,)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Array Type: {type(simple_array)}\") # type\n",
    "print(f\"Array data type: {simple_array.dtype}\") \n",
    "print(f\"Array Shape: {np.shape(simple_array)}\") # shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor Type: torch.LongTensor\n",
      "Tensor data type: torch.int64\n",
      "Tensor Shape: torch.Size([3])\n"
     ]
    }
   ],
   "source": [
    "print(f\"Tensor Type: {tensor1d.type()}\") # type\n",
    "print(f\"Tensor data type: {tensor1d.dtype}\") \n",
    "print(f\"Tensor Shape: {tensor1d.shape}\") # shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And a rank two tensor is like a numpy matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2],\n",
       "        [3, 4]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a 2D tensor from a nested Python list\n",
    "tensor2d = torch.tensor([[1, 2], [3, 4]])\n",
    "tensor2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 2],\n",
       "       [3, 4]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "    # NumPy matrix\n",
    "matrix = np.array ([[1, 2], [3, 4]])\n",
    "matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Difference in creation type\n",
    "Note that there is a difference in the creation API *tensor* versus *Tensor*.  \n",
    "A tensor infers the dtype automatically, while torch.Tensor (note the capital letter) returns an empty tensor without any data, and if you pass some data, it will convert into a torch.FloatTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 3],\n",
       "        [4, 5, 6]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = [[1,2,3],[4,5,6]] # a list of lists\n",
    "\n",
    "    # create a 3D tensor from a nested Python list\n",
    "tensorAsInt = torch.tensor(data)\n",
    "tensorAsInt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 2., 3.],\n",
       "        [4., 5., 6.]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensorAsFloat = torch.Tensor(data)\n",
    "tensorAsFloat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensorWithoutData = torch.Tensor()\n",
    "tensorWithoutData"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "torch.tensor is simply a better API and has an optional parameter to change the dtype  \n",
    "  \n",
    "### Create from array\n",
    "I can also create a tensor from a numpy array:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [[[1, 2], [3, 4]], [[5, 6], [7, 8]]]\n",
    "# create a 3D tensor from a nested Python list\n",
    "tensor3d_A = torch.tensor(data)\n",
    "\n",
    "# create a 3D tensor from NumPy array\n",
    "ary3d = np.array(data)\n",
    "tensor3d_B = torch.tensor(ary3d)  # Copies NumPy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1, 2],\n",
       "         [3, 4]],\n",
       "\n",
       "        [[5, 6],\n",
       "         [7, 8]]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor3d_A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1, 2],\n",
       "         [3, 4]],\n",
       "\n",
       "        [[5, 6],\n",
       "         [7, 8]]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor3d_B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[True, True],\n",
       "         [True, True]],\n",
       "\n",
       "        [[True, True],\n",
       "         [True, True]]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor3d_A == tensor3d_B"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conversion array - tensor\n",
    "It is possible to convert from array to tensors and viceversa:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'> [[0.9453812  0.71919377]\n",
      " [0.21445788 0.80011854]]\n",
      "\n",
      "tensor([[0.9454, 0.7192],\n",
      "        [0.2145, 0.8001]], dtype=torch.float64)\n",
      "\n",
      "<class 'numpy.ndarray'> [[0.9453812  0.71919377]\n",
      " [0.21445788 0.80011854]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# random numpy array\n",
    "array = np.random.rand(2,2)\n",
    "print(f\"{type(array)} {array}\\n\")\n",
    "\n",
    "# from numpy to tensor\n",
    "from_numpy_to_tensor = torch.from_numpy(array)\n",
    "print(f\"{from_numpy_to_tensor}\\n\")\n",
    "\n",
    "# from tensor to numpy\n",
    "tensor = from_numpy_to_tensor\n",
    "from_tensor_to_numpy = tensor.numpy()\n",
    "print(f\"{type(from_tensor_to_numpy)} {from_tensor_to_numpy}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 3],\n",
       "        [4, 5, 6]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = [[1,2,3],[4,5,6]] # a list of lists\n",
    "\n",
    "    # create a 3D tensor from a nested Python list\n",
    "tensor3d = torch.tensor(data)\n",
    "tensor3d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix = np.array (data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 2.,  4.,  6.],\n",
       "        [ 8., 10., 12.]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z = torch.from_numpy(matrix).float() + tensor3d # Il risultato è un tensore PyTorch a 32 bit\n",
    "z\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But be careful because the space is shared:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 3.,  5.,  7.],\n",
      "        [ 9., 11., 13.]])\n"
     ]
    }
   ],
   "source": [
    "zz = z.numpy()  # I copy z into zz\n",
    "zz += 1.0       # I modify zz\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now z has also been modified!  \n",
    "Another example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[1, 2],\n",
       "        [3, 4]],\n",
       "\n",
       "       [[5, 6],\n",
       "        [7, 8]]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ary3d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1, 2],\n",
       "         [3, 4]],\n",
       "\n",
       "        [[5, 6],\n",
       "         [7, 8]]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor3d_B  # remember it was directly created from ary3d but not using from_numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1, 2],\n",
       "         [3, 4]],\n",
       "\n",
       "        [[5, 6],\n",
       "         [7, 8]]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor3d_C = torch.from_numpy(ary3d)  # Shares memory with NumPy array ary3d\n",
    "tensor3d_C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[1, 2],\n",
      "         [3, 4]],\n",
      "\n",
      "        [[5, 6],\n",
      "         [7, 8]]])\n"
     ]
    }
   ],
   "source": [
    "ary3d[0, 0, 0] = 999  # I change one item of ary3d\n",
    "print(tensor3d_B) # remains unchanged\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[999,   2],\n",
      "         [  3,   4]],\n",
      "\n",
      "        [[  5,   6],\n",
      "         [  7,   8]]])\n"
     ]
    }
   ],
   "source": [
    "print(tensor3d_C) # changes because of memory sharing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[1, 2],\n",
      "         [3, 4]],\n",
      "\n",
      "        [[5, 6],\n",
      "         [7, 8]]])\n"
     ]
    }
   ],
   "source": [
    "print(tensor3d_B)  # still the same"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Allocation\n",
    "Tensors can be allocated like a Numpy array, using a tuple for the size (height, width):  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numpy: [[1. 1. 1.]\n",
      " [1. 1. 1.]]\n",
      "\n",
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "# numpy ones\n",
    "x = np.ones((2,3))  # allocates a 2 by 3 space full of 1s\n",
    "print(f\"Numpy: {x}\\n\")\n",
    "\n",
    "# pytorch ones\n",
    "y = torch.ones((2,3))\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One small difference is that tensors can be created also passing directly the dimensions, without using a tuple:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "print(torch.zeros(2,3))  # allocates space of 0s, note the tuple's missing brackets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numpy: [[0.1517801  0.0091318  0.01086989]\n",
      " [0.78558256 0.32190496 0.98464505]]\n",
      "\n",
      "tensor([[0.5834, 0.9540, 0.8295],\n",
      "        [0.5903, 0.3031, 0.1845]])\n"
     ]
    }
   ],
   "source": [
    "# numpy random\n",
    "print(f\"Numpy: {np.random.rand(2,3)}\\n\")\n",
    "\n",
    "# pytorch random\n",
    "print(torch.rand(2,3)) # allocates space of random numbers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Indexing\n",
    "All the operations that follow are shown on tensors, but the syntax and results for NumPy arrays is identical. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 3],\n",
       "        [4, 5, 6]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor3d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([4, 5, 6])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor3d[1] # the second row (index starts from zero)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2, 5])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor3d[:,1] # : means all of the first axis, so it shows the second column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([5, 6])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor3d[1,1:3] # second row, second and third column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic math with tensors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On tensors you can use the standard operators such as +, -, *, /:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2, 3, 4],\n",
       "        [5, 6, 7]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor3d+1  # add 1 to each scalar inside the tensor\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also apply operators between tensors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "# create tensor \n",
    "tensor1 = torch.ones(3,3)\n",
    "print(\"\\n\",tensor1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: torch.Size([9]); items: tensor([1., 1., 1., 1., 1., 1., 1., 1., 1.])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Resize\n",
    "print(f\"shape: {tensor1.view(9).shape}; items: {tensor1.view(9)}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Addition: tensor([[2., 2., 2.],\n",
      "        [2., 2., 2.],\n",
      "        [2., 2., 2.]])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Addition\n",
    "tensor2 = tensor1.add(tensor1)\n",
    "print(f\"Addition: {tensor2}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subtraction: tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.]])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Subtraction\n",
    "print(f\"Subtraction: {tensor1.sub(tensor1)}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Element wise multiplication: tensor([[2., 2., 2.],\n",
      "        [2., 2., 2.],\n",
      "        [2., 2., 2.]])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Element wise multiplication\n",
    "print(f\"Element wise multiplication: {torch.mul(tensor1, tensor2)}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Element wise division: tensor([[0.5000, 0.5000, 0.5000],\n",
      "        [0.5000, 0.5000, 0.5000],\n",
      "        [0.5000, 0.5000, 0.5000]])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Element wise division\n",
    "print(f\"Element wise division: {torch.div(tensor1, tensor2)}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean: 3.0\n",
      "std: 1.5811388492584229\n"
     ]
    }
   ],
   "source": [
    "# Mean\n",
    "tensor = torch.Tensor([1,2,3,4,5])\n",
    "print(f\"Mean: {tensor.mean()}\")\n",
    "\n",
    "# Standart deviation (std)\n",
    "print(f\"std: {tensor.std()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Broadcasting\n",
    "The magic trick is that PyTorch, when it tries to perform a simple operation between two tensors of different ranks, will use **broadcasting**.  \n",
    " That is, it will automatically expand the tensor with the smaller rank to have the same size as the one with the larger rank.  \n",
    " Broadcasting is an important capability that makes tensor code much easier to write but also more performant (PyTorch doesn't actually copy n times. It pretends it were a tensor of that shape, but doesn't actually allocate any additional memory).  \n",
    "It does the whole calculation in C (or, if you're using a GPU, in CUDA), tens of thousands of times faster than pure Python (up to millions of times faster on a GPU!).  \n",
    "This is true of all broadcasting and elementwise operations and functions done in PyTorch.  \n",
    "\n",
    "For instance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2, 3, 4])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor([1,2,3]) + torch.tensor(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.,  1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10., 11., 12., 13.,\n",
       "        14., 15., 16., 17., 18., 19.])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time = torch.arange(0,20).float(); time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "speed = torch.randn(20)*3 + 0.75*(time-9.5)**2 + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([71.1070, 58.1938, 41.3292, 34.8614, 22.5767, 15.1346,  9.0774,  3.6245,\n",
       "         6.9678, -5.5598,  1.1083,  4.8711,  5.9930,  7.2402, 21.1984, 25.3632,\n",
       "        31.1512, 44.7718, 59.2238, 74.2146])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "speed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Common operations\n",
    "It's also possible to transpose tensors and to multiply matrices:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 3],\n",
       "        [4, 5, 6]])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor2d = torch.tensor([[1, 2, 3], [4, 5, 6]])\n",
    "tensor2d\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor2d.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 4],\n",
       "        [2, 5],\n",
       "        [3, 6]])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor2d.T # transpose = rows exchanged with columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[14, 32],\n",
       "        [32, 77]])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor2d.matmul(tensor2d.T) # matrix multiplication "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[14, 32],\n",
       "        [32, 77]])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor2d @ tensor2d.T  # the operator @ is for matrix multiplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2],\n",
       "        [3, 4],\n",
       "        [5, 6]])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor2d.view(3, 2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2],\n",
       "        [3, 4],\n",
       "        [5, 6]])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor2d.reshape(3, 2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient\n",
    "pytorch is used in neural network and as you know, in neural network we have backpropagation where gradients are calculated. Therefore it makes sense that tensors can  handle gradients. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "xt = torch.tensor(3.).requires_grad_()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The special method is the magical incantation used to tell PyTorch that we want to calculate gradients with respect to that variable at that value. It is essentially tagging the variable, so PyTorch will remember to keep track of how to compute gradients of the other, direct calculations on it that you will ask for.  \n",
    "  \n",
    "  For example, let's define a function that calculates the square of a variable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(3.)\n",
      "None\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(xt.data) # just the tensor\n",
    "print(xt.grad) # the gradient, initially equal to None\n",
    "print(xt.grad_fn) # the computational graph, initially equal to None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(x): return x**2  # the function calculating the square"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f(3)  # 3 squared is 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "yt=f(xt)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(6.)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yt.backward()\n",
    "xt.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you remember calculus rules, the derivative of x^2 is 2x, and we have x=3, so the gradients should be 2 \\* 3 = 6, which is what PyTorch calculated for us!  \n",
    "This can be applied to higher rank tensors:  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 3.,  4., 10.], requires_grad=True)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xtB = torch.tensor([3.,4.,10.]).requires_grad_()\n",
    "xtB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(125., grad_fn=<SumBackward0>)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def f(x): return (x**2).sum()  # add sum, to return a scalar\n",
    "\n",
    "ytB = f(xtB)\n",
    "ytB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 6.,  8., 20.])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ytB.backward()\n",
    "xtB.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our gradients are 2 \\* xt (i.e., the derivative), as we'd expect!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use gradient for simple linear regression\n",
    "Firstly we define a random array of 30 number (input and label) which follow a trend:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# linear regression example\n",
    "X = np.random.rand(30, 1)*2.0\n",
    "w = np.random.rand(2, 1)\n",
    "y = X*w[0] + w[1] + np.random.randn(30, 1) * 0.05"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we prepare a simple linear regression model: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "W = torch.rand(1, 1, requires_grad=True) # initialise weights and bias\n",
    "b = torch.rand(1, requires_grad=True)\n",
    "\n",
    "def linear(x):\n",
    "  return torch.matmul(x, W) + b  # a classic linear regression formula\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random data is transformed into tensors, then weight and bias are trained (for 2500 epochs): "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xt = torch.from_numpy(X).float()  # transform into tensors\n",
    "yt = torch.from_numpy(y).float()\n",
    "\n",
    "for epoch in range(2500):\n",
    "\n",
    "  # predictions\n",
    "  y_pred = linear(Xt)\n",
    "\n",
    "  # calculates the loss function: mean square error \n",
    "  loss = torch.mean((y_pred - yt) ** 2)\n",
    "\n",
    "  #  back-propagation\n",
    "  loss.backward()\n",
    "\n",
    "  # Updates the weights\n",
    "  W.data = W.data - 0.005*W.grad.data # work on .data and not W/b directly, not to overwrite original tensors\n",
    "  b.data = b.data - 0.005*b.grad.data\n",
    "\n",
    "  #  gradient reset\n",
    "  W.grad.data.zero_()\n",
    "  b.grad.data.zero_()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we plot the results: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(X, y)\n",
    "plt.plot(Xt,y_pred.detach().numpy());"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use GPU\n",
    "Finally, let's see how to use the GPU to accelerate computation.  \n",
    "PyTorch comes already with support for GPU so nothing extra to be installed.  \n",
    "It offers a function to detect if CUDA or MPS is available on the system.  \n",
    "CUDA is Nvidia's language framework for GPU and MPS is the Apple’s Metal Performance Shaders (MPS) which can be used as a backend for PyTorch accelerated training too.  \n",
    "If no GPU, no MPS is available, then device will be set to CPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using mps device\n"
     ]
    }
   ],
   "source": [
    "myDevice = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "print(f\"Using {myDevice} device\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When using an expensive tensor operation (typically training a neural network), you simply pass an optional argument saying which device to use:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2., 2., 2., 2., 2.], device='mps:0')"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a Tensor directly on the mps device\n",
    "x = torch.ones(5, device=myDevice)\n",
    "\n",
    "    # Any operation happens on the device (in this case on MPS)\n",
    "y = x * 2\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's quantify the time gain when using a GPU.  \n",
    "We create 1000 random tensors and multiply them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_torch_tensors(device):\n",
    "    x = torch.rand((10000, 10000), dtype=torch.float32)\n",
    "    y = torch.rand((10000, 10000), dtype=torch.float32)\n",
    "    x = x.to(device)\n",
    "    y = y.to(device)\n",
    "\n",
    "    print(\"tensors created in \", device)\n",
    "    return x, y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensors created in  mps\n"
     ]
    }
   ],
   "source": [
    "# how long does it take on MPS?\n",
    "x, y = create_torch_tensors(myDevice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22.3 ms ± 606 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "x * y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensors created in  cpu\n"
     ]
    }
   ],
   "source": [
    "# how long does it take on CPU?\n",
    "x, y = create_torch_tensors(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33.2 ms ± 3.49 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "x * y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It takes half time on MPS (Apple silicon M1), would be even better, around a quarter on M3 and of course if you have an Nvidia GPU."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
