{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5c691dcc",
   "metadata": {},
   "source": [
    "# Translation\n",
    "\n",
    "In this project we will be teaching a neural network to translate from a language to English or viceversa.  \n",
    "  \n",
    "This is made possible by the simple but powerful idea of the **sequence to sequence network**, in which two recurrent neural networks work together to transform one sequence to another. An **encoder network** condenses an input sequence into a vector and a **decoder network** unfolds that vector into a new sequence.  \n",
    "  \n",
    "A good probabilistic translation model requires a large dataset (to cover as many cases as possible) and extensive training, so I will just show how it works with limited examples and the translation accuracy is not in focus (no real validation / test).  \n",
    "  \n",
    "## The dataset\n",
    "\n",
    "The dataset used in the example involves short sentence pairs used in the flash card software Anki.  \n",
    "  \n",
    "The dataset is called “Tab-delimited Bilingual Sentence Pairs” and is part of the [Tatoeba Project](https://tatoeba.org/) and listed on the [ManyThings.org site](https://www.manythings.org/anki/) for helping English as a Second Language students.\n",
    "\n",
    "\n",
    "The files have an attribution column so we need to strip it away before reading the input files.  \n",
    "This has to be done only once.  \n",
    "  \n",
    "### Prepare input files (one-off)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b3fb7b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Script to strip attribution information from tab-separated translation files.\n",
    "\n",
    "Input format: English_text \\t Other_language_text \\t CC-BY_attribution\n",
    "Output format: English_text \\t Other_language_text\n",
    "\"\"\"\n",
    "\n",
    "import sys\n",
    "import os\n",
    "\n",
    "def strip_attribution(input_file, output_file=None):\n",
    "    \"\"\"\n",
    "    Strip attribution column from tab-separated translation file.\n",
    "    \n",
    "    Args:\n",
    "        input_file (str): Path to input file\n",
    "        output_file (str): Path to output file (optional, defaults to input_clean.txt)\n",
    "    \"\"\"\n",
    "    \n",
    "    # Set default output filename if not provided\n",
    "    if output_file is None:\n",
    "        base_name = os.path.splitext(input_file)[0]\n",
    "        output_file = f\"{base_name}_clean.txt\"  # create a file with suffix clean\n",
    "    \n",
    "    try:\n",
    "        with open(input_file, 'r', encoding='utf-8') as infile:\n",
    "            with open(output_file, 'w', encoding='utf-8') as outfile:\n",
    "                line_count = 0\n",
    "                processed_count = 0\n",
    "                \n",
    "                for line in infile:\n",
    "                    line_count += 1\n",
    "                    line = line.rstrip('\\n\\r')\n",
    "                    \n",
    "                    # Skip empty lines\n",
    "                    if not line.strip():\n",
    "                        continue\n",
    "                    \n",
    "                    # Split by tab\n",
    "                    parts = line.split('\\t')\n",
    "                    \n",
    "                    # Check if we have at least 3 parts (English, Other, Attribution)\n",
    "                    if len(parts) >= 3:\n",
    "                        english_text = parts[0]\n",
    "                        other_text = parts[1]\n",
    "                        \n",
    "                        # Write only the first two columns\n",
    "                        outfile.write(f\"{english_text}\\t{other_text}\\n\")\n",
    "                        processed_count += 1\n",
    "                    else:\n",
    "                        print(f\"Warning: Line {line_count} doesn't have expected format: {line}\")\n",
    "                \n",
    "                print(f\"Processing complete!\")\n",
    "                print(f\"Total lines read: {line_count}\")\n",
    "                print(f\"Lines processed: {processed_count}\")\n",
    "                print(f\"Output written to: {output_file}\")\n",
    "                \n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: Input file '{input_file}' not found.\")\n",
    "        return False\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing file: {e}\")\n",
    "        return False\n",
    "    \n",
    "    return True\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a44d8e3",
   "metadata": {},
   "source": [
    "I did it for a couple of languages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57f5a1ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "strip_attribution(\"../datasets/translations/ita.txt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a03624c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "strip_attribution(\"../datasets/translations/jpn.txt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c2ee7b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "strip_attribution(\"../datasets/translations/cmn.txt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "32a6d209",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 381352\r\n",
      "-rw-r--r--@ 1 Massimo  staff   4.2M Jun  4 01:29 cmn.txt\r\n",
      "-rw-r--r--  1 Massimo  staff   1.8M Jun  7 17:16 cmn_clean.txt\r\n",
      "-rw-r--r--@ 1 Massimo  staff    48M Jun  4 01:29 deu.txt\r\n",
      "-rw-r--r--  1 Massimo  staff    22M Jun  6 16:31 deu_clean.txt\r\n",
      "-rw-r--r--@ 1 Massimo  staff   9.1M Mar 12  2017 fra_clean.txt\r\n",
      "-rw-r--r--@ 1 Massimo  staff    53M Jun  4 01:29 ita.txt\r\n",
      "-rw-r--r--  1 Massimo  staff    22M Jun  7 17:15 ita_clean.txt\r\n",
      "-rw-r--r--@ 1 Massimo  staff    18M Jun  4 01:29 jpn.txt\r\n",
      "-rw-r--r--@ 1 Massimo  staff   8.7M Jun  7 17:15 jpn_clean.txt\r\n"
     ]
    }
   ],
   "source": [
    "# Have a look at the available datasets\n",
    "\n",
    "! ls -lh \"../datasets/translations/\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3efffc3",
   "metadata": {},
   "source": [
    "Note that I have prepared non-latin languages dataset too, specifically Japanese (jpn) and Chinese (cmn),  \n",
    "They will require some additional pre-processing that I want to show.  \n",
    "\n",
    "## Prepare data structures\n",
    "\n",
    "We will now prepare the data structures to store the input data and a couple of helper functions.\n",
    "### Unicode to ASCII\n",
    "The files are all in Unicode, to simplify we will turn Unicode characters to ASCII, make everything lowercase, and trim most punctuation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7b9c8404",
   "metadata": {},
   "outputs": [],
   "source": [
    "import unicodedata\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cf078988",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn a Unicode string to plain ASCII, thanks to\n",
    "# https://stackoverflow.com/a/518232/2809427\n",
    "def _unicodeToAscii(s):\n",
    "    return ''.join(\n",
    "        c for c in unicodedata.normalize('NFD', s)\n",
    "        if unicodedata.category(c) != 'Mn'\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "428c6459",
   "metadata": {},
   "source": [
    "We can see how this works for a japanese sentence:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3fa1e37e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "なさい。\n"
     ]
    }
   ],
   "source": [
    "japString = \"なさい。\"\n",
    "print(japString)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "600c62c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "なさい。\n"
     ]
    }
   ],
   "source": [
    "print(_unicodeToAscii(japString))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53078955",
   "metadata": {},
   "source": [
    "### Normalise strings\n",
    "Lowercase, trim and remove non-letter characters helper.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b82b66e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _normaliseString(s):\n",
    "    s = _unicodeToAscii(s.lower().strip())\n",
    "    s = re.sub(r\"([.!?。])\", \"\", s)\n",
    "    return s.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "10bba4bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "なさい\n"
     ]
    }
   ],
   "source": [
    "print(_normaliseString(japString))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ba865e78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this is a strange sentence\n"
     ]
    }
   ],
   "source": [
    "print(_normaliseString(\" this is a STRANGE sentence \"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2058ab1d",
   "metadata": {},
   "source": [
    "### Split a sentence into words\n",
    "Now this is easy for latin languages by splitting words when a  blank character is encountered but this is not working for languages such as Japanese or Chinese as they don't separate words using spaces (and it's not always true that one character = one word, often words are formed by two or more characters).  \n",
    "  \n",
    "  Let's see some example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2f3c4409",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['English', 'sentences', 'are', 'easy', 'to', 'split']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'English sentences are easy to split'.split(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "70c71719",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['お行儀よくしなさい']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testSentenceJap = 'お行儀よくしなさい'  # O gyōgi yoku shi nasai: 5 words\n",
    "testSentenceJap.split(' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85643e5c",
   "metadata": {},
   "source": [
    "As you can see, the sentence is handled as one single word. This will make the model useless.  \n",
    "There are several ways to split sentences in Chinese / Japanese using external specific libraries, these are simple examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8c728e20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nagisa in /Users/Massimo/anaconda3/envs/ML/lib/python3.11/site-packages (0.2.11)\n",
      "Requirement already satisfied: six in /Users/Massimo/anaconda3/envs/ML/lib/python3.11/site-packages (from nagisa) (1.16.0)\n",
      "Requirement already satisfied: numpy in /Users/Massimo/anaconda3/envs/ML/lib/python3.11/site-packages (from nagisa) (1.24.0)\n",
      "Requirement already satisfied: DyNet38 in /Users/Massimo/anaconda3/envs/ML/lib/python3.11/site-packages (from nagisa) (2.2)\n",
      "Requirement already satisfied: cython in /Users/Massimo/anaconda3/envs/ML/lib/python3.11/site-packages (from DyNet38->nagisa) (3.1.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install nagisa\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fb2135f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nagisa   # Japanese splitting\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ab6efc37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['お', '行儀', 'よく', 'し', 'なさい']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nagisa.tagging(testSentenceJap).words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6801701",
   "metadata": {},
   "source": [
    "Perfect. We use another library for Chinese:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fae0aa72",
   "metadata": {},
   "outputs": [],
   "source": [
    "testSentenceCmn = \"我爱人工智能\"  #Wǒ ài réngōng zhìnéng: 3 or 4 words (the last two can be combined together)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2cefbcf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: jieba in /Users/Massimo/anaconda3/envs/ML/lib/python3.11/site-packages (0.42.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install jieba\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "49d9d700",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jieba  # Chinese words splitting library\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "79984c52",
   "metadata": {},
   "outputs": [],
   "source": [
    "wordsGenerator = jieba.cut(testSentenceCmn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c458392b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache /var/folders/8g/4xvwd0w96wg80spn6kr2rh640000gp/T/jieba.cache\n",
      "Loading model from cache /var/folders/8g/4xvwd0w96wg80spn6kr2rh640000gp/T/jieba.cache\n",
      "Loading model cost 0.377 seconds.\n",
      "Loading model cost 0.377 seconds.\n",
      "Prefix dict has been built successfully.\n",
      "Prefix dict has been built successfully.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['我', '爱', '人工智能']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(wordsGenerator)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "699da447",
   "metadata": {},
   "source": [
    "It's working. Let's put all together in a function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "dd6fdc98",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _splitSentence(langName,sentence):\n",
    "    \"\"\"\n",
    "    langName:  the input language, suing the smae convention as the dataset\n",
    "    sentence:  the string to split\n",
    "    return:    list of words (strings)\n",
    "    \"\"\"\n",
    "\n",
    "    if langName == \"jpn\":\n",
    "        return nagisa.tagging(sentence).words  # Japanese\n",
    "    elif langName == \"cmn\":\n",
    "        return list(jieba.cut(sentence))  # Chinese\n",
    "    else:\n",
    "        return sentence.split(' ')  # All other languages; add more tests if you want to split other non-latin "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "321e98c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['お', '行儀', 'よく', 'し', 'なさい']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_splitSentence(\"jpn\",testSentenceJap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c25fdfc4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['我', '爱', '人工智能']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_splitSentence(\"cmn\", testSentenceCmn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c7dd169",
   "metadata": {},
   "source": [
    "### Filter only short sentences\n",
    "Since there are a lot of example sentences and we want to train something quickly, we’ll trim the data set to only relatively short and simple sentences. Here the maximum number of words (use the previously defined function to split) is used as threshold.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "658a7cf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LENGTH = 10  # keep only sentences up to 10 words\n",
    "\n",
    "def _filterSentence(langName, s):\n",
    "    # s: input string\n",
    "    # langName: language of the sentence\n",
    "    # returns True if s is shorter than threshold MAX_LENGTH\n",
    "    w = _splitSentence(langName, s)\n",
    "    return len(w) < MAX_LENGTH\n",
    "\n",
    "def _filterPair(langName, p):\n",
    "    # langName: language of the sentence\n",
    "    # p: input pair of strings\n",
    "    # returns True if s is shorter than threshold MAX_LENGTH\n",
    "    return _filterSentence(langName, p[0]) and _filterSentence(langName, p[1])\n",
    " \n",
    "\n",
    "\n",
    "def _filterPairs(langName, pairs):\n",
    "    # langName: language of the sentence\n",
    "    # pairs: all dataset pairs\n",
    "    # return subset of shorter pairs\n",
    "    return [pair for pair in pairs if _filterPair(langName, pair)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8d4f63aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_filterSentence(\"jpn\", japString)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9a5de4eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_filterSentence(\"eng\", \"this is a sentence too long, note that punctuation is included in the count!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "307f6eca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "japPair = ['please.', japString]\n",
    "_filterPair(\"jpn\", japPair)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1b45878",
   "metadata": {},
   "source": [
    "## Read the files and prepare the data\n",
    "\n",
    "To read the data file we will split the file into lines and then split lines into pairs. The files are all English → Other Language, so if we want to translate from Other Language → English we can use the reverse flag to reverse the pairs.  \n",
    "Read lines and words are stored in two variables of **class Lang**: one for English and one for input language. \n",
    "The class Lang (language) contains the language name (a string), the found list of words and methods to index a word into a number and viceversa (used for training the network).  \n",
    "It also contains the function to split a sentence into words so we can leverage the language name, which is known.\n",
    "  \n",
    "  The full process for preparing the data is:\n",
    "\n",
    "- Read text file and split into lines, split lines into pairs\n",
    "\n",
    "- Normalize text, filter by length and content\n",
    "\n",
    "- Make word lists from sentences in pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "88ea9791",
   "metadata": {},
   "outputs": [],
   "source": [
    "SOS_token = 0  # Note the use of start and end sentence marks.  \n",
    "EOS_token = 1\n",
    "\n",
    "# The Language class, contains the words\n",
    "\n",
    "class Lang:\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.word2index = {}\n",
    "        self.word2count = {}\n",
    "        self.index2word = {SOS_token: \"SOS\", EOS_token: \"EOS\"}\n",
    "        self.n_words = 2  # Count SOS and EOS\n",
    "\n",
    "    def _splitSentence(self,sentence):\n",
    "        if self.name == \"jpn\":\n",
    "            return nagisa.tagging(sentence).words\n",
    "        elif self.name == \"cmn\":\n",
    "            return list(jieba.cut(sentence))\n",
    "        else:\n",
    "            return sentence.split(' ')\n",
    "        \n",
    "    def addSentence(self, sentence):\n",
    "        words = self._splitSentence(sentence) # first split the sentence into words\n",
    "\n",
    "        for word in words:\n",
    "            self.addWord(word)\n",
    "\n",
    "    def addWord(self, word):\n",
    "        if word not in self.word2index:\n",
    "            self.word2index[word] = self.n_words\n",
    "            self.word2count[word] = 1\n",
    "            self.index2word[self.n_words] = word\n",
    "            self.n_words += 1\n",
    "        else:\n",
    "            self.word2count[word] += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b77b28be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepareData(lang, reverse=False):\n",
    "\n",
    "    # read the data from the given file and instantiate the proper Language class\n",
    "    # lang: string representing the language; used to access the file\n",
    "    # reverse: boolean; true if translation is from language to English; false if viceversa\n",
    "    # return: \n",
    "    # - Input Lang class\n",
    "    # - Output Lang class\n",
    "    # - Pairs of sentences\n",
    "    \n",
    "    print(\"Reading lines...\")\n",
    "\n",
    "        # Read the file and split into lines\n",
    "    lines = open('../datasets/translations/%s_clean.txt' % (lang), encoding='utf-8').\\\n",
    "        read().strip().split('\\n')\n",
    "\n",
    "        # Split every line into pairs and normalize\n",
    "    pairs = [[_normaliseString(s) for s in l.split('\\t')] for l in lines]\n",
    "    print(\"Read %s sentence pairs\" % len(pairs))\n",
    "\n",
    "        # Reverse pairs + make Lang instances + filter pairs (only short ones)\n",
    "    if reverse:\n",
    "        pairs = [list(reversed(p)) for p in pairs]\n",
    "        \n",
    "        input_lang = Lang(lang)\n",
    "        output_lang = Lang(\"eng\")\n",
    "        \n",
    "        pairs = _filterPairs(input_lang.name, pairs)\n",
    "\n",
    "    else:\n",
    "        input_lang = Lang(\"eng\")\n",
    "        output_lang = Lang(lang)\n",
    "\n",
    "        pairs = _filterPairs(output_lang.name, pairs)\n",
    "\n",
    "            \n",
    "    print(\"Trimmed to %s sentence pairs\" % len(pairs))\n",
    "    \n",
    "        # extract words\n",
    "    print(\"Counting words...\")\n",
    "    for pair in pairs:\n",
    "        input_lang.addSentence(pair[0])\n",
    "        output_lang.addSentence(pair[1])\n",
    "        \n",
    "    print(\"Counted words:\")\n",
    "    print(input_lang.name, input_lang.n_words)\n",
    "    print(output_lang.name, output_lang.n_words)\n",
    "    \n",
    "    return input_lang, output_lang, pairs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dce05356",
   "metadata": {},
   "source": [
    "# First use case: English -> Italian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "938a6d6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading lines...\n",
      "Read 390190 sentence pairs\n",
      "Trimmed to 369926 sentence pairs\n",
      "Counting words...\n",
      "Counted words:\n",
      "eng 15772\n",
      "ita 30582\n"
     ]
    }
   ],
   "source": [
    "input_lang, output_lang, pairs = prepareData('ita', False)   # eng -> Italian\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9583145",
   "metadata": {},
   "source": [
    "The input and output languages contain several attributes (name, number of words, ...) and methods (convert a word into its index and viceversa):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "94bf2f53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'eng'"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_lang.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "f2d561c8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ita'"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_lang.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "c3306e35",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30582"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_lang.n_words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4645d73e",
   "metadata": {},
   "source": [
    "A total of 30K words are stored for Italian. This number will be used to size the neural network.  \n",
    "  \n",
    "  Example of pair sentence (english, italian):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "7f189c8a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['do it', 'lo faccia']"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pairs[42]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "de2244bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_lang.word2index[\"ciao\"]  # get the index of italian word \"ciao\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "52d6b700",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ciao'"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_lang.index2word[2]  #  verify the word associated to index 2 is 'ciao'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "3b90344c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_lang.word2index[\"hello\"] # works also for english "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "ac387c2a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_lang.word2count['ciao'] # number of occurences of word 'ciao'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "d65cddc8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"i'm tidy\", 'io sono ordinato']"
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pairs[999]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "5c8c56a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['io', 'sono', 'ordinato']"
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pairs[999][1].split(' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c61cd4c",
   "metadata": {},
   "source": [
    "## Preparing Training Data\n",
    "To train, for each pair we will need an input tensor (indexes of the words in the input sentence) and target tensor (indexes of the words in the target sentence). While creating these vectors we will append the EOS token to both sequences.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b010bd0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler\n",
    "from torch import optim\n",
    "\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "4f9a3b03",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "4ba19fc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For determinism\n",
    "\n",
    "SEED = 42\n",
    "\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "bfcd10d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_device():\n",
    "    \"\"\"\n",
    "    Get the best available device (CPU/GPU/MPS) with proper MPS handling.\n",
    "    \"\"\"\n",
    "    if torch.cuda.is_available():\n",
    "        return torch.device(\"cuda\")\n",
    "    elif torch.backends.mps.is_available():\n",
    "        # Check if Apple MPS is properly supported\n",
    "        try:\n",
    "            # Test MPS with a simple operation\n",
    "            test_tensor = torch.randn(2, 2, device=\"mps\")\n",
    "            _ = test_tensor + test_tensor\n",
    "            return torch.device(\"mps\")\n",
    "        except Exception as e:\n",
    "            print(f\"MPS available but not working properly: {e}\")\n",
    "            print(\"Falling back to CPU\")\n",
    "            return torch.device(\"cpu\")\n",
    "    else:\n",
    "        return torch.device(\"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "c692de9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n"
     ]
    }
   ],
   "source": [
    "# Set device\n",
    "myDevice = get_device()\n",
    "print(f\"Using device: {myDevice}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "b353e0ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "myDevice = \"cpu\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "067e97c4",
   "metadata": {},
   "source": [
    "### Embed data into tensors \n",
    "\n",
    "To embed text into tokens (using tokenise) and finally to indexes and tensors we need a couple of helper functions.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "b8f0db16",
   "metadata": {},
   "outputs": [],
   "source": [
    "def indexesFromSentence(lang, sentence):\n",
    "    words = lang._splitSentence(sentence)\n",
    "    return [lang.word2index[word] for word in words]\n",
    "\n",
    "def tensorFromSentence(lang, sentence):\n",
    "    indexes = indexesFromSentence(lang, sentence)\n",
    "    indexes.append(EOS_token)\n",
    "    \n",
    "    try:\n",
    "        \n",
    "        # Create tensor on CPU first, then move to device\n",
    "        tensor = torch.tensor(indexes, dtype=torch.long)\n",
    "        tensor = tensor.to(myDevice, non_blocking=True)\n",
    "        \n",
    "        return tensor.view(1, -1)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error creating tensor on {myDevice}: {e}\")\n",
    "        print(\"Creating tensor on CPU instead...\")\n",
    "        \n",
    "        # Fallback to CPU\n",
    "        tensor = torch.tensor(indexes, dtype=torch.long, device='cpu')\n",
    "        return tensor.view(1, -1)\n",
    "    \n",
    "\n",
    "def tensorsFromPair(pair):\n",
    "    input_tensor = tensorFromSentence(input_lang, pair[0])\n",
    "    target_tensor = tensorFromSentence(output_lang, pair[1])\n",
    "    return (input_tensor, target_tensor)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83ecaac8",
   "metadata": {},
   "source": [
    "The first helper, *indexesFromSentence* gets a sentence, tokenise it and maps each token into its index, based on the language:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "3cfad6b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[16, 619, 8723, 2449, 1207, 3207, 11079]"
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testSentenceEN = \"i love machine learning and artificial intelligence\"\n",
    "\n",
    "indexesFromSentence(input_lang, testSentenceEN)  # input language is English"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e07a7898",
   "metadata": {},
   "source": [
    "Similarly, the helper *tensorFromSentence* gets a sentence, tokenises it and maps each token into its tensor (note it adds 1 at the end  = End Of Sentence, EOS token):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "649b17c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[   16,   619,  8723,  2449,  1207,  3207, 11079,     1]])"
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensorFromSentence(input_lang, testSentenceEN)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21c0ac8d",
   "metadata": {},
   "source": [
    "## Load the data\n",
    "Now we are ready to load the data for the model training.  \n",
    "After setting the language pre-processing criteria, the next step is to create batches of training data using iterators.    \n",
    "We use a batch of 32, can be customised below.  \n",
    "As the sentences are many and the training will be too long (depending on GPU/CPU), I take a small percentage of the entire set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "e0f5cf40",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32  # use this to set the training batch size\n",
    "TRAIN_PERCENT = 0.1  # use this to set the training size\n",
    "\n",
    "def get_trainDataloader(input_lang, output_lang, pairs, device):\n",
    "\n",
    "        # get the training split\n",
    "    n = len(pairs)\n",
    "    trainSplit = int(n * TRAIN_PERCENT)\n",
    "    print(f\"train sentences: {trainSplit}\")\n",
    "    \n",
    "        # Pre-allocate arrays on CPU \n",
    "    input_ids = np.zeros((trainSplit, MAX_LENGTH), dtype=np.int64)  \n",
    "    target_ids = np.zeros((trainSplit, MAX_LENGTH), dtype=np.int64) \n",
    "\n",
    "        # tokenise and get indexes\n",
    "    for idx, (inp, tgt) in enumerate(pairs[:trainSplit]):\n",
    "        inp_ids = indexesFromSentence(input_lang, inp)\n",
    "        tgt_ids = indexesFromSentence(output_lang, tgt)\n",
    "        inp_ids.append(EOS_token)\n",
    "        tgt_ids.append(EOS_token)\n",
    "        input_ids[idx, :len(inp_ids)] = inp_ids\n",
    "        target_ids[idx, :len(tgt_ids)] = tgt_ids\n",
    "\n",
    "        # Create tensors on CPU first, then move to device\n",
    "    try:\n",
    "            # Create tensors with proper dtype (int64/long is more compatible with MPS)\n",
    "        input_tensor = torch.from_numpy(input_ids).long()\n",
    "        target_tensor = torch.from_numpy(target_ids).long()\n",
    "    \n",
    "            # Move to device safely\n",
    "        input_tensor = input_tensor.to(device, non_blocking=True)\n",
    "        target_tensor = target_tensor.to(device, non_blocking=True)\n",
    "    \n",
    "        train_data = TensorDataset(input_tensor, target_tensor)\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error moving tensors to {device}: {e}\")\n",
    "        print(\"Falling back to CPU...\")\n",
    "        device = torch.device(\"cpu\")\n",
    "        input_tensor = torch.from_numpy(input_ids).long()\n",
    "        target_tensor = torch.from_numpy(target_ids).long()\n",
    "        \n",
    "        train_data = TensorDataset(input_tensor, target_tensor)\n",
    "\n",
    "\n",
    "\n",
    "    train_sampler = RandomSampler(train_data)\n",
    "    train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=BATCH_SIZE)\n",
    "    \n",
    "    return train_dataloader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbfae1e7",
   "metadata": {},
   "source": [
    "Get the train dataset for Italian language:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "66cc187b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train sentences: 36992\n"
     ]
    }
   ],
   "source": [
    "trainData = get_trainDataloader(input_lang, output_lang, pairs, myDevice)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "59386ce9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.utils.data.dataloader.DataLoader"
      ]
     },
     "execution_count": 262,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(trainData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "349e2402",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source: torch.Size([32, 10])\n",
      "Target: torch.Size([32, 10])\n"
     ]
    }
   ],
   "source": [
    "# Check a batch\n",
    "for src_batch, tgt_batch in trainData:\n",
    "    print(\"Source:\", src_batch.shape)\n",
    "    print(\"Target:\", tgt_batch.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "e8e57e3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pick a random index less than the batch size\n",
    "index = random.randrange(len(src_batch))\n",
    "index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "id": "6030a089",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([13, 19, 66,  1,  0,  0,  0,  0,  0,  0])\n"
     ]
    }
   ],
   "source": [
    "print(src_batch[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "cd6f1187",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "go\n",
      "see\n",
      "tom\n",
      "EOS\n",
      "SOS\n",
      "SOS\n",
      "SOS\n",
      "SOS\n",
      "SOS\n",
      "SOS\n"
     ]
    }
   ],
   "source": [
    "for i in src_batch[index]:\n",
    "    print (input_lang.index2word[i.item()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "id": "56993a5f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([  48,  115, 1625,  179,    1,    0,    0,    0,    0,    0])\n"
     ]
    }
   ],
   "source": [
    "print(tgt_batch[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "e4d0a779",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vada\n",
      "a\n",
      "trovare\n",
      "tom\n",
      "EOS\n",
      "SOS\n",
      "SOS\n",
      "SOS\n",
      "SOS\n",
      "SOS\n"
     ]
    }
   ],
   "source": [
    "for i in tgt_batch[index]:\n",
    "    print (output_lang.index2word[i.item()])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3884b41e",
   "metadata": {},
   "source": [
    "# Model\n",
    "\n",
    "Recurrent Neural Network, or RNN, is a network that operates on a sequence and uses its own output as input for subsequent steps.\n",
    "\n",
    "A **Sequence to Sequence** (seq2seq) network is a model consisting of two RNNs called the encoder and decoder. The encoder reads an input sequence and outputs a single vector and the decoder reads that vector to produce an output sequence.\n",
    "\n",
    "Unlike sequence prediction with a single RNN, where every input corresponds to an output, the seq2seq model frees us from sequence length and order, which makes it ideal for translation between two languages.  \n",
    "In the general case, input sequences and output sequences have different lengths and the entire input sequence is required in order to start predicting the target.  \n",
    "\n",
    "Consider the sentence *Je ne suis pas le chat noir* → I am not the black cat. Most of the words in the input sentence have a direct translation in the output sentence but are in slightly different orders, e.g. *chat noir* and black cat. Because of the *ne/pas* construction there is also one more word in the input sentence. It would be difficult to produce a correct translation directly from the sequence of input words.  \n",
    "  \n",
    "\n",
    "## The Encoder\n",
    "\n",
    "With a seq2seq model the encoder creates a single vector which, in the ideal case, encodes the “meaning” of the input sequence into a single vector — a single point in some N dimensional space of sentences.  \n",
    "This **Context Vector** is said to contain the abstract representation of the input language sequence.\n",
    "\n",
    "The encoder of a seq2seq network is a RNN that processes the input sequence and outputs some value for every word from the input sentence. For every input word the encoder outputs a vector and a hidden state, and uses the hidden state for the next input word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "f36c9157",
   "metadata": {},
   "outputs": [],
   "source": [
    "HIDDEN_SIZE = 128\n",
    "\n",
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, dropout_p=0.1):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size, batch_first=True)\n",
    "        self.dropout = nn.Dropout(dropout_p)\n",
    "\n",
    "    def forward(self, input):\n",
    "        embedded = self.dropout(self.embedding(input))\n",
    "        output, hidden = self.gru(embedded)\n",
    "        return output, hidden\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "6f109857",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = EncoderRNN(input_lang.n_words, HIDDEN_SIZE)\n",
    "encoder = encoder.to(myDevice)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "83a093e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoder's state_dict:\n",
      "embedding.weight \t torch.Size([15772, 128])\n",
      "gru.weight_ih_l0 \t torch.Size([384, 128])\n",
      "gru.weight_hh_l0 \t torch.Size([384, 128])\n",
      "gru.bias_ih_l0 \t torch.Size([384])\n",
      "gru.bias_hh_l0 \t torch.Size([384])\n"
     ]
    }
   ],
   "source": [
    "print(\"Encoder's state_dict:\")\n",
    "for param_tensor in encoder.state_dict():\n",
    "    print(param_tensor, \"\\t\", encoder.state_dict()[param_tensor].size())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "dc3a583e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EncoderRNN(\n",
       "  (embedding): Embedding(15772, 128)\n",
       "  (gru): GRU(128, 128, batch_first=True)\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 271,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c4c9a25",
   "metadata": {},
   "source": [
    "The encoder is pretty simple:\n",
    "- the input layer (embedding) is taking all the input language (in this case English) words (around 15k) \n",
    "- the hidden layer is a GRU (Gated Recurrent Unit) - simpler than a LSTM - with a dropout mechanism (drops 10% of the weights) for regularisation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f3f59e8",
   "metadata": {},
   "source": [
    "##  The Decoder\n",
    "The decoder is another RNN that takes the encoder output vector and outputs a sequence of words to create the translation.\n",
    "\n",
    "The decoder is trained to predict the next characters of the target sequence, given previous characters of the target sequence. Specifically, it is trained to turn the target sequences into the same sequences but offset by one timestep in the future, a training process called \"teacher forcing\" in this context. Importantly, the encoder uses as initial state the state vectors from the encoder, which is how the decoder obtains information about what it is supposed to generate.\n",
    "\n",
    "At every step of decoding, the decoder is given an input token and hidden state. The initial input token is the start-of-string <SOS> token, and the first hidden state is the context vector (the encoder’s last hidden state)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "bdc701db",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size):\n",
    "        super(DecoderRNN, self).__init__()\n",
    "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size, batch_first=True)\n",
    "        self.out = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, encoder_outputs, encoder_hidden, target_tensor=None):\n",
    "        batch_size = encoder_outputs.size(0)\n",
    "        decoder_input = torch.empty(batch_size, 1, dtype=torch.long, device=myDevice).fill_(SOS_token)\n",
    "        decoder_hidden = encoder_hidden\n",
    "        decoder_outputs = []\n",
    "\n",
    "        for i in range(MAX_LENGTH):\n",
    "            decoder_output, decoder_hidden  = self.forward_step(decoder_input, decoder_hidden)\n",
    "            decoder_outputs.append(decoder_output)\n",
    "\n",
    "            if target_tensor is not None:\n",
    "                # Teacher forcing: Feed the target as the next input\n",
    "                decoder_input = target_tensor[:, i].unsqueeze(1) # Teacher forcing\n",
    "            else:\n",
    "                # Without teacher forcing: use its own predictions as the next input\n",
    "                _, topi = decoder_output.topk(1)\n",
    "                decoder_input = topi.squeeze(-1).detach()  # detach from history as input\n",
    "\n",
    "        decoder_outputs = torch.cat(decoder_outputs, dim=1)\n",
    "        decoder_outputs = F.log_softmax(decoder_outputs, dim=-1)\n",
    "        return decoder_outputs, decoder_hidden, None # We return `None` for consistency in the training loop\n",
    "\n",
    "    def forward_step(self, input, hidden):\n",
    "        output = self.embedding(input)\n",
    "        output = F.relu(output)\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "        output = self.out(output)\n",
    "        return output, hidden"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "537cc46a",
   "metadata": {},
   "source": [
    "### Teacher forcing\n",
    "While running the encoder on the input sequence is relatively straightforward, handling the input and output of the decoder requires more care. The most common approach is called teacher forcing.  \n",
    "This method acts like a Regularization. So that the model trains efficiently and fastly during the process.  \n",
    "  \n",
    "“Teacher forcing” is the concept of using the real target outputs as each next input, instead of using the decoder’s guess as the next input. Using teacher forcing causes it to converge faster but when the trained network is exploited, it may exhibit instability.  \n",
    "  \n",
    "You can observe outputs of teacher-forced networks that read with coherent grammar but wander far from the correct translation - intuitively it has learned to represent the output grammar and can “pick up” the meaning once the teacher tells it the first few words, but it has not properly learned how to create the sentence from the translation in the first place.  \n",
    "  \n",
    "Because of the freedom PyTorch’s autograd gives us, we can randomly choose to use teacher forcing or not with a simple if statement.  \n",
    "Another possibility would be to use a teach force ratio (tfr), where we can actually control the flow of input words to the decoder. Sending either of the word (actual target word or predicted target word) can be regulated with a probability of say 50%, so at any time step, one of them is passed during the training. Turn rtf up to use more of it.  \n",
    "  \n",
    "Note that In some niche cases you may not be able to use teacher forcing, because you don't have access to the full target sequences, e.g. if you are doing online training on very long sequences, where buffering complete input-target pairs would be impossible. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12ce1abb",
   "metadata": {},
   "source": [
    "## Attention\n",
    "If only the context vector is passed between the encoder and decoder, that single vector carries the burden of encoding the entire sentence.  \n",
    "  \n",
    "In this resides the limitation of classic sequence to sequence models; the encoder is \"forced\" to send only a single vector, regardless of the length of our input i.e. how many words compose our sentence. Even if we decide to use a large number of hidden units in the encoder with the aim of having a larger context, then the model overfits with short sequences, and we take a performance hit as we increase the number of parameters.  \n",
    "  \n",
    "This is the problem that attention solves.\n",
    "  \n",
    "The intuition behind attention is that rather than compressing the input, it might be better for the decoder to revisit the input sequence at every step. Moreover, rather than always seeing the same representation of the input, the decoder should selectively focus a different part of the encoder’s outputs for every step of the decoder’s own outputs. \n",
    "  \n",
    "Think about a sentence like \"Pizza came out of the oven and it tasted good.\"    \n",
    "Attention is the mechanism that allows to correctly associate the word 'it' with the pizza.  \n",
    "  \n",
    "Attention mechanism provided a simple means by which the decoder could dynamically attend to different parts of the input at each decoding step. The high-level idea is that the decoder can receive as input a context vector consisting of a weighted sum of the representations on the input at each time step. Intuitively, the weights determine the extent to which each step’s context “focuses” on each input token, and the key is to make this process for assigning the weights differentiable so that it can be learned along with all of the other neural network parameters.\n",
    "  \n",
    "  This process allows  to amplify the important parts of the sequence and reduce the irrelevant parts.   \n",
    "    \n",
    "There are different types of attention, the simplest being the **self-attention**: it works by seeing how similar each word is to all the other words in the sentence, including itself.  \n",
    "Self-attention calculates these similarities and then are used to determine how the each word is encoded.  \n",
    "For example, in the previous example, the word 'it' will have a similarity score close to pizza.   \n",
    "So, attention tries to establish relationships among words. \n",
    "   \n",
    "  A variation would be the **masked self-attention**: only use the similarity between the current word and everything other words that come before, ignoring everything that come after it. In the example sentence, the word 'it' would be compared only with the words before, including pizza. The idea is that reference has already been done and saves time. \n",
    "  \n",
    "**Bahdanau attention**, also known as additive attention, is a commonly used attention mechanism in sequence-to-sequence models, particularly in neural machine translation tasks. It was introduced by Bahdanau et al. in their paper titled *Neural Machine Translation by Jointly Learning to Align and Translate* (ArXiv:1409.0473).  This attention mechanism employs a learned alignment model to compute attention scores between the encoder and decoder hidden states. It utilizes a feed-forward neural network to calculate alignment scores.\n",
    "  \n",
    "However, there are alternative attention mechanisms available, such as Luong attention, which computes attention scores by taking the dot product between the decoder hidden state and the encoder hidden states. It does not involve the non-linear transformation used in Bahdanau attention."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "0bfa05fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BahdanauAttention(nn.Module):\n",
    "    def __init__(self, hidden_size):\n",
    "        super(BahdanauAttention, self).__init__()\n",
    "        self.Wa = nn.Linear(hidden_size, hidden_size)\n",
    "        self.Ua = nn.Linear(hidden_size, hidden_size)\n",
    "        self.Va = nn.Linear(hidden_size, 1)\n",
    "\n",
    "    def forward(self, query, keys):\n",
    "        scores = self.Va(torch.tanh(self.Wa(query) + self.Ua(keys)))\n",
    "        scores = scores.squeeze(2).unsqueeze(1)\n",
    "\n",
    "        weights = F.softmax(scores, dim=-1)\n",
    "        context = torch.bmm(weights, keys)\n",
    "\n",
    "        return context, weights\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "384ca728",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttnDecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size, dropout_p=0.1):\n",
    "        super(AttnDecoderRNN, self).__init__()\n",
    "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
    "        self.attention = BahdanauAttention(hidden_size)\n",
    "        self.gru = nn.GRU(2 * hidden_size, hidden_size, batch_first=True)\n",
    "        self.out = nn.Linear(hidden_size, output_size)\n",
    "        self.dropout = nn.Dropout(dropout_p)\n",
    "\n",
    "    def forward(self, encoder_outputs, encoder_hidden, target_tensor=None):\n",
    "        batch_size = encoder_outputs.size(0)\n",
    "        decoder_input = torch.empty(batch_size, 1, dtype=torch.long, device=myDevice).fill_(SOS_token)\n",
    "        decoder_hidden = encoder_hidden\n",
    "        decoder_outputs = []\n",
    "        attentions = []\n",
    "\n",
    "        for i in range(MAX_LENGTH):\n",
    "            decoder_output, decoder_hidden, attn_weights = self.forward_step(\n",
    "                decoder_input, decoder_hidden, encoder_outputs\n",
    "            )\n",
    "            decoder_outputs.append(decoder_output)\n",
    "            attentions.append(attn_weights)\n",
    "\n",
    "            if target_tensor is not None:\n",
    "                # Teacher forcing: Feed the target as the next input\n",
    "                decoder_input = target_tensor[:, i].unsqueeze(1) # Teacher forcing\n",
    "            else:\n",
    "                # Without teacher forcing: use its own predictions as the next input\n",
    "                _, topi = decoder_output.topk(1)\n",
    "                decoder_input = topi.squeeze(-1).detach()  # detach from history as input\n",
    "\n",
    "        decoder_outputs = torch.cat(decoder_outputs, dim=1)\n",
    "        decoder_outputs = F.log_softmax(decoder_outputs, dim=-1)\n",
    "        attentions = torch.cat(attentions, dim=1)\n",
    "\n",
    "        return decoder_outputs, decoder_hidden, attentions\n",
    "\n",
    "\n",
    "    def forward_step(self, input, hidden, encoder_outputs):\n",
    "        embedded =  self.dropout(self.embedding(input))\n",
    "\n",
    "        query = hidden.permute(1, 0, 2)\n",
    "        context, attn_weights = self.attention(query, encoder_outputs)\n",
    "        input_gru = torch.cat((embedded, context), dim=2)\n",
    "\n",
    "        output, hidden = self.gru(input_gru, hidden)\n",
    "        output = self.out(output)\n",
    "\n",
    "        return output, hidden, attn_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "2ef9593b",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder = AttnDecoderRNN(HIDDEN_SIZE, output_lang.n_words)\n",
    "decoder = decoder.to(myDevice)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "id": "95a96d07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decoder's state_dict:\n",
      "embedding.weight \t torch.Size([30582, 128])\n",
      "attention.Wa.weight \t torch.Size([128, 128])\n",
      "attention.Wa.bias \t torch.Size([128])\n",
      "attention.Ua.weight \t torch.Size([128, 128])\n",
      "attention.Ua.bias \t torch.Size([128])\n",
      "attention.Va.weight \t torch.Size([1, 128])\n",
      "attention.Va.bias \t torch.Size([1])\n",
      "gru.weight_ih_l0 \t torch.Size([384, 256])\n",
      "gru.weight_hh_l0 \t torch.Size([384, 128])\n",
      "gru.bias_ih_l0 \t torch.Size([384])\n",
      "gru.bias_hh_l0 \t torch.Size([384])\n",
      "out.weight \t torch.Size([30582, 128])\n",
      "out.bias \t torch.Size([30582])\n"
     ]
    }
   ],
   "source": [
    "print(\"Decoder's state_dict:\")\n",
    "for param_tensor in decoder.state_dict():\n",
    "    print(param_tensor, \"\\t\", decoder.state_dict()[param_tensor].size())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a14ae71",
   "metadata": {},
   "source": [
    "The decoder is more complicated:\n",
    "- the input layer has size of the output language's (the foreign language, not English) number of words\n",
    "- the attention mechanism (size is the hidden layer's size, e.g. 128 nodes)\n",
    "- another GRU\n",
    "- the output layer, with a dropout mechanism"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8898ef48",
   "metadata": {},
   "source": [
    "# Training\n",
    "Before start training, let's prepare a couple of helper functions, to print the training progress (especially tracking the time) and plot the loss curve.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "df9a1ec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import math\n",
    "\n",
    "def asMinutes(s):\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "def timeSince(since, percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "38460b12",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import matplotlib.ticker as ticker\n",
    "import numpy as np\n",
    "\n",
    "plt.switch_backend('agg')\n",
    "\n",
    "def showPlot(points):\n",
    "    plt.figure()\n",
    "    fig, ax = plt.subplots()\n",
    "    # this locator puts ticks at regular intervals\n",
    "    loc = ticker.MultipleLocator(base=0.2)\n",
    "    ax.yaxis.set_major_locator(loc)\n",
    "    plt.plot(points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "1445edc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "480fec41",
   "metadata": {},
   "source": [
    "## Training the Model\n",
    "To train, at each epoch, we run the input sentence through the encoder, and keep track of every output and the latest hidden state. Then the decoder is given the <SOS> token as its first input, and the last hidden state of the encoder as its first hidden state.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "da6ff1f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(dataloader, encoder, decoder, encoder_optimizer,\n",
    "          decoder_optimizer, criterion):\n",
    "\n",
    "    total_loss = 0\n",
    "        # iterate throught the dataloader batches\n",
    "    for data in dataloader:\n",
    "        input_tensor, target_tensor = data\n",
    "\n",
    "        encoder_optimizer.zero_grad()\n",
    "        decoder_optimizer.zero_grad()\n",
    "            # encoder\n",
    "        encoder_outputs, encoder_hidden = encoder(input_tensor)\n",
    "            # decoder\n",
    "        decoder_outputs, _, _ = decoder(encoder_outputs, encoder_hidden, target_tensor)\n",
    "\n",
    "            # calculate loss\n",
    "        loss = criterion(\n",
    "            decoder_outputs.view(-1, decoder_outputs.size(-1)),\n",
    "            target_tensor.view(-1)\n",
    "        )\n",
    "        loss.backward()\n",
    "\n",
    "        encoder_optimizer.step()\n",
    "        decoder_optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    return total_loss / len(dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d5b4ed8",
   "metadata": {},
   "source": [
    "The whole training process looks like this:\n",
    "\n",
    "- Start a timer\n",
    "\n",
    "- Initialise optimisers and criterion\n",
    "\n",
    "- Create set of training pairs\n",
    "\n",
    "- Start empty losses array for plotting\n",
    "\n",
    "Then we call the above train_epoch in a loop and occasionally print the progress (% of examples, time so far, estimated time and average loss).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "af143b09",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_dataloader, encoder, decoder, n_epochs=80, learning_rate=0.001,\n",
    "               print_every=10, plot_every=10):\n",
    "        # start the timer\n",
    "    start = time.time()\n",
    "    \n",
    "        # initialisation\n",
    "    plot_losses = []\n",
    "    print_loss_total = 0  # Reset every print_every\n",
    "    plot_loss_total = 0  # Reset every plot_every\n",
    "\n",
    "    encoder_optimizer = optim.Adam(encoder.parameters(), lr=learning_rate)\n",
    "    decoder_optimizer = optim.Adam(decoder.parameters(), lr=learning_rate)\n",
    "    criterion = nn.NLLLoss()\n",
    "\n",
    "    print(\"Starting train of the model ...\")\n",
    "    print(f\"time since start (estimated remaining) | epoch / {n_epochs} | progress (%) | loss average\")\n",
    "    \n",
    "        # epochs loop\n",
    "    for epoch in range(1, n_epochs + 1):\n",
    "        \n",
    "        loss = train_epoch(train_dataloader, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion)\n",
    "        \n",
    "        print_loss_total += loss\n",
    "        plot_loss_total += loss\n",
    "\n",
    "            # print progress if due\n",
    "        if epoch % print_every == 0:\n",
    "            print_loss_avg = print_loss_total / print_every\n",
    "            print_loss_total = 0\n",
    "            print('%s | %d | %d%% | %.4f' % (timeSince(start, epoch / n_epochs),\n",
    "                                        epoch, epoch / n_epochs * 100, print_loss_avg))\n",
    "\n",
    "            # plot loss if due\n",
    "        if epoch % plot_every == 0:\n",
    "            plot_loss_avg = plot_loss_total / plot_every\n",
    "            plot_losses.append(plot_loss_avg)\n",
    "            plot_loss_total = 0\n",
    "\n",
    "    print(\"Training completed. Here is the loss plot:\")\n",
    "    showPlot(plot_losses);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "7b331513",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting train of the model ...\n",
      "time since start (estimated remaining) | epoch / 30 | progress (%) | loss average\n",
      "25m 28s (- 50m 57s) | 10 | 33% | 0.6980\n",
      "50m 15s (- 25m 7s) | 20 | 66% | 0.2315\n",
      "74m 31s (- 0m 0s) | 30 | 100% | 0.2029\n",
      "Training completed. Here is the loss plot:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train(trainData, encoder, decoder, n_epochs = 30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5feaf0c9",
   "metadata": {},
   "source": [
    "Already after 20 epochs the loss (on training data) was greatly reduced."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82ab06d1",
   "metadata": {},
   "source": [
    "### Save the model\n",
    "\n",
    "This is optional but useful if you train a complex model for long time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "id": "c8adfecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = \"../outputs/translationModels/\"\n",
    "torch.save(encoder.state_dict(), PATH+\"encIT\")\n",
    "torch.save(decoder.state_dict(), PATH+\"decIT\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67c8e90d",
   "metadata": {},
   "source": [
    "## Translate a sentence  \n",
    "In inference mode, i.e. when we want to decode unknown input sequences, we go through a slightly different process: there are no targets. Every time it predicts a word we add it to the output string and if it predicts the EOS token we stop there. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "1ab23f0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate(encoder, decoder, sentence, input_lang, output_lang):\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        \n",
    "            # transform input sequence into tensors\n",
    "        input_tensor = tensorFromSentence(input_lang, sentence)\n",
    "        \n",
    "            # encode the input sequence into state vectors\n",
    "        encoder_outputs, encoder_hidden = encoder(input_tensor)\n",
    "            # Feed the state vectors to the decoder to produce predictions\n",
    "        decoder_outputs, decoder_hidden, decoder_attn = decoder(encoder_outputs, encoder_hidden)\n",
    "\n",
    "        _, topi = decoder_outputs.topk(1)\n",
    "        decoded_ids = topi.squeeze()\n",
    "\n",
    "            # Repeat until we generate the end-of-sequence character or we hit the character limit\n",
    "        decoded_words = []\n",
    "        for idx in decoded_ids:\n",
    "            if idx.item() == EOS_token:\n",
    "                decoded_words.append('<EOS>')\n",
    "                break\n",
    "                # Append the sampled character to the output sequence\n",
    "            decoded_words.append(output_lang.index2word[idx.item()])\n",
    "            \n",
    "    return decoded_words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17ec0e4b",
   "metadata": {},
   "source": [
    "Let's try with a test sentence:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "35ba8d52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i love machine learning and artificial intelligence\n"
     ]
    }
   ],
   "source": [
    "print(testSentenceEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "68bdd96a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "io amo il mio popcorn <EOS>\n"
     ]
    }
   ],
   "source": [
    "  # let's try first with the test sentence\n",
    "translationIT = translate(encoder, decoder, testSentenceEN, input_lang, output_lang)\n",
    "print(' '.join(w for w in translationIT))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4924ffce",
   "metadata": {},
   "source": [
    "This means \"I love my popcorn\" which is hilarious. Clearly it's not perfect :)  \n",
    "Let's evaluate more."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b155481a",
   "metadata": {},
   "source": [
    "## Evaluation\n",
    "Evaluation is performed on the original dataset and we can decide if randomly sampling from the training data splice or the part not used for training.  \n",
    "  \n",
    "  It's not easy to evaluate a translation because you need to compare two similar strings and langauages are messy and ambiguous, there is not a single way to translate a sentence but multiple ways can be acceptable.  \n",
    "  \n",
    "  ### BLEU metric\n",
    "  **BLEU** (Bilingual Evaluation Understudy) is a metric that evaluates the quality of machine-generated text (like a translation or summary) by comparing its word overlaps (n-grams) to one or more human-created reference texts.\n",
    "  \n",
    "The official BLEU calculation is complex due to various heuristics (e.g., handling multiple references, effective reference length, smoothing for zero n-gram counts, tokenization standards) so it's better not to implement BLEU from scratch but instead, to use well-established libraries that have robust and correct implementations.  \n",
    "We will use the NTLK implementation. Simple and robust.  \n",
    "\n",
    "#### Smoothing function\n",
    "\n",
    "In the context of the BLEU score, a smoothing function is a technique used to address the problem of zero n-gram precisions.  \n",
    "  \n",
    "What is the problem?  \n",
    "If even one of the higher-order n-gram precisions (e.g., for bigrams, trigrams, or 4-grams) turns out to be zero, the entire BLEU score becomes zero. This happens because the BLEU score is calculated using a geometric mean of the individual n-gram precisions. If any term in a geometric mean is zero, the product is zero.  \n",
    "  \n",
    "This is particularly problematic for:  \n",
    "\n",
    "- Short sentences: Shorter sentences have fewer possible n-grams, making it more likely that some n-gram orders will have zero matches.\n",
    "\n",
    "- Poor translations: If a machine translation is very different from the reference, it might have no matching n-grams for certain orders.\n",
    "\n",
    "- Single-sentence evaluation: BLEU was originally designed for corpus-level evaluation, where aggregating counts over many sentences makes zero counts less likely. When applied to single sentences (as with sentence_bleu), the sparsity problem is much more pronounced.\n",
    "  \n",
    "A BLEU score of 0.0, especially for short sentences or slightly off translations, can be overly harsh and not very informative. It doesn't differentiate between a translation that has some overlap but no perfect higher-order matches, and a translation that has no overlap whatsoever.  \n",
    "  \n",
    "What does a Smoothing Function do?  \n",
    "A smoothing function modifies the calculation of n-gram precisions to prevent them from becoming exactly zero. Instead of a zero precision, it substitutes a very small positive value, or it adds a small constant to both the numerator (matched n-gram count) and denominator (total n-gram count) to ensure the precision is never zero. This allows the geometric mean to be calculated and provides a more nuanced score even when perfect matches for all n-gram orders are not found.  \n",
    "\n",
    "Evaluation doesn't prove a model works: it just discovers the ways it fails, so let's see the mistakes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "id": "d9d635e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "questo e molto <EOS>\n"
     ]
    }
   ],
   "source": [
    "  # let's try first with the test sentence\n",
    "translationIT = translate(encoder, decoder, \"this is a very easy sentence\", input_lang, output_lang)\n",
    "print(' '.join(w for w in translationIT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "id": "cca81fa3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['questo', 'e', 'molto', '<EOS>']"
      ]
     },
     "execution_count": 296,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translationIT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "id": "80806df6",
   "metadata": {},
   "outputs": [],
   "source": [
    "actualIT = \"questa é una frase molto semplice\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "16e30ea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "id": "08c863d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the SmoothingFunction object\n",
    "chencherry = SmoothingFunction()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "id": "4107d334",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NLTK BLEU-4 (smoothed with method1): 0.11\n"
     ]
    }
   ],
   "source": [
    "# Apply a smoothing method (e.g., method1 from Chen & Cherry)\n",
    "# NLTK offers several methods (method0 to method7).\n",
    "# method1 is a common simple one.\n",
    "score_smoothed = sentence_bleu(_splitSentence(\"ita\",actualIT), translationIT[:-1], smoothing_function=chencherry.method1)\n",
    "print(f\"NLTK BLEU-4 (smoothed with method1): {score_smoothed:.2f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "466fae93",
   "metadata": {},
   "source": [
    "As mentioned above, BLEU has limitation when applied to short sentences.  \n",
    "In this case, a metric of 0.11 is basically a full matching."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "id": "fd8a6d09",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluateRandomly(encoder, decoder, pairs, language, onTrain = True, n=3):\n",
    "    # Sample n sentences from given pairs and translate them using the given dataset (train or test) \n",
    "    # and print the result (no return)\n",
    "    #\n",
    "    # Inputs:\n",
    "    # encoder, decoder: the model\n",
    "    # pairs: the dataset\n",
    "    # onTrain: boolean; True if sampling to be done on train dataset\n",
    "    # n: integer; number of sentences to sample; default is 3\n",
    "    \n",
    "    chencherry = SmoothingFunction()\n",
    "\n",
    "    dataset = \"train\" if onTrain else \"test\"\n",
    "    print(f\"Evaluating {n} random sentences from {dataset} dataset\\n\\n\")\n",
    "    \n",
    "    trainSplit = int(len(pairs) * TRAIN_PERCENT)\n",
    "    print(f\"train split: {trainSplit}\")\n",
    "    \n",
    "    print(\"> input sentence in English \\n = target sentence translated in selected language \\n< Output sentence from the model\\n\")\n",
    "    \n",
    "    for i in range(n):\n",
    "        pair = random.choice(pairs[:trainSplit]) if onTrain else random.choice(pairs[trainSplit:])\n",
    "        print('>', pair[0])\n",
    "        print('=', pair[1])\n",
    "        #print(_splitSentence(language,pair[1]))\n",
    "        \n",
    "        output_words = translate(encoder, decoder, pair[0], input_lang, output_lang)\n",
    "        \n",
    "        output_sentence = ' '.join(output_words[:-1])\n",
    "        print('<', output_sentence)\n",
    "        #print(output_words)\n",
    "        \n",
    "        score_smoothed = sentence_bleu(_splitSentence(language,pair[1]), output_words[:-1], smoothing_function=chencherry.method1)\n",
    "        print(f\"NLTK BLEU-4 (smoothed with method1): {score_smoothed:.2f}\")\n",
    "\n",
    "        print('')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e2a1cc0",
   "metadata": {},
   "source": [
    "First we try with 3 random sentences from the training dataset:  \n",
    "- first line is the English sentence\n",
    "- second line is the target Italian sentence from the Train dataset\n",
    "- third line is the translated  Italian sentence (which should be the same or similar as the second line) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "id": "252fa24a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating 3 random sentences from train dataset\n",
      "\n",
      "\n",
      "train split: 36992\n",
      "> input sentence in English \n",
      " = target sentence translated in selected language \n",
      "< Output sentence from the model\n",
      "\n",
      "> tom's cheating\n",
      "= tom sta imbrogliando\n",
      "< tom sta imbrogliando\n",
      "NLTK BLEU-4 (smoothed with method1): 0.00\n",
      "\n",
      "> is that new\n",
      "= e nuovo\n",
      "< quello e nuovo\n",
      "NLTK BLEU-4 (smoothed with method1): 0.11\n",
      "\n",
      "> that's my book\n",
      "= e il mio libro\n",
      "< il mio libro\n",
      "NLTK BLEU-4 (smoothed with method1): 0.00\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluateRandomly(encoder, decoder, pairs, \"ita\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a972aa7a",
   "metadata": {},
   "source": [
    "As expected, **the model is quite good on the training examples** it has seen.  \n",
    "And this even with limited training.  \n",
    "  \n",
    "  Now we try the same with sentences that the model has not seen before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "id": "03b17ac1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating 3 random sentences from test dataset\n",
      "\n",
      "\n",
      "train split: 36992\n",
      "> input sentence in English \n",
      " = target sentence translated in selected language \n",
      "< Output sentence from the model\n",
      "\n",
      "> you are on the wrong train\n",
      "= e sul treno sbagliato\n",
      "< e in ordine\n",
      "NLTK BLEU-4 (smoothed with method1): 0.11\n",
      "\n",
      "> what time did you get to bed last night\n",
      "= a che ora e andata a letto ieri sera\n",
      "< a qualcuno e due cuoco\n",
      "NLTK BLEU-4 (smoothed with method1): 0.06\n",
      "\n",
      "> the monkey ate my banana\n",
      "= la scimmia ha mangiato la mia banana\n",
      "< il mio nome\n",
      "NLTK BLEU-4 (smoothed with method1): 0.00\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluateRandomly(encoder, decoder, pairs, \"ita\", onTrain = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cc78df5",
   "metadata": {},
   "source": [
    "And here the results are almost ok; the last sentence is good, only the first one is wrong.  \n",
    "  \n",
    "# Other languages\n",
    "To have a quick try at other languages, we first prepare a helper function to run the pipeline (read, prepare the data, train the model, evaluate):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cc730c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def runETLpipeline(language):\n",
    "        # Step1 : read and prepare the data\n",
    "    input_lang, output_lang, pairs = prepareData(language, False)   # eng -> chinese\n",
    "        # Step2: load data\n",
    "    trainData = get_trainDataloader(input_lang, output_lang, pairs, myDevice)\n",
    "    \n",
    "    print(\"=====\")\n",
    "        # Step3: instantiate the decoder in the output language\n",
    "    decoder = AttnDecoderRNN(HIDDEN_SIZE, output_lang.n_words)\n",
    "    decoder = decoder.to(myDevice)\n",
    "    \n",
    "    print(\"Decoder's state_dict:\")\n",
    "    for param_tensor in decoder.state_dict():\n",
    "        print(param_tensor, \"\\t\", decoder.state_dict()[param_tensor].size())\n",
    "        \n",
    "    print(\"=====\")\n",
    "    print(decoder)\n",
    "    print(\"=====\")\n",
    "    \n",
    "    \n",
    "        # Step4: training\n",
    "    train(trainData, encoder, decoder, n_epochs=20, print_every=5, plot_every=5)\n",
    "\n",
    "    print(\"=====\")\n",
    "    print (pairs[42]) # verify\n",
    "\n",
    "\n",
    "        # Step5: evaluation\n",
    "    evaluateRandomly(encoder, decoder, pairs)\n",
    "    evaluateRandomly(encoder, decoder, pairs, onTrain = False)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3876ce6b",
   "metadata": {},
   "source": [
    "# Japanese\n",
    "\n",
    "Let's see how it works with a non-latin language: Japanese"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "d9988b57",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_PERCENT = 0.8  # not many sentences in the dataset so we can increase the train percentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7221ca3c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#runETLpipeline('jpn')\n",
    "# I prefer to run each single part, to check mistakes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17b5fe7f",
   "metadata": {},
   "source": [
    "Train loss was quickly reduced (probably 10-15 epochs would have been enough) and again the train sentences are right translated while the test sentences are wrong."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "id": "af37c8ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading lines...\n",
      "Read 115492 sentence pairs\n",
      "Trimmed to 39815 sentence pairs\n",
      "Counting words...\n",
      "Counted words:\n",
      "eng 7167\n",
      "jpn 10656\n"
     ]
    }
   ],
   "source": [
    "input_lang, output_lang, pairs = prepareData('jpn', False)   # eng -> chinese\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "id": "ded3a078",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'eng'"
      ]
     },
     "execution_count": 326,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_lang.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "id": "c14f6c2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'jpn'"
      ]
     },
     "execution_count": 327,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_lang.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "id": "99255902",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10656"
      ]
     },
     "execution_count": 328,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_lang.n_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "id": "3fc5ca08",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hello', 'もしもし']"
      ]
     },
     "execution_count": 329,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pairs[42]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "id": "4bf97311",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 330,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_lang.word2index[\"もしもし\"]  # get the index "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "id": "3d0eb974",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'もしもし'"
      ]
     },
     "execution_count": 331,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_lang.index2word[6]  #  get the word associated to index 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "id": "c8699309",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 332,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_lang.word2index[\"hello\"] # works also for english "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "id": "ba121d9f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 333,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_lang.word2count['もしもし'] # number of occurences of word 'ciao'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "id": "6e80ba08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['why not', 'なせいけないの？']"
      ]
     },
     "execution_count": 334,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pairs[299]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a81b5564",
   "metadata": {},
   "source": [
    "Pairs are the data, basically a list with sentences in pairs: english and foreign language, in this case Italian:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "id": "40499c25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i like it', '気に入ってます']"
      ]
     },
     "execution_count": 335,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pairs[620]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "id": "50ce74df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[469, 87, 186, 11, 112]"
      ]
     },
     "execution_count": 336,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indexesFromSentence(output_lang, pairs[620][1])  # input language is English"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "id": "ca3a2782",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train sentences: 3981\n"
     ]
    }
   ],
   "source": [
    "trainData = get_trainDataloader(input_lang, output_lang, pairs, myDevice)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "id": "74aa1640",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source: torch.Size([32, 10])\n",
      "Target: torch.Size([32, 10])\n"
     ]
    }
   ],
   "source": [
    "# Check a batch\n",
    "for src_batch, tgt_batch in trainData:\n",
    "    print(\"Source:\", src_batch.shape)\n",
    "    print(\"Target:\", tgt_batch.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "id": "8dff085d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 339,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pick a random index less than the batch size.\n",
    "index = random.randrange(len(src_batch))\n",
    "index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "id": "0bf799aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i\n",
      "left\n",
      "tom\n",
      "EOS\n",
      "SOS\n",
      "SOS\n",
      "SOS\n",
      "SOS\n",
      "SOS\n",
      "SOS\n"
     ]
    }
   ],
   "source": [
    "for i in src_batch[index]:\n",
    "    print (input_lang.index2word[i.item()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "id": "07638fce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "トム\n",
      "と\n",
      "は\n",
      "別れ\n",
      "た\n",
      "わ\n",
      "よ\n",
      "EOS\n",
      "SOS\n",
      "SOS\n"
     ]
    }
   ],
   "source": [
    "for i in tgt_batch[index]:\n",
    "    print (output_lang.index2word[i.item()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "id": "73a92111",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder = AttnDecoderRNN(HIDDEN_SIZE, output_lang.n_words)\n",
    "decoder = decoder.to(myDevice)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "id": "d688bd03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decoder's state_dict:\n",
      "embedding.weight \t torch.Size([10656, 128])\n",
      "attention.Wa.weight \t torch.Size([128, 128])\n",
      "attention.Wa.bias \t torch.Size([128])\n",
      "attention.Ua.weight \t torch.Size([128, 128])\n",
      "attention.Ua.bias \t torch.Size([128])\n",
      "attention.Va.weight \t torch.Size([1, 128])\n",
      "attention.Va.bias \t torch.Size([1])\n",
      "gru.weight_ih_l0 \t torch.Size([384, 256])\n",
      "gru.weight_hh_l0 \t torch.Size([384, 128])\n",
      "gru.bias_ih_l0 \t torch.Size([384])\n",
      "gru.bias_hh_l0 \t torch.Size([384])\n",
      "out.weight \t torch.Size([10656, 128])\n",
      "out.bias \t torch.Size([10656])\n"
     ]
    }
   ],
   "source": [
    "print(\"Decoder's state_dict:\")\n",
    "for param_tensor in decoder.state_dict():\n",
    "    print(param_tensor, \"\\t\", decoder.state_dict()[param_tensor].size())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "id": "39e3d9ab",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting train of the model ...\n",
      "time since start (estimated remaining) | epoch / 30 | progress (%) | loss average\n",
      "1m 39s (- 3m 19s) | 10 | 33% | 1.7735\n",
      "3m 25s (- 1m 42s) | 20 | 66% | 0.7065\n",
      "4m 56s (- 0m 0s) | 30 | 100% | 0.3200\n",
      "Training completed. Here is the loss plot:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train(trainData, encoder, decoder, n_epochs=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "id": "02eae8b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "彼女 は 背 か 高い <EOS>\n"
     ]
    }
   ],
   "source": [
    "translationCM = translate(encoder, decoder, 'there is no limit to the universe', input_lang, output_lang)\n",
    "print(' '.join(w for w in translationCM))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "158357ac",
   "metadata": {},
   "source": [
    "Almost ...  there is no room in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "id": "ea517e81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating 3 random sentences from train dataset\n",
      "\n",
      "\n",
      "train split: 3981\n",
      "> input sentence in English \n",
      " = target sentence translated in selected language \n",
      "< Output sentence from the model\n",
      "\n",
      "> years passed\n",
      "= 年月か経った\n",
      "< 年月 か 経っ まし た\n",
      "NLTK BLEU-4 (smoothed with method1): 0.06\n",
      "\n",
      "> no one died\n",
      "= 誰も死ななかった\n",
      "< 誰 も 死な なかっ なかっ た 虚しい 死ん しゃっ\n",
      "NLTK BLEU-4 (smoothed with method1): 0.03\n",
      "\n",
      "> good for you\n",
      "= 良かったてすね\n",
      "< 良かったて す か ?\n",
      "NLTK BLEU-4 (smoothed with method1): 0.07\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluateRandomly(encoder, decoder, pairs, \"jpn\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6038aefc",
   "metadata": {},
   "source": [
    "# Chinese\n",
    "Let's do the same with Chinese"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "id": "3c08cc49",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_PERCENT = 0.8 # even bigger train dataset, hopefully this will improve the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "id": "766b417e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading lines...\n",
      "Read 30919 sentence pairs\n",
      "Trimmed to 11077 sentence pairs\n",
      "Counting words...\n",
      "Counted words:\n",
      "eng 4104\n",
      "cmn 6930\n"
     ]
    }
   ],
   "source": [
    "input_lang, output_lang, pairs = prepareData('cmn', False)   # eng -> chinese\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "id": "5f27c30a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['be nice', '友善点']"
      ]
     },
     "execution_count": 351,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pairs[42]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "id": "b1c888e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[57, 55]"
      ]
     },
     "execution_count": 352,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indexesFromSentence(output_lang, pairs[42][1])  # input language is English"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "id": "27f08aae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'友善'"
      ]
     },
     "execution_count": 353,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_lang.index2word[57]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "id": "3f7004d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['release him', '放开他']"
      ]
     },
     "execution_count": 354,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pairs[599]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "id": "8be6f1d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train sentences: 8861\n"
     ]
    }
   ],
   "source": [
    "trainData = get_trainDataloader(input_lang, output_lang, pairs, myDevice)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "id": "0a5490d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source: torch.Size([32, 10])\n",
      "Target: torch.Size([32, 10])\n"
     ]
    }
   ],
   "source": [
    "# Check a batch\n",
    "for src_batch, tgt_batch in trainData:\n",
    "    print(\"Source:\", src_batch.shape)\n",
    "    print(\"Target:\", tgt_batch.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "id": "734576fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 357,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pick a random index less than the batch size.\n",
    "index = random.randrange(len(src_batch))\n",
    "index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "id": "17d0b8c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "it\n",
      "is\n",
      "pitch\n",
      "dark\n",
      "EOS\n",
      "SOS\n",
      "SOS\n",
      "SOS\n",
      "SOS\n",
      "SOS\n"
     ]
    }
   ],
   "source": [
    "for i in src_batch[index]:\n",
    "    print (input_lang.index2word[i.item()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "id": "13847770",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "天色\n",
      "漆黑\n",
      "EOS\n",
      "SOS\n",
      "SOS\n",
      "SOS\n",
      "SOS\n",
      "SOS\n",
      "SOS\n",
      "SOS\n"
     ]
    }
   ],
   "source": [
    "for i in tgt_batch[index]:\n",
    "    print (output_lang.index2word[i.item()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "id": "0aa9d943",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder = AttnDecoderRNN(HIDDEN_SIZE, output_lang.n_words)\n",
    "decoder = decoder.to(myDevice)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "id": "85ff50af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decoder's state_dict:\n",
      "embedding.weight \t torch.Size([6930, 128])\n",
      "attention.Wa.weight \t torch.Size([128, 128])\n",
      "attention.Wa.bias \t torch.Size([128])\n",
      "attention.Ua.weight \t torch.Size([128, 128])\n",
      "attention.Ua.bias \t torch.Size([128])\n",
      "attention.Va.weight \t torch.Size([1, 128])\n",
      "attention.Va.bias \t torch.Size([1])\n",
      "gru.weight_ih_l0 \t torch.Size([384, 256])\n",
      "gru.weight_hh_l0 \t torch.Size([384, 128])\n",
      "gru.bias_ih_l0 \t torch.Size([384])\n",
      "gru.bias_hh_l0 \t torch.Size([384])\n",
      "out.weight \t torch.Size([6930, 128])\n",
      "out.bias \t torch.Size([6930])\n"
     ]
    }
   ],
   "source": [
    "print(\"Decoder's state_dict:\")\n",
    "for param_tensor in decoder.state_dict():\n",
    "    print(param_tensor, \"\\t\", decoder.state_dict()[param_tensor].size())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "id": "2f182745",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting train of the model ...\n",
      "time since start (estimated remaining) | epoch / 80 | progress (%) | loss average\n",
      "4m 49s (- 14m 27s) | 20 | 25% | 1.0840\n",
      "9m 54s (- 9m 54s) | 40 | 50% | 0.1633\n",
      "14m 31s (- 4m 50s) | 60 | 75% | 0.0631\n",
      "19m 8s (- 0m 0s) | 80 | 100% | 0.0441\n",
      "Training completed. Here is the loss plot:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train(trainData, encoder, decoder, n_epochs=80, print_every=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "id": "e8d8db44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cmn'"
      ]
     },
     "execution_count": 363,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "  # let's try first with the test sentence\n",
    "output_lang.name\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "id": "21894615",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "我 爱 輕 <EOS>\n"
     ]
    }
   ],
   "source": [
    "translationCM = translate(encoder, decoder, 'i love artificial intelligence', input_lang, output_lang)\n",
    "print(' '.join(w for w in translationCM))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ed45fff",
   "metadata": {},
   "source": [
    "\" I love this machine\"  \n",
    "almost..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "id": "38f0c01d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating 3 random sentences from train dataset\n",
      "\n",
      "\n",
      "train split: 8861\n",
      "> input sentence in English \n",
      " = target sentence translated in selected language \n",
      "< Output sentence from the model\n",
      "\n",
      "> don't touch my camera\n",
      "= 不要碰我的相機\n",
      "< 不要 碰 我 的 相機\n",
      "NLTK BLEU-4 (smoothed with method1): 0.07\n",
      "\n",
      "> can i touch it\n",
      "= 可以碰嗎？\n",
      "< 可以 碰 嗎 ？\n",
      "NLTK BLEU-4 (smoothed with method1): 0.11\n",
      "\n",
      "> i work in a factory\n",
      "= 我在一家工廠工作\n",
      "< 我 在 一家 工廠 工作\n",
      "NLTK BLEU-4 (smoothed with method1): 0.06\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluateRandomly(encoder, decoder, pairs, \"cmn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "id": "c01a82e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating 3 random sentences from test dataset\n",
      "\n",
      "\n",
      "train split: 8861\n",
      "> input sentence in English \n",
      " = target sentence translated in selected language \n",
      "< Output sentence from the model\n",
      "\n",
      "> tom visited boston last year\n",
      "= 湯姆去年去了波士頓\n",
      "< 汤姆 住 波士顿\n",
      "NLTK BLEU-4 (smoothed with method1): 0.00\n",
      "\n",
      "> the election was unanimous\n",
      "= 选举一致通过了\n",
      "< 选举 一致 号 有没有 空 了 ？\n",
      "NLTK BLEU-4 (smoothed with method1): 0.03\n",
      "\n",
      "> my passport's been stolen\n",
      "= 我的护照被人偷了\n",
      "< 我 的 表 被 提到 赢 了\n",
      "NLTK BLEU-4 (smoothed with method1): 0.05\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluateRandomly(encoder, decoder, pairs, \"cmn\", onTrain = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "463c0dc6",
   "metadata": {},
   "source": [
    "# German to English\n",
    "\n",
    "Finally, let's see how it works with a reversed translation: from German to English"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "id": "c4e5dcd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading lines...\n",
      "Read 320340 sentence pairs\n",
      "Trimmed to 275316 sentence pairs\n",
      "Counting words...\n",
      "Counted words:\n",
      "deu 38787\n",
      "eng 19300\n"
     ]
    }
   ],
   "source": [
    "input_lang, output_lang, pairs = prepareData('deu', True)   # German -> english\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a98c10b",
   "metadata": {},
   "source": [
    "The input and output languages contain several attributes (name, number of words, ...) and methods (convert a word into its index and viceversa):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "id": "846ac205",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'deu'"
      ]
     },
     "execution_count": 369,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_lang.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "id": "92b034d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'eng'"
      ]
     },
     "execution_count": 370,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_lang.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "id": "746195c1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19300"
      ]
     },
     "execution_count": 371,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_lang.n_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "id": "343300d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17"
      ]
     },
     "execution_count": 372,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_lang.word2index[\"hello\"]  # get the index of english word \"hello\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "id": "3ccef6ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hello'"
      ]
     },
     "execution_count": 373,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_lang.index2word[17]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "id": "0c2ec058",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "626"
      ]
     },
     "execution_count": 374,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_lang.word2index[\"liebe\"] # german"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "id": "555a7610",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "56"
      ]
     },
     "execution_count": 375,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_lang.word2count['hello'] # number of occurences of word 'hello'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db6952cc",
   "metadata": {},
   "source": [
    "Pairs are the data, basically a list with sentences in pairs: english and foreign language, in this case German:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "id": "c91a6b24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['entschuldigung', 'sorry']"
      ]
     },
     "execution_count": 376,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pairs[42]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "id": "71252792",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_PERCENT = 0.1  # huge train dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "id": "f2e3bd70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train sentences: 27531\n"
     ]
    }
   ],
   "source": [
    "trainData = get_trainDataloader(input_lang, output_lang, pairs, myDevice)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "id": "b1347f27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source: torch.Size([32, 10])\n",
      "Target: torch.Size([32, 10])\n"
     ]
    }
   ],
   "source": [
    "# Check a batch\n",
    "for src_batch, tgt_batch in trainData:\n",
    "    print(\"Source:\", src_batch.shape)\n",
    "    print(\"Target:\", tgt_batch.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "id": "6709ad7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 380,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pick a random index less than the batch size.\n",
    "index = random.randrange(len(src_batch))\n",
    "index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "id": "c26b2a71",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([  59, 1748,    1,    0,    0,    0,    0,    0,    0,    0])\n"
     ]
    }
   ],
   "source": [
    "print(tgt_batch[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "id": "ab6520c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i'm\n",
      "expecting\n",
      "EOS\n",
      "SOS\n",
      "SOS\n",
      "SOS\n",
      "SOS\n",
      "SOS\n",
      "SOS\n",
      "SOS\n"
     ]
    }
   ],
   "source": [
    "for i in tgt_batch[index]:\n",
    "    print (output_lang.index2word[i.item()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "id": "415a8208",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([  33,   88,  776, 2477,    1,    0,    0,    0,    0,    0])\n"
     ]
    }
   ],
   "source": [
    "print(src_batch[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "id": "2ba9145d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ich\n",
      "bin\n",
      "guter\n",
      "hoffnung\n",
      "EOS\n",
      "SOS\n",
      "SOS\n",
      "SOS\n",
      "SOS\n",
      "SOS\n"
     ]
    }
   ],
   "source": [
    "for i in src_batch[index]:\n",
    "    print (input_lang.index2word[i.item()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "id": "af26b235",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder = AttnDecoderRNN(HIDDEN_SIZE, output_lang.n_words)\n",
    "decoder = decoder.to(myDevice)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "id": "daaa0f01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decoder's state_dict:\n",
      "embedding.weight \t torch.Size([19300, 128])\n",
      "attention.Wa.weight \t torch.Size([128, 128])\n",
      "attention.Wa.bias \t torch.Size([128])\n",
      "attention.Ua.weight \t torch.Size([128, 128])\n",
      "attention.Ua.bias \t torch.Size([128])\n",
      "attention.Va.weight \t torch.Size([1, 128])\n",
      "attention.Va.bias \t torch.Size([1])\n",
      "gru.weight_ih_l0 \t torch.Size([384, 256])\n",
      "gru.weight_hh_l0 \t torch.Size([384, 128])\n",
      "gru.bias_ih_l0 \t torch.Size([384])\n",
      "gru.bias_hh_l0 \t torch.Size([384])\n",
      "out.weight \t torch.Size([19300, 128])\n",
      "out.bias \t torch.Size([19300])\n"
     ]
    }
   ],
   "source": [
    "print(\"Decoder's state_dict:\")\n",
    "for param_tensor in decoder.state_dict():\n",
    "    print(param_tensor, \"\\t\", decoder.state_dict()[param_tensor].size())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "id": "5fb0fe35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AttnDecoderRNN(\n",
       "  (embedding): Embedding(19300, 128)\n",
       "  (attention): BahdanauAttention(\n",
       "    (Wa): Linear(in_features=128, out_features=128, bias=True)\n",
       "    (Ua): Linear(in_features=128, out_features=128, bias=True)\n",
       "    (Va): Linear(in_features=128, out_features=1, bias=True)\n",
       "  )\n",
       "  (gru): GRU(256, 128, batch_first=True)\n",
       "  (out): Linear(in_features=128, out_features=19300, bias=True)\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 387,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "id": "dd07f099",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting train of the model ...\n",
      "time since start (estimated remaining) | epoch / 30 | progress (%) | loss average\n",
      "12m 35s (- 25m 10s) | 10 | 33% | 0.7688\n",
      "25m 33s (- 12m 46s) | 20 | 66% | 0.1994\n",
      "39m 11s (- 0m 0s) | 30 | 100% | 0.1050\n",
      "Training completed. Here is the loss plot:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train(trainData, encoder, decoder, n_epochs = 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "id": "304f520a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i love you <EOS>\n"
     ]
    }
   ],
   "source": [
    "translationEN = translate(encoder, decoder, 'ich liebe dich', input_lang, output_lang)\n",
    "print(' '.join(w for w in translationEN))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "id": "577b040f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train sentences: 27531\n"
     ]
    }
   ],
   "source": [
    "        # get the training split\n",
    "n = len(pairs)\n",
    "trainSplit = int(n * TRAIN_PERCENT)\n",
    "print(f\"train sentences: {trainSplit}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "id": "853787b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating 3 random sentences from train dataset\n",
      "\n",
      "\n",
      "train split: 27531\n",
      "> input sentence in English \n",
      " = target sentence translated in selected language \n",
      "< Output sentence from the model\n",
      "\n",
      "> das hat niemand gesagt\n",
      "= no one said that\n",
      "< nobody said that\n",
      "NLTK BLEU-4 (smoothed with method1): 0.00\n",
      "\n",
      "> es ist so still\n",
      "= it's so quiet\n",
      "< it's so quiet\n",
      "NLTK BLEU-4 (smoothed with method1): 0.00\n",
      "\n",
      "> komm, sing mit mir\n",
      "= come sing with me\n",
      "< i sing\n",
      "NLTK BLEU-4 (smoothed with method1): 0.15\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluateRandomly(encoder, decoder, pairs, \"deu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65c8b7dd",
   "metadata": {},
   "source": [
    "Almost perfect, with few epochs and few examples, even if the BLEU metric is not correct (too short sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "id": "51739fe3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating 3 random sentences from test dataset\n",
      "\n",
      "\n",
      "train split: 27531\n",
      "> input sentence in English \n",
      " = target sentence translated in selected language \n",
      "< Output sentence from the model\n",
      "\n",
      "> tom ist nie nach hause gekommen\n",
      "= tom never came home\n",
      "< tom made home\n",
      "NLTK BLEU-4 (smoothed with method1): 0.00\n",
      "\n",
      "> ich habe gehort, daß ihr jemanden dafur bezahlt hattet\n",
      "= i heard that you paid someone to do that\n",
      "< i saw you\n",
      "NLTK BLEU-4 (smoothed with method1): 0.11\n",
      "\n",
      "> vielleicht konnten sie mir helfen\n",
      "= maybe you could help me\n",
      "< i may tell me\n",
      "NLTK BLEU-4 (smoothed with method1): 0.00\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluateRandomly(encoder, decoder, pairs, \"deu\", onTrain = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "id": "5dd94084",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluateOnTest(encoder, decoder, pairs, input_lang, output_lang):\n",
    "\n",
    "    bleuTotal = 0\n",
    "    n = 0\n",
    "    \n",
    "    for i in range(trainSplit+1, len(pairs)):\n",
    "        try:\n",
    "            output_words = translate(encoder, decoder, pairs[i][0], input_lang, output_lang)\n",
    "\n",
    "            \n",
    "            output_sentence = ' '.join(output_words)\n",
    "            output_sentence = output_sentence.removesuffix(\"<EOS>\")\n",
    "\n",
    "            b = sentence_bleu(output_sentence, pairs[i][1], smoothing_function=chencherry.method1)\n",
    "            bleuTotal += b\n",
    "            n += 1\n",
    "\n",
    "        except:\n",
    "            continue   # just skip if there was any problem (usually word not found)\n",
    "            \n",
    "    print(\"Total examples analysed =\", n)\n",
    "    print(f\"Average BLEU (smoothed): {(bleuTotal/n):.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "id": "f958b800",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total examples analysed = 201183\n",
      "Average BLEU (smoothed): 0.012\n"
     ]
    }
   ],
   "source": [
    "evaluateOnTest(encoder, decoder, pairs, input_lang, output_lang)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1b15137",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
