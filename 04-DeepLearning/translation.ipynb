{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5c691dcc",
   "metadata": {},
   "source": [
    "# Translation\n",
    "\n",
    "In this project we will be teaching a neural network to translate from a language to English or viceversa.  \n",
    "  \n",
    "This is made possible by the simple but powerful idea of the **sequence to sequence network**, in which two recurrent neural networks work together to transform one sequence to another. An **encoder network** condenses an input sequence into a vector and a **decoder network** unfolds that vector into a new sequence.  \n",
    "  \n",
    "A good probabilistic translation model requires a large dataset (to cover as many cases as possible) and extensive training, so I will just show how it works with limited examples and the translation accuracy is not in focus (no real validation / test).  \n",
    "  \n",
    "## The dataset\n",
    "\n",
    "The dataset used in the example involves short sentence pairs used in the flash card software Anki.  \n",
    "  \n",
    "The dataset is called “Tab-delimited Bilingual Sentence Pairs” and is part of the [Tatoeba Project](https://tatoeba.org/) and listed on the [ManyThings.org site](https://www.manythings.org/anki/) for helping English as a Second Language students.\n",
    "\n",
    "\n",
    "The files have an attribution column so we need to strip it away before reading the input files.  \n",
    "This has to be done only once.  \n",
    "  \n",
    "### Prepare input files (one-off)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7b3fb7b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Script to strip attribution information from tab-separated translation files.\n",
    "\n",
    "Input format: English_text \\t Other_language_text \\t CC-BY_attribution\n",
    "Output format: English_text \\t Other_language_text\n",
    "\"\"\"\n",
    "\n",
    "import sys\n",
    "import os\n",
    "\n",
    "def strip_attribution(input_file, output_file=None):\n",
    "    \"\"\"\n",
    "    Strip attribution column from tab-separated translation file.\n",
    "    \n",
    "    Args:\n",
    "        input_file (str): Path to input file\n",
    "        output_file (str): Path to output file (optional, defaults to input_clean.txt)\n",
    "    \"\"\"\n",
    "    \n",
    "    # Set default output filename if not provided\n",
    "    if output_file is None:\n",
    "        base_name = os.path.splitext(input_file)[0]\n",
    "        output_file = f\"{base_name}_clean.txt\"  # create a file with suffix clean\n",
    "    \n",
    "    try:\n",
    "        with open(input_file, 'r', encoding='utf-8') as infile:\n",
    "            with open(output_file, 'w', encoding='utf-8') as outfile:\n",
    "                line_count = 0\n",
    "                processed_count = 0\n",
    "                \n",
    "                for line in infile:\n",
    "                    line_count += 1\n",
    "                    line = line.rstrip('\\n\\r')\n",
    "                    \n",
    "                    # Skip empty lines\n",
    "                    if not line.strip():\n",
    "                        continue\n",
    "                    \n",
    "                    # Split by tab\n",
    "                    parts = line.split('\\t')\n",
    "                    \n",
    "                    # Check if we have at least 3 parts (English, Other, Attribution)\n",
    "                    if len(parts) >= 3:\n",
    "                        english_text = parts[0]\n",
    "                        other_text = parts[1]\n",
    "                        \n",
    "                        # Write only the first two columns\n",
    "                        outfile.write(f\"{english_text}\\t{other_text}\\n\")\n",
    "                        processed_count += 1\n",
    "                    else:\n",
    "                        print(f\"Warning: Line {line_count} doesn't have expected format: {line}\")\n",
    "                \n",
    "                print(f\"Processing complete!\")\n",
    "                print(f\"Total lines read: {line_count}\")\n",
    "                print(f\"Lines processed: {processed_count}\")\n",
    "                print(f\"Output written to: {output_file}\")\n",
    "                \n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: Input file '{input_file}' not found.\")\n",
    "        return False\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing file: {e}\")\n",
    "        return False\n",
    "    \n",
    "    return True\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a44d8e3",
   "metadata": {},
   "source": [
    "I did it for a couple of languages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57f5a1ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "strip_attribution(\"../datasets/translations/ita.txt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a03624c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "strip_attribution(\"../datasets/translations/jpn.txt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c2ee7b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "strip_attribution(\"../datasets/translations/cmn.txt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "32a6d209",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 381352\r\n",
      "-rw-r--r--@ 1 Massimo  staff   4.2M Jun  4 01:29 cmn.txt\r\n",
      "-rw-r--r--  1 Massimo  staff   1.8M Jun  7 17:16 cmn_clean.txt\r\n",
      "-rw-r--r--@ 1 Massimo  staff    48M Jun  4 01:29 deu.txt\r\n",
      "-rw-r--r--  1 Massimo  staff    22M Jun  6 16:31 deu_clean.txt\r\n",
      "-rw-r--r--@ 1 Massimo  staff   9.1M Mar 12  2017 fra_clean.txt\r\n",
      "-rw-r--r--@ 1 Massimo  staff    53M Jun  4 01:29 ita.txt\r\n",
      "-rw-r--r--  1 Massimo  staff    22M Jun  7 17:15 ita_clean.txt\r\n",
      "-rw-r--r--@ 1 Massimo  staff    18M Jun  4 01:29 jpn.txt\r\n",
      "-rw-r--r--@ 1 Massimo  staff   8.7M Jun  7 17:15 jpn_clean.txt\r\n"
     ]
    }
   ],
   "source": [
    "# Have a look at the available datasets\n",
    "\n",
    "! ls -lh \"../datasets/translations/\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3efffc3",
   "metadata": {},
   "source": [
    "## Prepare data structures\n",
    "\n",
    "We will now prepare the data structures to store the input data and a couple of helper functions.\n",
    "### Unicode to ASCII\n",
    "The files are all in Unicode, to simplify we will turn Unicode characters to ASCII, make everything lowercase, and trim most punctuation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7b9c8404",
   "metadata": {},
   "outputs": [],
   "source": [
    "import unicodedata\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cf078988",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn a Unicode string to plain ASCII, thanks to\n",
    "# https://stackoverflow.com/a/518232/2809427\n",
    "def _unicodeToAscii(s):\n",
    "    return ''.join(\n",
    "        c for c in unicodedata.normalize('NFD', s)\n",
    "        if unicodedata.category(c) != 'Mn'\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "428c6459",
   "metadata": {},
   "source": [
    "We can see how this works for a japanese sentence:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3fa1e37e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "なさい。\n"
     ]
    }
   ],
   "source": [
    "japString = \"なさい。\"\n",
    "print(japString)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "600c62c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "なさい。\n"
     ]
    }
   ],
   "source": [
    "print(_unicodeToAscii(japString))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53078955",
   "metadata": {},
   "source": [
    "### Normalise strings\n",
    "Lowercase, trim and remove non-letter characters helper.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b82b66e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _normaliseString(s):\n",
    "    s = _unicodeToAscii(s.lower().strip())\n",
    "    s = re.sub(r\"([.!?])\", r\" \\1\", s)\n",
    "    return s.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "10bba4bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "なさい。\n"
     ]
    }
   ],
   "source": [
    "print(_normaliseString(japString))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "id": "ba865e78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this is a strange sentence\n"
     ]
    }
   ],
   "source": [
    "print(_normaliseString(\" this is a STRANGE sentence \"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c7dd169",
   "metadata": {},
   "source": [
    "### Filter only short sentences\n",
    "Since there are a lot of example sentences and we want to train something quickly, we’ll trim the data set to only relatively short and simple sentences. Here the maximum length is used as threshold.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "658a7cf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LENGTH = 10  # keep only sentences up to 10 words\n",
    "\n",
    "def _filterSentence(s):\n",
    "    # s: input string\n",
    "    # returns True if s is shorter than threshold MAX_LENGTH\n",
    "    \n",
    "    return len(s.split(' ')) < MAX_LENGTH\n",
    "\n",
    "def _filterPair(p):\n",
    "    # p: input pair of strings\n",
    "    # returns True if s is shorter than threshold MAX_LENGTH\n",
    "    return _filterSentence(p[0]) and _filterSentence(p[1])\n",
    " \n",
    "\n",
    "\n",
    "def _filterPairs(pairs):\n",
    "    return [pair for pair in pairs if _filterPair(pair)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8d4f63aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_filterSentence(japString)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9a5de4eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_filterSentence(\"this is a sentence too long, note that punctuation is included in the count!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "307f6eca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "japPair = ['please.', japString]\n",
    "_filterPair(japPair)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1b45878",
   "metadata": {},
   "source": [
    "## Read the files and prepare the data\n",
    "\n",
    "To read the data file we will split the file into lines and then split lines into pairs. The files are all English → Other Language, so if we want to translate from Other Language → English we can use the reverse flag to reverse the pairs.  \n",
    "Read lines and words are stored in two variables of **class Lang**: one for English and one for input language. \n",
    "The class Lang (language) contains the language name (a string), the found list of words and methods to index a word into a number and viceversa (used for training the network).  \n",
    "  \n",
    "  The full process for preparing the data is:\n",
    "\n",
    "- Read text file and split into lines, split lines into pairs\n",
    "\n",
    "- Normalize text, filter by length and content\n",
    "\n",
    "- Make word lists from sentences in pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "88ea9791",
   "metadata": {},
   "outputs": [],
   "source": [
    "SOS_token = 0  # Note the use of start and end sentence marks.  \n",
    "EOS_token = 1\n",
    "\n",
    "# The Language class, contains the words\n",
    "\n",
    "class Lang:\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.word2index = {}\n",
    "        self.word2count = {}\n",
    "        self.index2word = {SOS_token: \"SOS\", EOS_token: \"EOS\"}\n",
    "        self.n_words = 2  # Count SOS and EOS\n",
    "\n",
    "    def addSentence(self, sentence):\n",
    "        for word in sentence.split(' '):\n",
    "            self.addWord(word)\n",
    "\n",
    "    def addWord(self, word):\n",
    "        if word not in self.word2index:\n",
    "            self.word2index[word] = self.n_words\n",
    "            self.word2count[word] = 1\n",
    "            self.index2word[self.n_words] = word\n",
    "            self.n_words += 1\n",
    "        else:\n",
    "            self.word2count[word] += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b77b28be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepareData(lang, reverse=False):\n",
    "\n",
    "    # read the data from the given file and instantiate the proper Language class\n",
    "    # lang: string representing the language; used to access the file\n",
    "    # reverse: boolean; true if translation is from language to English; false if viceversa\n",
    "    # return: \n",
    "    # - Input Lang class\n",
    "    # - Output Lang class\n",
    "    # - Pairs of sentences\n",
    "    \n",
    "    print(\"Reading lines...\")\n",
    "\n",
    "        # Read the file and split into lines\n",
    "    lines = open('../datasets/translations/%s_clean.txt' % (lang), encoding='utf-8').\\\n",
    "        read().strip().split('\\n')\n",
    "\n",
    "        # Split every line into pairs and normalize\n",
    "    pairs = [[_normalizeString(s) for s in l.split('\\t')] for l in lines]\n",
    "    print(\"Read %s sentence pairs\" % len(pairs))\n",
    "\n",
    "        # Reverse pairs, make Lang instances\n",
    "    if reverse:\n",
    "        pairs = [list(reversed(p)) for p in pairs]\n",
    "        input_lang = Lang(lang)\n",
    "        output_lang = Lang(\"eng\")\n",
    "    else:\n",
    "        input_lang = Lang(\"eng\")\n",
    "        output_lang = Lang(lang)\n",
    "\n",
    "        \n",
    "    #input_lang, output_lang, pairs = readLangs(lang, reverse)\n",
    "    pairs = _filterPairs(pairs)\n",
    "    print(\"Trimmed to %s sentence pairs\" % len(pairs))\n",
    "    \n",
    "    print(\"Counting words...\")\n",
    "    for pair in pairs:\n",
    "        input_lang.addSentence(pair[0])\n",
    "        output_lang.addSentence(pair[1])\n",
    "    print(\"Counted words:\")\n",
    "    print(input_lang.name, input_lang.n_words)\n",
    "    print(output_lang.name, output_lang.n_words)\n",
    "    \n",
    "    return input_lang, output_lang, pairs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dce05356",
   "metadata": {},
   "source": [
    "# First example: English -> Italian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "938a6d6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading lines...\n",
      "Read 390190 sentence pairs\n",
      "Trimmed to 351325 sentence pairs\n",
      "Counting words...\n",
      "Counted words:\n",
      "eng 15028\n",
      "ita 29382\n"
     ]
    }
   ],
   "source": [
    "input_lang, output_lang, pairs = prepareData('ita', False)   # eng -> Italian\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9583145",
   "metadata": {},
   "source": [
    "The input and output languages contain several attributes (name, number of words, ...) and methods (convert a word into its index and viceversa):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "94bf2f53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'eng'"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_lang.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "f2d561c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ita'"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_lang.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "c3306e35",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29382"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_lang.n_words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4645d73e",
   "metadata": {},
   "source": [
    "A total of 23K words are stored for Italian. This number will be used to size the neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "de2244bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_lang.word2index[\"ciao\"]  # get the index of italian word \"ciao\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "52d6b700",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ciao'"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_lang.index2word[2]  #  get the word associated to index 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "3b90344c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "622"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_lang.word2index[\"love\"] # works also for english "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "ac387c2a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_lang.word2count['ciao'] # number of occurences of word 'ciao'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6c3cb93",
   "metadata": {},
   "source": [
    "Pairs are the data, basically a list with sentences in pairs: english and foreign language, in this case Italian:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "7f189c8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['do it .', 'lo faccia .']"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pairs[42]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c61cd4c",
   "metadata": {},
   "source": [
    "## Preparing Training Data\n",
    "To train, for each pair we will need an input tensor (indexes of the words in the input sentence) and target tensor (indexes of the words in the target sentence). While creating these vectors we will append the EOS token to both sequences.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "b010bd0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler\n",
    "from torch import optim\n",
    "\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "4f9a3b03",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "4ba19fc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For determinism\n",
    "\n",
    "SEED = 42\n",
    "\n",
    "random.seed(SEED)\n",
    "#np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "bfcd10d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_device():\n",
    "    \"\"\"\n",
    "    Get the best available device (CPU/GPU/MPS) with proper MPS handling.\n",
    "    \"\"\"\n",
    "    if torch.cuda.is_available():\n",
    "        return torch.device(\"cuda\")\n",
    "    elif torch.backends.mps.is_available():\n",
    "        # Check if Apple MPS is properly supported\n",
    "        try:\n",
    "            # Test MPS with a simple operation\n",
    "            test_tensor = torch.randn(2, 2, device=\"mps\")\n",
    "            _ = test_tensor + test_tensor\n",
    "            return torch.device(\"mps\")\n",
    "        except Exception as e:\n",
    "            print(f\"MPS available but not working properly: {e}\")\n",
    "            print(\"Falling back to CPU\")\n",
    "            return torch.device(\"cpu\")\n",
    "    else:\n",
    "        return torch.device(\"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "c692de9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n"
     ]
    }
   ],
   "source": [
    "# Set device\n",
    "myDevice = get_device()\n",
    "print(f\"Using device: {myDevice}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "067e97c4",
   "metadata": {},
   "source": [
    "### Embed data into tensors \n",
    "\n",
    "To embed text into tokens (using tokenise) and finally to indexes and tensors we need a couple of helper functions.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "b8f0db16",
   "metadata": {},
   "outputs": [],
   "source": [
    "def indexesFromSentence(lang, sentence):\n",
    "    return [lang.word2index[word] for word in sentence.split(' ')]\n",
    "\n",
    "def tensorFromSentence(lang, sentence):\n",
    "    indexes = indexesFromSentence(lang, sentence)\n",
    "    indexes.append(EOS_token)\n",
    "    \n",
    "    try:\n",
    "        \n",
    "        # Create tensor on CPU first, then move to device\n",
    "        tensor = torch.tensor(indexes, dtype=torch.long)\n",
    "        tensor = tensor.to(myDevice, non_blocking=True)\n",
    "        \n",
    "        return tensor.view(1, -1)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error creating tensor on {myDevice}: {e}\")\n",
    "        print(\"Creating tensor on CPU instead...\")\n",
    "        \n",
    "        # Fallback to CPU\n",
    "        tensor = torch.tensor(indexes, dtype=torch.long, device='cpu')\n",
    "        return tensor.view(1, -1)\n",
    "    \n",
    "\n",
    "def tensorsFromPair(pair):\n",
    "    input_tensor = tensorFromSentence(input_lang, pair[0])\n",
    "    target_tensor = tensorFromSentence(output_lang, pair[1])\n",
    "    return (input_tensor, target_tensor)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83ecaac8",
   "metadata": {},
   "source": [
    "The first helper, *indexesFromSentence* gets a sentence, tokenise it and maps each token into its index, based on the language:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "3cfad6b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[19, 622, 8722, 2454, 1210, 3212, 11051]"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testSentenceEN = \"i love machine learning and artificial intelligence\"\n",
    "\n",
    "indexesFromSentence(input_lang, testSentenceEN)  # input language is English"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e07a7898",
   "metadata": {},
   "source": [
    "Similarly, the helpr *tensorFromSentence* gets a sentence, tokenise it and maps each token into its tensor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "649b17c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[   19,   622,  8722,  2454,  1210,  3212, 11051,     1]])"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensorFromSentence(input_lang, testSentenceEN)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21c0ac8d",
   "metadata": {},
   "source": [
    "## Load the data\n",
    "Now we are ready to load the data for the model training.  \n",
    "After setting the language pre-processing criteria, the next step is to create batches of training data using iterators.    \n",
    "We use a batch of 32, can be customised below.  \n",
    "As the sentences are many and the training will be too long (depending on GPU/CPU), I take a small percentage of the entire set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "e0f5cf40",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32  # use this to set the training batch size\n",
    "TRAIN_PERCENT = 0.1  # use this to set the training size\n",
    "\n",
    "def get_trainDataloader(input_lang, output_lang, pairs, device):\n",
    "\n",
    "        # get the training split\n",
    "    n = len(pairs)\n",
    "    trainSplit = int(n * TRAIN_PERCENT)\n",
    "    print(f\"train sentences: {trainSplit}\")\n",
    "    \n",
    "        # Pre-allocate arrays on CPU \n",
    "    input_ids = np.zeros((trainSplit, MAX_LENGTH), dtype=np.int64)  \n",
    "    target_ids = np.zeros((trainSplit, MAX_LENGTH), dtype=np.int64) \n",
    "\n",
    "        # tokenise and get indexes\n",
    "    for idx, (inp, tgt) in enumerate(pairs[:trainSplit]):\n",
    "        inp_ids = indexesFromSentence(input_lang, inp)\n",
    "        tgt_ids = indexesFromSentence(output_lang, tgt)\n",
    "        inp_ids.append(EOS_token)\n",
    "        tgt_ids.append(EOS_token)\n",
    "        input_ids[idx, :len(inp_ids)] = inp_ids\n",
    "        target_ids[idx, :len(tgt_ids)] = tgt_ids\n",
    "\n",
    "        # Create tensors on CPU first, then move to device\n",
    "    try:\n",
    "            # Create tensors with proper dtype (int64/long is more compatible with MPS)\n",
    "        input_tensor = torch.from_numpy(input_ids).long()\n",
    "        target_tensor = torch.from_numpy(target_ids).long()\n",
    "    \n",
    "            # Move to device safely\n",
    "        input_tensor = input_tensor.to(device, non_blocking=True)\n",
    "        target_tensor = target_tensor.to(device, non_blocking=True)\n",
    "    \n",
    "        train_data = TensorDataset(input_tensor, target_tensor)\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error moving tensors to {device}: {e}\")\n",
    "        print(\"Falling back to CPU...\")\n",
    "        device = torch.device(\"cpu\")\n",
    "        input_tensor = torch.from_numpy(input_ids).long()\n",
    "        target_tensor = torch.from_numpy(target_ids).long()\n",
    "        \n",
    "        train_data = TensorDataset(input_tensor, target_tensor)\n",
    "\n",
    "\n",
    "\n",
    "    train_sampler = RandomSampler(train_data)\n",
    "    train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=BATCH_SIZE)\n",
    "    \n",
    "    return train_dataloader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbfae1e7",
   "metadata": {},
   "source": [
    "Get the train dataset for Italian language:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "66cc187b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train sentences: 35132\n"
     ]
    }
   ],
   "source": [
    "trainData = get_trainDataloader(input_lang, output_lang, pairs, myDevice)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "59386ce9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.utils.data.dataloader.DataLoader"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(trainData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "349e2402",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source: torch.Size([32, 10])\n",
      "Target: torch.Size([32, 10])\n"
     ]
    }
   ],
   "source": [
    "# Check a batch\n",
    "for src_batch, tgt_batch in trainData:\n",
    "    print(\"Source:\", src_batch.shape)\n",
    "    print(\"Target:\", tgt_batch.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "e8e57e3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pick a random index less than the batch size\n",
    "index = random.randrange(len(src_batch))\n",
    "index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "56993a5f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([  64,   60, 1098, 1739, 3201, 4967,    4,    1,    0,    0])\n"
     ]
    }
   ],
   "source": [
    "print(tgt_batch[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "e4d0a779",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "io\n",
      "ho\n",
      "bisogno\n",
      "delle\n",
      "mie\n",
      "chiavi\n",
      ".\n",
      "EOS\n",
      "SOS\n",
      "SOS\n"
     ]
    }
   ],
   "source": [
    "for i in tgt_batch[index]:\n",
    "    print (output_lang.index2word[i.item()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "6030a089",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([  19,  390,  571, 1999,    3,    1,    0,    0,    0,    0])\n"
     ]
    }
   ],
   "source": [
    "print(src_batch[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "cd6f1187",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i\n",
      "need\n",
      "my\n",
      "keys\n",
      ".\n",
      "EOS\n",
      "SOS\n",
      "SOS\n",
      "SOS\n",
      "SOS\n"
     ]
    }
   ],
   "source": [
    "for i in src_batch[index]:\n",
    "    print (input_lang.index2word[i.item()])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3884b41e",
   "metadata": {},
   "source": [
    "# Model\n",
    "\n",
    "Recurrent Neural Network, or RNN, is a network that operates on a sequence and uses its own output as input for subsequent steps.\n",
    "\n",
    "A **Sequence to Sequence** (seq2seq) network is a model consisting of two RNNs called the encoder and decoder. The encoder reads an input sequence and outputs a single vector and the decoder reads that vector to produce an output sequence.\n",
    "\n",
    "Unlike sequence prediction with a single RNN, where every input corresponds to an output, the seq2seq model frees us from sequence length and order, which makes it ideal for translation between two languages.  \n",
    "In the general case, input sequences and output sequences have different lengths and the entire input sequence is required in order to start predicting the target.  \n",
    "\n",
    "Consider the sentence *Je ne suis pas le chat noir* → I am not the black cat. Most of the words in the input sentence have a direct translation in the output sentence but are in slightly different orders, e.g. *chat noir* and black cat. Because of the *ne/pas* construction there is also one more word in the input sentence. It would be difficult to produce a correct translation directly from the sequence of input words.  \n",
    "  \n",
    "\n",
    "## The Encoder\n",
    "\n",
    "With a seq2seq model the encoder creates a single vector which, in the ideal case, encodes the “meaning” of the input sequence into a single vector — a single point in some N dimensional space of sentences.  \n",
    "This **Context Vector** is said to contain the abstract representation of the input language sequence.\n",
    "\n",
    "The encoder of a seq2seq network is a RNN that processes the input sequence and outputs some value for every word from the input sentence. For every input word the encoder outputs a vector and a hidden state, and uses the hidden state for the next input word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "f36c9157",
   "metadata": {},
   "outputs": [],
   "source": [
    "HIDDEN_SIZE = 128\n",
    "\n",
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, dropout_p=0.1):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size, batch_first=True)\n",
    "        self.dropout = nn.Dropout(dropout_p)\n",
    "\n",
    "    def forward(self, input):\n",
    "        embedded = self.dropout(self.embedding(input))\n",
    "        output, hidden = self.gru(embedded)\n",
    "        return output, hidden\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "6f109857",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = EncoderRNN(input_lang.n_words, HIDDEN_SIZE)\n",
    "encoder = encoder.to(myDevice)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "83a093e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoder's state_dict:\n",
      "embedding.weight \t torch.Size([15028, 128])\n",
      "gru.weight_ih_l0 \t torch.Size([384, 128])\n",
      "gru.weight_hh_l0 \t torch.Size([384, 128])\n",
      "gru.bias_ih_l0 \t torch.Size([384])\n",
      "gru.bias_hh_l0 \t torch.Size([384])\n"
     ]
    }
   ],
   "source": [
    "print(\"Encoder's state_dict:\")\n",
    "for param_tensor in encoder.state_dict():\n",
    "    print(param_tensor, \"\\t\", encoder.state_dict()[param_tensor].size())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "dc3a583e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EncoderRNN(\n",
       "  (embedding): Embedding(15028, 128)\n",
       "  (gru): GRU(128, 128, batch_first=True)\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c4c9a25",
   "metadata": {},
   "source": [
    "The encoder is pretty simple:\n",
    "- the input layer (embedding) is taking all the input language (in this case English) words (around 15k) \n",
    "- the hidden layer is a GRU (Gated Recurrent Unit) - simpler than a LSTM - with a dropout mechanism (drops 10% of the weights) for regularisation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f3f59e8",
   "metadata": {},
   "source": [
    "##  The Decoder\n",
    "The decoder is another RNN that takes the encoder output vector and outputs a sequence of words to create the translation.\n",
    "\n",
    "The decoder is trained to predict the next characters of the target sequence, given previous characters of the target sequence. Specifically, it is trained to turn the target sequences into the same sequences but offset by one timestep in the future, a training process called \"teacher forcing\" in this context. Importantly, the encoder uses as initial state the state vectors from the encoder, which is how the decoder obtains information about what it is supposed to generate.\n",
    "\n",
    "At every step of decoding, the decoder is given an input token and hidden state. The initial input token is the start-of-string <SOS> token, and the first hidden state is the context vector (the encoder’s last hidden state)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "bdc701db",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size):\n",
    "        super(DecoderRNN, self).__init__()\n",
    "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size, batch_first=True)\n",
    "        self.out = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, encoder_outputs, encoder_hidden, target_tensor=None):\n",
    "        batch_size = encoder_outputs.size(0)\n",
    "        decoder_input = torch.empty(batch_size, 1, dtype=torch.long, device=myDevice).fill_(SOS_token)\n",
    "        decoder_hidden = encoder_hidden\n",
    "        decoder_outputs = []\n",
    "\n",
    "        for i in range(MAX_LENGTH):\n",
    "            decoder_output, decoder_hidden  = self.forward_step(decoder_input, decoder_hidden)\n",
    "            decoder_outputs.append(decoder_output)\n",
    "\n",
    "            if target_tensor is not None:\n",
    "                # Teacher forcing: Feed the target as the next input\n",
    "                decoder_input = target_tensor[:, i].unsqueeze(1) # Teacher forcing\n",
    "            else:\n",
    "                # Without teacher forcing: use its own predictions as the next input\n",
    "                _, topi = decoder_output.topk(1)\n",
    "                decoder_input = topi.squeeze(-1).detach()  # detach from history as input\n",
    "\n",
    "        decoder_outputs = torch.cat(decoder_outputs, dim=1)\n",
    "        decoder_outputs = F.log_softmax(decoder_outputs, dim=-1)\n",
    "        return decoder_outputs, decoder_hidden, None # We return `None` for consistency in the training loop\n",
    "\n",
    "    def forward_step(self, input, hidden):\n",
    "        output = self.embedding(input)\n",
    "        output = F.relu(output)\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "        output = self.out(output)\n",
    "        return output, hidden"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "537cc46a",
   "metadata": {},
   "source": [
    "### Teacher forcing\n",
    "While running the encoder on the input sequence is relatively straightforward, handling the input and output of the decoder requires more care. The most common approach is called teacher forcing.  \n",
    "This method acts like a Regularization. So that the model trains efficiently and fastly during the process.  \n",
    "  \n",
    "“Teacher forcing” is the concept of using the real target outputs as each next input, instead of using the decoder’s guess as the next input. Using teacher forcing causes it to converge faster but when the trained network is exploited, it may exhibit instability.  \n",
    "  \n",
    "You can observe outputs of teacher-forced networks that read with coherent grammar but wander far from the correct translation - intuitively it has learned to represent the output grammar and can “pick up” the meaning once the teacher tells it the first few words, but it has not properly learned how to create the sentence from the translation in the first place.  \n",
    "  \n",
    "Because of the freedom PyTorch’s autograd gives us, we can randomly choose to use teacher forcing or not with a simple if statement.  \n",
    "Another possibility would be to use a teach force ratio (tfr), where we can actually control the flow of input words to the decoder. Sending either of the word (actual target word or predicted target word) can be regulated with a probability of say 50%, so at any time step, one of them is passed during the training. Turn rtf up to use more of it.  \n",
    "  \n",
    "Note that In some niche cases you may not be able to use teacher forcing, because you don't have access to the full target sequences, e.g. if you are doing online training on very long sequences, where buffering complete input-target pairs would be impossible. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12ce1abb",
   "metadata": {},
   "source": [
    "## Attention\n",
    "If only the context vector is passed between the encoder and decoder, that single vector carries the burden of encoding the entire sentence.  \n",
    "  \n",
    "In this resides the limitation of classic sequence to sequence models; the encoder is \"forced\" to send only a single vector, regardless of the length of our input i.e. how many words compose our sentence. Even if we decide to use a large number of hidden units in the encoder with the aim of having a larger context, then the model overfits with short sequences, and we take a performance hit as we increase the number of parameters.  \n",
    "  \n",
    "This is the problem that attention solves.\n",
    "  \n",
    "The intuition behind attention is that rather than compressing the input, it might be better for the decoder to revisit the input sequence at every step. Moreover, rather than always seeing the same representation of the input, the decoder should selectively focus a different part of the encoder’s outputs for every step of the decoder’s own outputs. \n",
    "  \n",
    "Think about a sentence like \"Pizza came out of the oven and it tasted good.\"    \n",
    "Attention is the mechanism that allows to correctly associate the word 'it' with the pizza.  \n",
    "  \n",
    "Attention mechanism provided a simple means by which the decoder could dynamically attend to different parts of the input at each decoding step. The high-level idea is that the decoder can receive as input a context vector consisting of a weighted sum of the representations on the input at each time step. Intuitively, the weights determine the extent to which each step’s context “focuses” on each input token, and the key is to make this process for assigning the weights differentiable so that it can be learned along with all of the other neural network parameters.\n",
    "  \n",
    "  This process allows  to amplify the important parts of the sequence and reduce the irrelevant parts.   \n",
    "    \n",
    "There are different types of attention, the simplest being the **self-attention**: it works by seeing how similar each word is to all the other words in the sentence, including itself.  \n",
    "Self-attention calculates these similarities and then are used to determine how the each word is encoded.  \n",
    "For example, in the previous example, the word 'it' will have a similarity score close to pizza.   \n",
    "So, attention tries to establish relationships among words. \n",
    "   \n",
    "  A variation would be the **masked self-attention**: only use the similarity between the current word and everything other words that come before, ignoring everything that come after it. In the example sentence, the word 'it' would be compared only with the words before, including pizza. The idea is that reference has already been done and saves time. \n",
    "  \n",
    "**Bahdanau attention**, also known as additive attention, is a commonly used attention mechanism in sequence-to-sequence models, particularly in neural machine translation tasks. It was introduced by Bahdanau et al. in their paper titled *Neural Machine Translation by Jointly Learning to Align and Translate* (ArXiv:1409.0473).  This attention mechanism employs a learned alignment model to compute attention scores between the encoder and decoder hidden states. It utilizes a feed-forward neural network to calculate alignment scores.\n",
    "  \n",
    "However, there are alternative attention mechanisms available, such as Luong attention, which computes attention scores by taking the dot product between the decoder hidden state and the encoder hidden states. It does not involve the non-linear transformation used in Bahdanau attention."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "0bfa05fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BahdanauAttention(nn.Module):\n",
    "    def __init__(self, hidden_size):\n",
    "        super(BahdanauAttention, self).__init__()\n",
    "        self.Wa = nn.Linear(hidden_size, hidden_size)\n",
    "        self.Ua = nn.Linear(hidden_size, hidden_size)\n",
    "        self.Va = nn.Linear(hidden_size, 1)\n",
    "\n",
    "    def forward(self, query, keys):\n",
    "        scores = self.Va(torch.tanh(self.Wa(query) + self.Ua(keys)))\n",
    "        scores = scores.squeeze(2).unsqueeze(1)\n",
    "\n",
    "        weights = F.softmax(scores, dim=-1)\n",
    "        context = torch.bmm(weights, keys)\n",
    "\n",
    "        return context, weights\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "384ca728",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttnDecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size, dropout_p=0.1):\n",
    "        super(AttnDecoderRNN, self).__init__()\n",
    "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
    "        self.attention = BahdanauAttention(hidden_size)\n",
    "        self.gru = nn.GRU(2 * hidden_size, hidden_size, batch_first=True)\n",
    "        self.out = nn.Linear(hidden_size, output_size)\n",
    "        self.dropout = nn.Dropout(dropout_p)\n",
    "\n",
    "    def forward(self, encoder_outputs, encoder_hidden, target_tensor=None):\n",
    "        batch_size = encoder_outputs.size(0)\n",
    "        decoder_input = torch.empty(batch_size, 1, dtype=torch.long, device=myDevice).fill_(SOS_token)\n",
    "        decoder_hidden = encoder_hidden\n",
    "        decoder_outputs = []\n",
    "        attentions = []\n",
    "\n",
    "        for i in range(MAX_LENGTH):\n",
    "            decoder_output, decoder_hidden, attn_weights = self.forward_step(\n",
    "                decoder_input, decoder_hidden, encoder_outputs\n",
    "            )\n",
    "            decoder_outputs.append(decoder_output)\n",
    "            attentions.append(attn_weights)\n",
    "\n",
    "            if target_tensor is not None:\n",
    "                # Teacher forcing: Feed the target as the next input\n",
    "                decoder_input = target_tensor[:, i].unsqueeze(1) # Teacher forcing\n",
    "            else:\n",
    "                # Without teacher forcing: use its own predictions as the next input\n",
    "                _, topi = decoder_output.topk(1)\n",
    "                decoder_input = topi.squeeze(-1).detach()  # detach from history as input\n",
    "\n",
    "        decoder_outputs = torch.cat(decoder_outputs, dim=1)\n",
    "        decoder_outputs = F.log_softmax(decoder_outputs, dim=-1)\n",
    "        attentions = torch.cat(attentions, dim=1)\n",
    "\n",
    "        return decoder_outputs, decoder_hidden, attentions\n",
    "\n",
    "\n",
    "    def forward_step(self, input, hidden, encoder_outputs):\n",
    "        embedded =  self.dropout(self.embedding(input))\n",
    "\n",
    "        query = hidden.permute(1, 0, 2)\n",
    "        context, attn_weights = self.attention(query, encoder_outputs)\n",
    "        input_gru = torch.cat((embedded, context), dim=2)\n",
    "\n",
    "        output, hidden = self.gru(input_gru, hidden)\n",
    "        output = self.out(output)\n",
    "\n",
    "        return output, hidden, attn_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "2ef9593b",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder = AttnDecoderRNN(HIDDEN_SIZE, output_lang.n_words)\n",
    "decoder = decoder.to(myDevice)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "95a96d07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decoder's state_dict:\n",
      "embedding.weight \t torch.Size([29382, 128])\n",
      "attention.Wa.weight \t torch.Size([128, 128])\n",
      "attention.Wa.bias \t torch.Size([128])\n",
      "attention.Ua.weight \t torch.Size([128, 128])\n",
      "attention.Ua.bias \t torch.Size([128])\n",
      "attention.Va.weight \t torch.Size([1, 128])\n",
      "attention.Va.bias \t torch.Size([1])\n",
      "gru.weight_ih_l0 \t torch.Size([384, 256])\n",
      "gru.weight_hh_l0 \t torch.Size([384, 128])\n",
      "gru.bias_ih_l0 \t torch.Size([384])\n",
      "gru.bias_hh_l0 \t torch.Size([384])\n",
      "out.weight \t torch.Size([29382, 128])\n",
      "out.bias \t torch.Size([29382])\n"
     ]
    }
   ],
   "source": [
    "print(\"Decoder's state_dict:\")\n",
    "for param_tensor in decoder.state_dict():\n",
    "    print(param_tensor, \"\\t\", decoder.state_dict()[param_tensor].size())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "f6b59542",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AttnDecoderRNN(\n",
       "  (embedding): Embedding(29382, 128)\n",
       "  (attention): BahdanauAttention(\n",
       "    (Wa): Linear(in_features=128, out_features=128, bias=True)\n",
       "    (Ua): Linear(in_features=128, out_features=128, bias=True)\n",
       "    (Va): Linear(in_features=128, out_features=1, bias=True)\n",
       "  )\n",
       "  (gru): GRU(256, 128, batch_first=True)\n",
       "  (out): Linear(in_features=128, out_features=29382, bias=True)\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a14ae71",
   "metadata": {},
   "source": [
    "The decoder is more complicated:\n",
    "- the input layer has size of the output language's (the foreign language, not English) number of words\n",
    "- the attention mechanism (size is the hidden layer's size, e.g. 128 nodes)\n",
    "- another GRU\n",
    "- the output layer, with a dropout mechanism"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8898ef48",
   "metadata": {},
   "source": [
    "# Training\n",
    "Before start training, let's prepare a couple of helper functions, to print the training progress (especially tracking the time) and plot the loss curve.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "id": "df9a1ec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import math\n",
    "\n",
    "def asMinutes(s):\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "def timeSince(since, percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "38460b12",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import matplotlib.ticker as ticker\n",
    "import numpy as np\n",
    "\n",
    "plt.switch_backend('agg')\n",
    "\n",
    "def showPlot(points):\n",
    "    plt.figure()\n",
    "    fig, ax = plt.subplots()\n",
    "    # this locator puts ticks at regular intervals\n",
    "    loc = ticker.MultipleLocator(base=0.2)\n",
    "    ax.yaxis.set_major_locator(loc)\n",
    "    plt.plot(points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "1445edc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "480fec41",
   "metadata": {},
   "source": [
    "## Training the Model\n",
    "To train, at each epoch, we run the input sentence through the encoder, and keep track of every output and the latest hidden state. Then the decoder is given the <SOS> token as its first input, and the last hidden state of the encoder as its first hidden state.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "da6ff1f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(dataloader, encoder, decoder, encoder_optimizer,\n",
    "          decoder_optimizer, criterion):\n",
    "\n",
    "    total_loss = 0\n",
    "        # iterate throught the dataloader batches\n",
    "    for data in dataloader:\n",
    "        input_tensor, target_tensor = data\n",
    "\n",
    "        encoder_optimizer.zero_grad()\n",
    "        decoder_optimizer.zero_grad()\n",
    "            # encoder\n",
    "        encoder_outputs, encoder_hidden = encoder(input_tensor)\n",
    "            # decoder\n",
    "        decoder_outputs, _, _ = decoder(encoder_outputs, encoder_hidden, target_tensor)\n",
    "\n",
    "            # calculate loss\n",
    "        loss = criterion(\n",
    "            decoder_outputs.view(-1, decoder_outputs.size(-1)),\n",
    "            target_tensor.view(-1)\n",
    "        )\n",
    "        loss.backward()\n",
    "\n",
    "        encoder_optimizer.step()\n",
    "        decoder_optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    return total_loss / len(dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d5b4ed8",
   "metadata": {},
   "source": [
    "The whole training process looks like this:\n",
    "\n",
    "- Start a timer\n",
    "\n",
    "- Initialise optimisers and criterion\n",
    "\n",
    "- Create set of training pairs\n",
    "\n",
    "- Start empty losses array for plotting\n",
    "\n",
    "Then we call train many times and occasionally print the progress (% of examples, time so far, estimated time) and average loss).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "af143b09",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_dataloader, encoder, decoder, n_epochs=80, learning_rate=0.001,\n",
    "               print_every=10, plot_every=10):\n",
    "        # start the timer\n",
    "    start = time.time()\n",
    "    \n",
    "        # initialisation\n",
    "    plot_losses = []\n",
    "    print_loss_total = 0  # Reset every print_every\n",
    "    plot_loss_total = 0  # Reset every plot_every\n",
    "\n",
    "    encoder_optimizer = optim.Adam(encoder.parameters(), lr=learning_rate)\n",
    "    decoder_optimizer = optim.Adam(decoder.parameters(), lr=learning_rate)\n",
    "    criterion = nn.NLLLoss()\n",
    "\n",
    "    print(\"Starting train of the model ...\")\n",
    "    print(f\"time since start (estimated remaining) | epoch / {n_epochs} | progress (%) | loss average\")\n",
    "    \n",
    "        # epochs loop\n",
    "    for epoch in range(1, n_epochs + 1):\n",
    "        \n",
    "        loss = train_epoch(train_dataloader, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion)\n",
    "        \n",
    "        print_loss_total += loss\n",
    "        plot_loss_total += loss\n",
    "\n",
    "            # print progress if due\n",
    "        if epoch % print_every == 0:\n",
    "            print_loss_avg = print_loss_total / print_every\n",
    "            print_loss_total = 0\n",
    "            print('%s | %d | %d%% | %.4f' % (timeSince(start, epoch / n_epochs),\n",
    "                                        epoch, epoch / n_epochs * 100, print_loss_avg))\n",
    "\n",
    "            # plot loss if due\n",
    "        if epoch % plot_every == 0:\n",
    "            plot_loss_avg = plot_loss_total / plot_every\n",
    "            plot_losses.append(plot_loss_avg)\n",
    "            plot_loss_total = 0\n",
    "\n",
    "    print(\"Training completed. Here is the loss plot:\")\n",
    "    showPlot(plot_losses);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "7b331513",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting train of the model ...\n",
      "time since start (estimated remaining) | epoch / 40 | progress (%) | loss average\n",
      "23m 26s (- 70m 18s) | 10 | 25% | 0.6266\n",
      "47m 59s (- 47m 59s) | 20 | 50% | 0.2296\n",
      "73m 14s (- 24m 24s) | 30 | 75% | 0.2011\n",
      "98m 10s (- 0m 0s) | 40 | 100% | 0.1920\n",
      "Training completed. Here is the loss plot:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train(trainData, encoder, decoder, n_epochs = 40)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5feaf0c9",
   "metadata": {},
   "source": [
    "Already after 20 epochs the loss (on training data) was greatly reduced."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82ab06d1",
   "metadata": {},
   "source": [
    "### Save the model\n",
    "\n",
    "This is optional but useful if you train a complex model for long time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "aea7f08d",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = \"../outputs/translationModels/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "c8adfecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = \"../outputs/translationModels/\"\n",
    "torch.save(encoder.state_dict(), PATH+\"encIT\")\n",
    "torch.save(decoder.state_dict(), PATH+\"decIT\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67c8e90d",
   "metadata": {},
   "source": [
    "## Translate a sentence  \n",
    "In inference mode, i.e. when we want to decode unknown input sequences, we go through a slightly different process: there are no targets. Every time it predicts a word we add it to the output string and if it predicts the EOS token we stop there. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "1ab23f0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate(encoder, decoder, sentence, input_lang, output_lang):\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        \n",
    "            # transform input sequence into tensors\n",
    "        input_tensor = tensorFromSentence(input_lang, sentence)\n",
    "        \n",
    "            # encode the input sequence into state vectors\n",
    "        encoder_outputs, encoder_hidden = encoder(input_tensor)\n",
    "            # Feed the state vectors to the decoder to produce predictions\n",
    "        decoder_outputs, decoder_hidden, decoder_attn = decoder(encoder_outputs, encoder_hidden)\n",
    "\n",
    "        _, topi = decoder_outputs.topk(1)\n",
    "        decoded_ids = topi.squeeze()\n",
    "\n",
    "            # Repeat until we generate the end-of-sequence character or we hit the character limit\n",
    "        decoded_words = []\n",
    "        for idx in decoded_ids:\n",
    "            if idx.item() == EOS_token:\n",
    "                decoded_words.append('<EOS>')\n",
    "                break\n",
    "                # Append the sampled character to the output sequence\n",
    "            decoded_words.append(output_lang.index2word[idx.item()])\n",
    "            \n",
    "    return decoded_words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17ec0e4b",
   "metadata": {},
   "source": [
    "Let's try with a test sentence:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "35ba8d52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i love machine learning and artificial intelligence\n"
     ]
    }
   ],
   "source": [
    "print(testSentenceEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "68bdd96a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "io amo gli hot dog . <EOS>\n"
     ]
    }
   ],
   "source": [
    "  # let's try first with the test sentence\n",
    "translationIT = translate(encoder, decoder, testSentenceEN, input_lang, output_lang)\n",
    "print(' '.join(w for w in translationIT))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4924ffce",
   "metadata": {},
   "source": [
    "This means \"I love the hot dogs\" which is hilarious. Clearly it's not perfect :)  \n",
    "Let's evaluate more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "b8ef910c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "non c'e alcuna la porta . <EOS>\n"
     ]
    }
   ],
   "source": [
    "translationIT = translate(encoder, decoder, 'there is no limit to the universe .', input_lang, output_lang)\n",
    "print(' '.join(w for w in translationIT))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b155481a",
   "metadata": {},
   "source": [
    "## Evaluation\n",
    "Evaluation is performed on the original dataset and we can decide if randomly sampling from the training data splice or the part not used for training.  \n",
    "Evaluation doesn't prove a model works: it just discovers the ways it fails, so let's see the mistakes:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "ce56a199",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35132"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = len(pairs)\n",
    "trainSplit = int(p * TRAIN_PERCENT)\n",
    "trainSplit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "fd8a6d09",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluateRandomly(encoder, decoder, pairs, onTrain = True, n=3):\n",
    "    # Sample n sentences from given pairs and translate them using the given dataset (train or test) \n",
    "    # and print the result (no return)\n",
    "    #\n",
    "    # Inputs:\n",
    "    # encoder, decoder: the model\n",
    "    # pairs: the dataset\n",
    "    # onTrain: boolean; True if sampling to be done on train dataset\n",
    "    # n: integer; number of sentences to sample; default is 3\n",
    "    \n",
    "    dataset = \"train\" if onTrain else \"test\"\n",
    "    print(f\"Evaluating {n} random sentences from {dataset} dataset\\n\\n\")\n",
    "    \n",
    "    trainSplit = int(len(pairs) * TRAIN_PERCENT)\n",
    "    print(f\"train split: {trainSplit}\")\n",
    "    \n",
    "    print(\"> input sentence in selected language\\n = target sentence translated in English \\n< Output sentence from the model\\n\")\n",
    "    \n",
    "    for i in range(n):\n",
    "        pair = random.choice(pairs[:trainSplit]) if onTrain else random.choice(pairs[trainSplit:])\n",
    "        print('>', pair[0])\n",
    "        print('=', pair[1])\n",
    "        \n",
    "        output_words = translate(encoder, decoder, pair[0], input_lang, output_lang)\n",
    "        \n",
    "        output_sentence = ' '.join(output_words)\n",
    "        print('<', output_sentence)\n",
    "        print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e2a1cc0",
   "metadata": {},
   "source": [
    "First we try with 3 random sentences from the training dataset:  \n",
    "- first line is the English sentence\n",
    "- second line is the target Italian sentence from the Train dataset\n",
    "- third line is the translated  Italian sentence (which should be the same or similar as the second line) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "252fa24a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating 3 random sentences from train dataset\n",
      "\n",
      "\n",
      "> input sentence in selected language\n",
      " = target sentence translated in English \n",
      "< Output sentence from the model\n",
      "\n",
      "> i need a hug .\n",
      "= a me serve un abbraccio .\n",
      "< mi serve un abbraccio . <EOS>\n",
      "\n",
      "> stand still .\n",
      "= stia ferma .\n",
      "< stia ferma . <EOS>\n",
      "\n",
      "> i saw a ufo .\n",
      "= vidi un ufo .\n",
      "< vidi un ufo . <EOS>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluateRandomly(encoder, decoder)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a972aa7a",
   "metadata": {},
   "source": [
    "As expected, **the model is quite good on the training examples** it has seen.  \n",
    "And this even with limited training.  \n",
    "  \n",
    "  Now we try the same with sentences that the model has not seen before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "03b17ac1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating 3 random sentences from test dataset\n",
      "\n",
      "\n",
      "> input sentence in selected language\n",
      " = target sentence translated in English \n",
      "< Output sentence from the model\n",
      "\n",
      "> the worst thing about winter is the snow .\n",
      "= la cosa peggiore riguardo all'inverno e la neve .\n",
      "< la macchina e partita . <EOS>\n",
      "\n",
      "> i want to watch a documentary .\n",
      "= voglio vedere un documentario .\n",
      "< una una una maschera . <EOS>\n",
      "\n",
      "> i am rather happy .\n",
      "= io sono abbastanza contento .\n",
      "< io sono stata felice . <EOS>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluateRandomly(encoder, decoder, onTrain = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cc78df5",
   "metadata": {},
   "source": [
    "And here the results are not that great; the last sentence is kinda similar but the other two are wrong.  \n",
    "  \n",
    "# Other languages\n",
    "To have a quick try at other languages, we first prepare a helper function to run the pipeline (read, prepare the data, train the model, evaluate):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "7cc730c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def runETLpipeline(language):\n",
    "        # Step1 : read and prepare the data\n",
    "    input_lang, output_lang, pairs = prepareData(language, False)   # eng -> chinese\n",
    "        # Step2: load data\n",
    "    trainData = get_trainDataloader(input_lang, output_lang, pairs, myDevice)\n",
    "    \n",
    "    print(\"=====\")\n",
    "        # Step3: instantiate the decoder in the output language\n",
    "    decoder = AttnDecoderRNN(HIDDEN_SIZE, output_lang.n_words)\n",
    "    decoder = decoder.to(myDevice)\n",
    "    \n",
    "    print(\"Decoder's state_dict:\")\n",
    "    for param_tensor in decoder.state_dict():\n",
    "        print(param_tensor, \"\\t\", decoder.state_dict()[param_tensor].size())\n",
    "        \n",
    "    print(\"=====\")\n",
    "    print(decoder)\n",
    "    print(\"=====\")\n",
    "    \n",
    "    \n",
    "        # Step4: training\n",
    "    train(trainData, encoder, decoder, n_epochs=20, print_every=5, plot_every=5)\n",
    "\n",
    "    print(\"=====\")\n",
    "    print (pairs[42]) # verify\n",
    "\n",
    "\n",
    "        # Step5: evaluation\n",
    "    evaluateRandomly(encoder, decoder, pairs)\n",
    "    evaluateRandomly(encoder, decoder, pairs, onTrain = False)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3876ce6b",
   "metadata": {},
   "source": [
    "# Japanese\n",
    "\n",
    "Let's see how it works with a non-latin language: Japanese"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "d9988b57",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_PERCENT = 0.5  # not many sentences in the dataset so we can increase the train percentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "7221ca3c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading lines...\n",
      "Read 115492 sentence pairs\n",
      "Trimmed to 95729 sentence pairs\n",
      "Counting words...\n",
      "Counted words:\n",
      "eng 12089\n",
      "jpn 75717\n",
      "train sentences: 47864\n",
      "=====\n",
      "Decoder's state_dict:\n",
      "embedding.weight \t torch.Size([75717, 128])\n",
      "attention.Wa.weight \t torch.Size([128, 128])\n",
      "attention.Wa.bias \t torch.Size([128])\n",
      "attention.Ua.weight \t torch.Size([128, 128])\n",
      "attention.Ua.bias \t torch.Size([128])\n",
      "attention.Va.weight \t torch.Size([1, 128])\n",
      "attention.Va.bias \t torch.Size([1])\n",
      "gru.weight_ih_l0 \t torch.Size([384, 256])\n",
      "gru.weight_hh_l0 \t torch.Size([384, 128])\n",
      "gru.bias_ih_l0 \t torch.Size([384])\n",
      "gru.bias_hh_l0 \t torch.Size([384])\n",
      "out.weight \t torch.Size([75717, 128])\n",
      "out.bias \t torch.Size([75717])\n",
      "=====\n",
      "AttnDecoderRNN(\n",
      "  (embedding): Embedding(75717, 128)\n",
      "  (attention): BahdanauAttention(\n",
      "    (Wa): Linear(in_features=128, out_features=128, bias=True)\n",
      "    (Ua): Linear(in_features=128, out_features=128, bias=True)\n",
      "    (Va): Linear(in_features=128, out_features=1, bias=True)\n",
      "  )\n",
      "  (gru): GRU(256, 128, batch_first=True)\n",
      "  (out): Linear(in_features=128, out_features=75717, bias=True)\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      ")\n",
      "=====\n",
      "Starting train of the model ...\n",
      "time since start (estimated remaining) | epoch / 20 | progress (%) | loss average\n",
      "32m 34s (- 97m 43s) | 5 | 25% | 0.7964\n",
      "63m 59s (- 63m 59s) | 10 | 50% | 0.1899\n",
      "94m 42s (- 31m 34s) | 15 | 75% | 0.1083\n",
      "125m 29s (- 0m 0s) | 20 | 100% | 0.1000\n",
      "Training completed. Here is the loss plot:\n",
      "=====\n",
      "Evaluating 3 random sentences from train dataset\n",
      "\n",
      "\n",
      "> input sentence in selected language\n",
      " = target sentence translated in English \n",
      "< Output sentence from the model\n",
      "\n",
      "> i promised i'd do that .\n",
      "= それをすると約束しました。\n",
      "< それをすると約束しました。 <EOS>\n",
      "\n",
      "> stop . that tickles .\n",
      "= やめて。くすくったい。\n",
      "< やめて。くすくったい。 <EOS>\n",
      "\n",
      "> tom is washing his car .\n",
      "= トムは車を洗っている。\n",
      "< トムは車を洗っている。 <EOS>\n",
      "\n",
      "Evaluating 3 random sentences from test dataset\n",
      "\n",
      "\n",
      "> input sentence in selected language\n",
      " = target sentence translated in English \n",
      "< Output sentence from the model\n",
      "\n",
      "> the city wants to extend the road .\n",
      "= 市はその道路を延長したいと考えている。\n",
      "< トムは道路を渡った。 <EOS>\n",
      "\n",
      "> is this diamond real or fake ?\n",
      "= このタイヤモントって、本物なのかな？偽物なのかな？\n",
      "< トムの友達なの？ <EOS>\n",
      "\n",
      "> i'd like to have cheesecake for dessert .\n",
      "= テサートにはチースケーキを頂きたい。\n",
      "< あの青いのも私のてす。 <EOS>\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "runETLpipeline('jpn')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17b5fe7f",
   "metadata": {},
   "source": [
    "Train loss was quickly reduced (probably 10-15 epochs would have been enough) and again the train sentences are right translated while the test sentences are wrong."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6038aefc",
   "metadata": {},
   "source": [
    "# Chinese\n",
    "Let's do the same with Chinese"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "3c08cc49",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_PERCENT = 0.8 # even bigger train dataset, hopefully this will improve the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "fa80c1fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading lines...\n",
      "Read 30919 sentence pairs\n",
      "Trimmed to 27065 sentence pairs\n",
      "Counting words...\n",
      "Counted words:\n",
      "eng 7179\n",
      "cmn 23657\n",
      "train sentences: 21652\n",
      "=====\n",
      "Decoder's state_dict:\n",
      "embedding.weight \t torch.Size([23657, 128])\n",
      "attention.Wa.weight \t torch.Size([128, 128])\n",
      "attention.Wa.bias \t torch.Size([128])\n",
      "attention.Ua.weight \t torch.Size([128, 128])\n",
      "attention.Ua.bias \t torch.Size([128])\n",
      "attention.Va.weight \t torch.Size([1, 128])\n",
      "attention.Va.bias \t torch.Size([1])\n",
      "gru.weight_ih_l0 \t torch.Size([384, 256])\n",
      "gru.weight_hh_l0 \t torch.Size([384, 128])\n",
      "gru.bias_ih_l0 \t torch.Size([384])\n",
      "gru.bias_hh_l0 \t torch.Size([384])\n",
      "out.weight \t torch.Size([23657, 128])\n",
      "out.bias \t torch.Size([23657])\n",
      "=====\n",
      "AttnDecoderRNN(\n",
      "  (embedding): Embedding(23657, 128)\n",
      "  (attention): BahdanauAttention(\n",
      "    (Wa): Linear(in_features=128, out_features=128, bias=True)\n",
      "    (Ua): Linear(in_features=128, out_features=128, bias=True)\n",
      "    (Va): Linear(in_features=128, out_features=1, bias=True)\n",
      "  )\n",
      "  (gru): GRU(256, 128, batch_first=True)\n",
      "  (out): Linear(in_features=128, out_features=23657, bias=True)\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      ")\n",
      "=====\n",
      "Starting train of the model ...\n",
      "time since start (estimated remaining) | epoch / 20 | progress (%) | loss average\n",
      "6m 12s (- 18m 36s) | 5 | 25% | 0.7987\n",
      "12m 26s (- 12m 26s) | 10 | 50% | 0.1545\n",
      "18m 40s (- 6m 13s) | 15 | 75% | 0.0374\n",
      "25m 4s (- 0m 0s) | 20 | 100% | 0.0274\n",
      "Training completed. Here is the loss plot:\n",
      "=====\n",
      "['be nice .', '友善点。']\n",
      "Evaluating 3 random sentences from train dataset\n",
      "\n",
      "\n",
      "train split: 21652\n",
      "> input sentence in selected language\n",
      " = target sentence translated in English \n",
      "< Output sentence from the model\n",
      "\n",
      "> we're eating apples .\n",
      "= 我們正在吃蘋果。\n",
      "< 軽い昼食をとりました。 <EOS>\n",
      "\n",
      "> tom just doesn't understand .\n",
      "= 汤姆就是不懂。\n",
      "< 私はむしろここにいたい。 <EOS>\n",
      "\n",
      "> let's meet at one o'clock .\n",
      "= 让我们在一点见面。\n",
      "< きれいな花てすね！ <EOS>\n",
      "\n",
      "Evaluating 3 random sentences from test dataset\n",
      "\n",
      "\n",
      "train split: 21652\n",
      "> input sentence in selected language\n",
      " = target sentence translated in English \n",
      "< Output sentence from the model\n",
      "\n",
      "> it wasn't you who told me about this .\n",
      "= 这件事情不是你告诉我的。\n",
      "< お手洗いはとこてすか。 <EOS>\n",
      "\n",
      "> you can't use this washing machine .\n",
      "= 你不能用這臺洗衣機。\n",
      "< 私は運勢を占ってもらった。 <EOS>\n",
      "\n",
      "> the boy carved his name on the tree .\n",
      "= 男孩把他的名字刻在树上。\n",
      "< とうしたの。 <EOS>\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "runETLpipeline(\"cmn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "766b417e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading lines...\n",
      "Read 30919 sentence pairs\n",
      "Trimmed to 27065 sentence pairs\n",
      "Counting words...\n",
      "Counted words:\n",
      "eng 7179\n",
      "cmn 23657\n"
     ]
    }
   ],
   "source": [
    "input_lang, output_lang, pairs = prepareData('cmn', False)   # eng -> chinese\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "8be6f1d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train sentences: 21652\n"
     ]
    }
   ],
   "source": [
    "trainData = get_trainDataloader(input_lang, output_lang, pairs, myDevice)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "734576fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pick a random index less than the batch size.\n",
    "index = random.randrange(len(src_batch))\n",
    "index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "13847770",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "多怪啊！\n",
      "你紧张吗？\n",
      "我不喜欢小孩。\n",
      "你用跑的。\n",
      "EOS\n",
      "SOS\n",
      "SOS\n",
      "SOS\n",
      "SOS\n",
      "SOS\n"
     ]
    }
   ],
   "source": [
    "for i in tgt_batch[index]:\n",
    "    print (output_lang.index2word[i.item()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "5f27c30a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['be nice .', '友善点。']"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pairs[42]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "0aa9d943",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder = AttnDecoderRNN(HIDDEN_SIZE, output_lang.n_words)\n",
    "decoder = decoder.to(myDevice)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "85ff50af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decoder's state_dict:\n",
      "embedding.weight \t torch.Size([23657, 128])\n",
      "attention.Wa.weight \t torch.Size([128, 128])\n",
      "attention.Wa.bias \t torch.Size([128])\n",
      "attention.Ua.weight \t torch.Size([128, 128])\n",
      "attention.Ua.bias \t torch.Size([128])\n",
      "attention.Va.weight \t torch.Size([1, 128])\n",
      "attention.Va.bias \t torch.Size([1])\n",
      "gru.weight_ih_l0 \t torch.Size([384, 256])\n",
      "gru.weight_hh_l0 \t torch.Size([384, 128])\n",
      "gru.bias_ih_l0 \t torch.Size([384])\n",
      "gru.bias_hh_l0 \t torch.Size([384])\n",
      "out.weight \t torch.Size([23657, 128])\n",
      "out.bias \t torch.Size([23657])\n"
     ]
    }
   ],
   "source": [
    "print(\"Decoder's state_dict:\")\n",
    "for param_tensor in decoder.state_dict():\n",
    "    print(param_tensor, \"\\t\", decoder.state_dict()[param_tensor].size())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "2f182745",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting train of the model ...\n",
      "time since start (estimated remaining) | epoch / 10 | progress (%) | loss average\n",
      "6m 26s (- 6m 26s) | 5 | 50% | 0.7617\n",
      "12m 57s (- 0m 0s) | 10 | 100% | 0.1190\n",
      "Training completed. Here is the loss plot:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train(trainData, encoder, decoder, n_epochs=10, print_every=5, plot_every=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "e8d8db44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cmn'"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "  # let's try first with the test sentence\n",
    "output_lang.name\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "21894615",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "我只做別人付錢讓我做的事。 <EOS>\n"
     ]
    }
   ],
   "source": [
    "translationCM = translate(encoder, decoder, 'there is no limit to the universe .', input_lang, output_lang)\n",
    "print(' '.join(w for w in translationCM))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ed45fff",
   "metadata": {},
   "source": [
    "\"I only do what I am paid to do\"  \n",
    "Ahah, is the model complaining?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "eb3771ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21652"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = len(pairs)\n",
    "trainSplit = int(p * TRAIN_PERCENT)\n",
    "trainSplit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "38f0c01d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating 3 random sentences from train dataset\n",
      "\n",
      "\n",
      "> input sentence in selected language\n",
      " = target sentence translated in English \n",
      "< Output sentence from the model\n",
      "\n",
      "> everyone will die .\n",
      "= 人固有一死。\n",
      "< 人固有一死。 <EOS>\n",
      "\n",
      "> the dog always barks at me .\n",
      "= 狗總是對著我嚎叫。\n",
      "< 不要看湯姆。看著我。 <EOS>\n",
      "\n",
      "> i have an opinion .\n",
      "= 我有一個意見。\n",
      "< 我有一個意見。 <EOS>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluateRandomly(encoder, decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "c01a82e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating 3 random sentences from test dataset\n",
      "\n",
      "\n",
      "> input sentence in selected language\n",
      " = target sentence translated in English \n",
      "< Output sentence from the model\n",
      "\n",
      "> sorry, tom, i don't have time to chat .\n",
      "= 湯姆，抱歉，我沒時間閒聊。\n",
      "< 我在这，你想聊天吗？ <EOS>\n",
      "\n",
      "> i'm almost finished reading this book .\n",
      "= 我就要读完这本书了。\n",
      "< 能够出一份力太好了。 <EOS>\n",
      "\n",
      "> his little brother is a famous soccer player .\n",
      "= 他弟弟是个有名的足球选手。\n",
      "< 湯姆是一個非常好的網球選手。 <EOS>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluateRandomly(encoder, decoder, onTrain = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "463c0dc6",
   "metadata": {},
   "source": [
    "# German\n",
    "\n",
    "Finally, let's see how it works with a reversed translation: from German to English"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "c4e5dcd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading lines...\n",
      "Read 320340 sentence pairs\n",
      "Trimmed to 249679 sentence pairs\n",
      "Counting words...\n",
      "Counted words:\n",
      "deu 35150\n",
      "eng 17892\n"
     ]
    }
   ],
   "source": [
    "input_lang, output_lang, pairs = prepareData('deu', True)   # German -> english\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a98c10b",
   "metadata": {},
   "source": [
    "The input and output languages contain several attributes (name, number of words, ...) and methods (convert a word into its index and viceversa):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "846ac205",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'deu'"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_lang.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "92b034d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'eng'"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_lang.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "746195c1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17892"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_lang.n_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "343300d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_lang.word2index[\"hello\"]  # get the index of english word \"hello\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "3ccef6ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hello'"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_lang.index2word[19]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "0c2ec058",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "630"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_lang.word2index[\"liebe\"] # german"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "555a7610",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "55"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_lang.word2count['hello'] # number of occurences of word 'hello'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db6952cc",
   "metadata": {},
   "source": [
    "Pairs are the data, basically a list with sentences in pairs: english and foreign language, in this case German:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "c91a6b24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['entschuldigung ?', 'sorry ?']"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pairs[42]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "71252792",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_PERCENT = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "f2e3bd70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train sentences: 24967\n"
     ]
    }
   ],
   "source": [
    "trainData = get_trainDataloader(input_lang, output_lang, pairs, myDevice)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "b1347f27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source: torch.Size([32, 10])\n",
      "Target: torch.Size([32, 10])\n"
     ]
    }
   ],
   "source": [
    "# Check a batch\n",
    "for src_batch, tgt_batch in trainData:\n",
    "    print(\"Source:\", src_batch.shape)\n",
    "    print(\"Target:\", tgt_batch.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "6709ad7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pick a random index less than the batch size.\n",
    "index = random.randrange(len(src_batch))\n",
    "index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "c26b2a71",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([  17,  354, 1797,    3,    1,    0,    0,    0,    0,    0])\n"
     ]
    }
   ],
   "source": [
    "print(tgt_batch[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "ab6520c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "it\n",
      "was\n",
      "superb\n",
      ".\n",
      "EOS\n",
      "SOS\n",
      "SOS\n",
      "SOS\n",
      "SOS\n",
      "SOS\n"
     ]
    }
   ],
   "source": [
    "for i in tgt_batch[index]:\n",
    "    print (output_lang.index2word[i.item()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "415a8208",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([  28,   86, 2998, 1443,    3,    1,    0,    0,    0,    0])\n"
     ]
    }
   ],
   "source": [
    "print(src_batch[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "2ba9145d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "es\n",
      "ist\n",
      "grandios\n",
      "gewesen\n",
      ".\n",
      "EOS\n",
      "SOS\n",
      "SOS\n",
      "SOS\n",
      "SOS\n"
     ]
    }
   ],
   "source": [
    "for i in src_batch[index]:\n",
    "    print (input_lang.index2word[i.item()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "af26b235",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder = AttnDecoderRNN(HIDDEN_SIZE, output_lang.n_words)\n",
    "decoder = decoder.to(myDevice)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "daaa0f01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decoder's state_dict:\n",
      "embedding.weight \t torch.Size([17892, 128])\n",
      "attention.Wa.weight \t torch.Size([128, 128])\n",
      "attention.Wa.bias \t torch.Size([128])\n",
      "attention.Ua.weight \t torch.Size([128, 128])\n",
      "attention.Ua.bias \t torch.Size([128])\n",
      "attention.Va.weight \t torch.Size([1, 128])\n",
      "attention.Va.bias \t torch.Size([1])\n",
      "gru.weight_ih_l0 \t torch.Size([384, 256])\n",
      "gru.weight_hh_l0 \t torch.Size([384, 128])\n",
      "gru.bias_ih_l0 \t torch.Size([384])\n",
      "gru.bias_hh_l0 \t torch.Size([384])\n",
      "out.weight \t torch.Size([17892, 128])\n",
      "out.bias \t torch.Size([17892])\n"
     ]
    }
   ],
   "source": [
    "print(\"Decoder's state_dict:\")\n",
    "for param_tensor in decoder.state_dict():\n",
    "    print(param_tensor, \"\\t\", decoder.state_dict()[param_tensor].size())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "5fb0fe35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AttnDecoderRNN(\n",
       "  (embedding): Embedding(17892, 128)\n",
       "  (attention): BahdanauAttention(\n",
       "    (Wa): Linear(in_features=128, out_features=128, bias=True)\n",
       "    (Ua): Linear(in_features=128, out_features=128, bias=True)\n",
       "    (Va): Linear(in_features=128, out_features=1, bias=True)\n",
       "  )\n",
       "  (gru): GRU(256, 128, batch_first=True)\n",
       "  (out): Linear(in_features=128, out_features=17892, bias=True)\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "dd07f099",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting train of the model ...\n",
      "time since start (estimated remaining) | epoch / 10 | progress (%) | loss average\n",
      "11m 12s (- 0m 0s) | 10 | 100% | 0.7508\n",
      "Training completed. Here is the loss plot:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train(trainData, encoder, decoder, n_epochs = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "304f520a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i love you . <EOS>\n"
     ]
    }
   ],
   "source": [
    "translationEN = translate(encoder, decoder, 'ich liebe dich .', input_lang, output_lang)\n",
    "print(' '.join(w for w in translationEN))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "d26d395b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24967"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = len(pairs)\n",
    "trainSplit = int(p * TRAIN_PERCENT)\n",
    "trainSplit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "853787b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating 3 random sentences from train dataset\n",
      "\n",
      "\n",
      "> input sentence in selected language\n",
      " = target sentence translated in English \n",
      "< Output sentence from the model\n",
      "\n",
      "> nicht bewegen !\n",
      "= don't move !\n",
      "< don't move ! <EOS>\n",
      "\n",
      "> wurde tom bestraft ?\n",
      "= was tom punished ?\n",
      "< are tom punished ? <EOS>\n",
      "\n",
      "> ich bin ziemlich pingelig .\n",
      "= i'm quite picky .\n",
      "< i'm quite picky . <EOS>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluateRandomly(encoder, decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "51739fe3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating 3 random sentences from test dataset\n",
      "\n",
      "\n",
      "> input sentence in selected language\n",
      " = target sentence translated in English \n",
      "< Output sentence from the model\n",
      "\n",
      "> tom hat einen vollbart .\n",
      "= tom has a full beard .\n",
      "< tom had a drunk . <EOS>\n",
      "\n",
      "> wenn du nach hause willst, dann geh !\n",
      "= if you want to go home, go .\n",
      "< show it to you . <EOS>\n",
      "\n",
      "> es ist schon 11 uhr .\n",
      "= it's already eleven .\n",
      "< there's it by . <EOS>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluateRandomly(encoder, decoder, onTrain = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8dbc858",
   "metadata": {},
   "source": [
    "## Bleu evaluation\n",
    "\n",
    "One more thing: to properly evaluate if a translation is correct, it's not enough to cmpare the target sentence and the translated sentence, as languages have nuances and multiple  alternative valid tranlsations.  \n",
    "A Bilingual Evaluation Understudy (BLEU) has been  proposed for evaluating machine translation results: for any n-gram, BLEU evaluates whether this n-gram appears in the target sequence.  \n",
    "*Papineni et al., 2002  \n",
    "BLEU: a method for automatic evaluation of machine translation. Proceedings of the 40th Annual Meeting of the Association for Computational Linguistics (pp. 311–318).*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "d95050e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "10c701d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bleu(pred_seq, label_seq, k):  \n",
    "    \"\"\"Compute the BLEU.\"\"\"\n",
    "    pred_tokens, label_tokens = pred_seq.split(' '), label_seq.split(' ')\n",
    "    len_pred, len_label = len(pred_tokens), len(label_tokens)\n",
    "    \n",
    "    score = math.exp(min(0, 1 - len_label / len_pred))\n",
    "    \n",
    "    for n in range(1, min(k, len_pred) + 1):\n",
    "        \n",
    "        num_matches, label_subs = 0, collections.defaultdict(int)\n",
    "        \n",
    "        for i in range(len_label - n + 1):\n",
    "            label_subs[' '.join(label_tokens[i: i + n])] += 1\n",
    "            \n",
    "        for i in range(len_pred - n + 1):\n",
    "            if label_subs[' '.join(pred_tokens[i: i + n])] > 0:\n",
    "                num_matches += 1\n",
    "                label_subs[' '.join(pred_tokens[i: i + n])] -= 1\n",
    "                \n",
    "        score *= math.pow(num_matches / (len_pred - n + 1), math.pow(0.5, n))\n",
    "        \n",
    "    return score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "176c3721",
   "metadata": {},
   "source": [
    "Here is a quick & dirty test with BLEU evaluation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "97da834f",
   "metadata": {},
   "outputs": [],
   "source": [
    "engs = ['go .', 'i lost .', 'he\\'s calm .', 'i\\'m home .']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "8ebde337",
   "metadata": {},
   "outputs": [],
   "source": [
    "deus = ['gehe !', 'ich habe verloren .', 'er ist ruhig .', 'ich bin zu hause .']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "id": "0714b2ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['go away .', 'i lost lost .', \"he's a calm calm .\", \"i'm home at home .\"]\n"
     ]
    }
   ],
   "source": [
    "preds = []\n",
    "\n",
    "for ds in deus:\n",
    "    es = translate(encoder, decoder, ds, input_lang, output_lang) \n",
    "    es = ' '.join([w for w in es if w != '<EOS>'])\n",
    "    preds.append(es)\n",
    "    \n",
    "print(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "id": "2c3b11a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gehe ! => go away . | bleu = 0.000\n",
      "ich habe verloren . => i lost lost . | bleu = 0.783\n",
      "er ist ruhig . => he's a calm calm . | bleu = 0.548\n",
      "ich bin zu hause . => i'm home at home . | bleu = 0.651\n"
     ]
    }
   ],
   "source": [
    "for en, de, p in zip(engs, deus, preds):\n",
    "    translation = []\n",
    "    \n",
    "    print(f'{de} => {p} | bleu = '\n",
    "          f'{bleu(p, en, k=2):.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41edf0d9",
   "metadata": {},
   "source": [
    "BLEU is a number between 0 (totally incorrect translation) and 1 (perfect translation), so higher the number, better the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "id": "5dd94084",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluateOnTest(encoder, decoder, pairs, input_lang, output_lang):\n",
    "\n",
    "    bleuTotal = 0\n",
    "    n = 0\n",
    "    \n",
    "    for i in range(trainSplit+1, len(pairs)):\n",
    "        try:\n",
    "            output_words = translate(encoder, decoder, pairs[i][0], input_lang, output_lang)\n",
    "        except:\n",
    "            continue\n",
    "            \n",
    "        output_sentence = ' '.join(output_words)\n",
    "        output_sentence = output_sentence.removesuffix(\"<EOS>\")\n",
    "\n",
    "        b = bleu(output_sentence, pairs[i][1], k=2)\n",
    "        bleuTotal += b\n",
    "        n += 1\n",
    "        \n",
    "    print(\"Total bleu =\", bleuTotal)\n",
    "    print(\"Average bleu = \", bleuTotal / n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "id": "f958b800",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total bleu = 26807.97134789218\n",
      "Average bleu =  0.14522588015868348\n"
     ]
    }
   ],
   "source": [
    "evaluateOnTest(encoder, decoder, pairs, input_lang, output_lang)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1b15137",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
